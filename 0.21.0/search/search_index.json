{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About","text":""},{"location":"index.html#mxlpy","title":"mxlpy","text":"<p>mxlpy is a Python package designed to enable mechanistic learning, bridging the gap between mechanistic modeling and machine learning. The package enables you to integrate ordinary differential equation (ODE) models with data-driven techniques. This combination allows for more accurate and interpretable predictions in systems where both physical laws and data-driven insights are valuable. mxlpy thus facilitates the development of models that are not only data-efficient but also robust and capable of capturing complex system dynamics. Choose one of the notebooks below to start your journey!</p>"},{"location":"index.html#building-and-simulating-models","title":"Building and simulating models","text":"<p>In this first notebook you will learn how to build ODE models and do basic simulations with them. This will allow you to create time courses and do steady-state analysis as shown below.</p> <p>Start learning</p>"},{"location":"index.html#parameter-scans","title":"Parameter scans","text":"<p>Parameter scans allow you to systematically assess the behaviour of your model dependent on the value of one or more parameters. mxlpy has rountines to scan over, and easily visualise time courses, protocol time courses, and steady states for one or more parameters.</p> <p>Start learning</p>"},{"location":"index.html#metabolic-control-analysis","title":"Metabolic control analysis","text":"<p>Metabolic control analysis answers the question: what happens to the concentrations and fluxes if I slightly perturb the system? It is thus a local measurement about which reactions hold the most control. If you ever read about rate-limiting steps, then this is for you!</p> <p>Start learning</p>"},{"location":"index.html#fitting","title":"Fitting","text":"<p>Almost every model at some point needs to be fitted to experimental data to be validated. mxlpy offers highly customisable routines for fitting either time series or steady-states.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#monte-carlo-methods","title":"Monte Carlo methods","text":"<p>Almost every parameter in biology is better described with a distribution than a single value. Monte-carlo methods allow you to capture the range of possible behaviour your model can exhibit. This is especially useful when you want to understand the uncertainty in your model's predictions. mxlpy offers these Monte Carlo methods for all scans  ...</p> + = <p>and even for metabolic control analysis</p> + = <p>Start learning</p>"},{"location":"index.html#label-models","title":"Label models","text":"<p>Labelled models allow explicitly mapping the transitions between isotopomers variables.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#mechanistic-learning","title":"Mechanistic Learning","text":"<p>Mechanistic learning is the intersection of mechanistic modelling and machine learning. mxlpy currently supports two such approaches: surrogates and neural posterior estimation. Surrogate models replace whole parts of a mechanistic model (or even the entire model) with machine learning models.</p> <p></p> <p>This allows combining together multiple models of arbitrary size, without having to worry about the internal state of each model. They are especially useful for improving the description of boundary effects, e.g. a dynamic description of downstream consumption. Neural posterior estimation answers the question: what parameters could have generated the data I measured? Here you use an ODE model and prior knowledge about the parameters of interest to create synthetic data. You then use the generated synthetic data as the features and the input parameters as the targets to train an inverse problem. Once that training is successful, the neural network can now predict the input parameters for real world data.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#parameterisation","title":"Parameterisation","text":"<p>Obtaining experimentally measured parameters can be challenging. Using the Brenda enzymes database we can obtain  distributions of enzymatic parameters for a wide range of organisms. These distributions can in turn be used with our Monte-Carlo methods to capture the range of possible behaviour your model can exhibit.</p> + = <p>Start learning</p>"},{"location":"index.html#experimental-features","title":"Experimental features","text":"<p>A collection of experimental features for you to explore. Warning: all APIs shown should be considered unstable and may change without notice.</p> <p>Start learning</p>"},{"location":"index.html#how-to-cite","title":"How to cite","text":"<p>If you use this software in your scientific work, please cite this article:</p> <ul> <li>doi</li> <li>bibtex file</li> </ul>"},{"location":"basics.html","title":"Basics","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Any\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy import unwrap\n\n\ndef print_annotated(description: str, value: Any) -&gt; None:\n    print(\n        description,\n        value,\n        sep=\"\\n\",\n        end=\"\\n\\n\",\n    )\n</pre> from __future__ import annotations  from pathlib import Path from typing import Any  import matplotlib.pyplot as plt  from example_models import get_linear_chain_2v from mxlpy import unwrap   def print_annotated(description: str, value: Any) -&gt; None:     print(         description,         value,         sep=\"\\n\",         end=\"\\n\\n\",     ) In\u00a0[2]: Copied! <pre>def constant(k: float) -&gt; float:\n    return k\n\n\ndef proportional(k: float, s: float) -&gt; float:\n    return k * s\n</pre> def constant(k: float) -&gt; float:     return k   def proportional(k: float, s: float) -&gt; float:     return k * s <p>Next, we create our model.</p> <p>For this, we first import the <code>Model</code> class from the <code>mxlpy</code> package.</p> In\u00a0[3]: Copied! <pre>from mxlpy import Model\n\nmodel = Model()\n</pre> from mxlpy import Model  model = Model() <p>We first add parameters to the model using <code>.add_parameters({name: value})</code>.</p> <p>Note that the function returns our <code>Model</code> object again. This will be useful later, as we can chain multiple calls together.</p> In\u00a0[4]: Copied! <pre>model = model.add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})\n</pre> model = model.add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1}) <p>Next we add the dynamic variables <code>S</code> and <code>P</code> with their respective initial condition.</p> In\u00a0[5]: Copied! <pre>model = model.add_variables({\"S\": 0, \"P\": 0})\n</pre> model = model.add_variables({\"S\": 0, \"P\": 0}) <p>Finally, we add the three reactions by using</p> <pre>.add_reaction(\n    name,              # the internal name for the reaction\n    fn=...,            # a python function to be evaluated\n    args=[name, ...]   # the arguments passed to the python function\n    stoichiometry={    # a mapping encoding how much the variable `name`\n        name: value    # is changed by the reaction\n    },\n)\n</pre> <p>Attention There are a couple of points to note here. First, the function passed to <code>fn</code> here (and elsewhere) needs to be pickle-able Thus, lambda functions are not supported!</p> <p>Second, the arguments defined with <code>args</code> are passed to <code>fn</code> by position, not by name. Thus, the order of arguments in <code>args</code> needs to match the order of arguments in <code>fn</code></p> In\u00a0[6]: Copied! <pre>model.add_reaction(\n    \"v0\",\n    fn=constant,\n    args=[\"k_in\"],\n    stoichiometry={\"S\": 1},  # produces one S\n)\nmodel.add_reaction(\n    \"v1\",\n    fn=proportional,\n    args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`\n    stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P\n)\nmodel.add_reaction(\n    \"v2\",\n    fn=proportional,\n    args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`\n    stoichiometry={\"P\": -1},  # exports one P\n)\n\nprint(model.get_reaction_names())\n</pre> model.add_reaction(     \"v0\",     fn=constant,     args=[\"k_in\"],     stoichiometry={\"S\": 1},  # produces one S ) model.add_reaction(     \"v1\",     fn=proportional,     args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`     stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P ) model.add_reaction(     \"v2\",     fn=proportional,     args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`     stoichiometry={\"P\": -1},  # exports one P )  print(model.get_reaction_names()) <pre>['v0', 'v1', 'v2']\n</pre> <p>Note, that we in general recommend to use a single function that returns the model instead of defining it globally. This allows us to quickly re-create the model whenever we need a fresh version of it. Below, we define the same model again, but inside a single function.</p> <p>Note that we made use of operator chaining to avoid having to write <code>model</code> for every call.</p> <p>So we can write <code>Model.method1().method2()...</code>  instead of having to write</p> <pre>model.method1()\nmodel.method2()\n</pre> <p>etc</p> In\u00a0[7]: Copied! <pre>def create_linear_chain_model() -&gt; Model:\n    return (\n        Model()\n        .add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})\n        .add_variables({\"S\": 0, \"P\": 0})\n        .add_reaction(\n            \"v0\",\n            fn=constant,\n            args=[\"k_in\"],\n            stoichiometry={\"S\": 1},  # produces one S\n        )\n        .add_reaction(\n            \"v1\",\n            fn=proportional,\n            args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`\n            stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P\n        )\n        .add_reaction(\n            \"v2\",\n            fn=proportional,\n            args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`\n            stoichiometry={\"P\": -1},  # exports one P\n        )\n    )\n</pre> def create_linear_chain_model() -&gt; Model:     return (         Model()         .add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})         .add_variables({\"S\": 0, \"P\": 0})         .add_reaction(             \"v0\",             fn=constant,             args=[\"k_in\"],             stoichiometry={\"S\": 1},  # produces one S         )         .add_reaction(             \"v1\",             fn=proportional,             args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`             stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P         )         .add_reaction(             \"v2\",             fn=proportional,             args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`             stoichiometry={\"P\": -1},  # exports one P         )     ) <p>We can then simulate the model by passing it to a <code>Simulator</code> and simulate a time series using <code>.simulate(t_end)</code>. Finally, we can obtain the concentrations and fluxes using <code>get_result</code>.</p> <p>While you can directly plot the <code>pd.DataFrame</code>s, mxlpy supplies a variety of plots in the <code>plot</code> namespace that are worth checking out.</p> In\u00a0[8]: Copied! <pre>from mxlpy import Simulator, plot\n\nres = (\n    Simulator(create_linear_chain_model())  # initialise the simulator\n    .simulate(5)  # simulate until t_end = 5 a.u.\n    .get_result()  # return pd.DataFrames for concentrations and fluxes\n)\n\nif res is not None:\n    variables, fluxes = res\n\n    fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5))\n    _ = plot.lines(variables, ax=ax1)\n    _ = plot.lines(fluxes, ax=ax2)\n\n    # Never forget to labelr you axes :)\n    ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\n    ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\n    plt.show()\n</pre> from mxlpy import Simulator, plot  res = (     Simulator(create_linear_chain_model())  # initialise the simulator     .simulate(5)  # simulate until t_end = 5 a.u.     .get_result()  # return pd.DataFrames for concentrations and fluxes )  if res is not None:     variables, fluxes = res      fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5))     _ = plot.lines(variables, ax=ax1)     _ = plot.lines(fluxes, ax=ax2)      # Never forget to labelr you axes :)     ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")     ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")     plt.show() <p>Note, that we checked whether the results were <code>None</code> in case the simulation failed. Explicitly checking using an <code>if</code> clause is the prefered error handling mechanism.</p> <p>If you are sure the simulation won't fail, and still want your code to be type-safe, you can use <code>unwrap</code>.</p> <pre>variables, fluxes = unwrap(Simulator(model).simulate(10).get_result())\n</pre> <p>Note that these functions will throw an error if the values are <code>None</code>, which potentially might crash your programs.</p> In\u00a0[9]: Copied! <pre>def moiety_1(x1: float, total: float) -&gt; float:\n    return total - x1\n\n\ndef model_derived() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"ATP\": 1.0})\n        .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})\n        .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])\n        .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])\n        .add_reaction(\n            \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}\n        )\n    )\n\n\nvariables, fluxes = unwrap(Simulator(model_derived()).simulate(10).get_result())\nfig, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> def moiety_1(x1: float, total: float) -&gt; float:     return total - x1   def model_derived() -&gt; Model:     return (         Model()         .add_variables({\"ATP\": 1.0})         .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})         .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])         .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])         .add_reaction(             \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}         )     )   variables, fluxes = unwrap(Simulator(model_derived()).simulate(10).get_result()) fig, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[10]: Copied! <pre>m = create_linear_chain_model()\n\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_args(),\n)\n\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_args({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  print_annotated(     \"Using initial conditions as default:\",     m.get_args(), )  print_annotated(     \"Using custom concentrations:\",     m.get_args({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nS    0.0\nP    0.0\ndtype: float64\n\nUsing custom concentrations:\nS    1.0\nP    0.5\ndtype: float64\n\n</pre> <p>If the <code>args</code> look fine, the next step is usually to check whether the rate equations are looking as expected</p> In\u00a0[11]: Copied! <pre>m = create_linear_chain_model()\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_fluxes(),\n)\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model() print_annotated(     \"Using initial conditions as default:\",     m.get_fluxes(), ) print_annotated(     \"Using custom concentrations:\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nv0    1.0\nv1    0.0\nv2    0.0\ndtype: float64\n\nUsing custom concentrations:\nv0    1.0\nv1    1.0\nv2    0.5\ndtype: float64\n\n</pre> <p>and whether the stoichiometries are assigned correctly</p> In\u00a0[12]: Copied! <pre>m = create_linear_chain_model()\nm.get_stoichiometries()\n</pre> m = create_linear_chain_model() m.get_stoichiometries() Out[12]: v0 v1 v2 S 1.0 -1.0 0.0 P 0.0 1.0 -1.0 <p>Lastly, you can check the generated right hand side</p> In\u00a0[13]: Copied! <pre>m = create_linear_chain_model()\n\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_right_hand_side(),\n)\n\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_right_hand_side({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  print_annotated(     \"Using initial conditions as default:\",     m.get_right_hand_side(), )  print_annotated(     \"Using custom concentrations:\",     m.get_right_hand_side({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nS    1.0\nP    0.0\ndtype: float64\n\nUsing custom concentrations:\nS    0.0\nP    0.5\ndtype: float64\n\n</pre> <p>If any of the quantities above were unexpected, you can check the model interactively by accessing the various collections.</p> <p>Note: the returned quantities are copies of the internal data, modifying these won't have any effect on the model</p> In\u00a0[14]: Copied! <pre>print_annotated(\"Parameters\", m.parameters)\nprint_annotated(\"Variables\", m.variables)\nprint_annotated(\"Reactions\", m.reactions)\n</pre> print_annotated(\"Parameters\", m.parameters) print_annotated(\"Variables\", m.variables) print_annotated(\"Reactions\", m.reactions) <pre>Parameters\n{'k_in': 1, 'k_1': 1, 'k_out': 1}\n\nVariables\n{'S': 0, 'P': 0}\n\nReactions\n{'v0': Reaction(fn=&lt;function constant at 0x7ff6bbacb4c0&gt;, stoichiometry={'S': 1}, args=['k_in']), 'v1': Reaction(fn=&lt;function proportional at 0x7ff6bbacb560&gt;, stoichiometry={'S': -1, 'P': 1}, args=['k_1', 'S']), 'v2': Reaction(fn=&lt;function proportional at 0x7ff6bbacb560&gt;, stoichiometry={'P': -1}, args=['k_out', 'P'])}\n\n</pre> <p>In case you model contains derived quantitites you can access the derived quantities using <code>.derived</code>. Note that this returns a copy of the derived quantities, so editing it won't have any effect on the model.</p> In\u00a0[15]: Copied! <pre>model_derived().derived\n</pre> model_derived().derived Out[15]: <pre>{'k_atp': Derived(fn=&lt;function proportional at 0x7ff6bbacb560&gt;, args=['k_base', 'e0_atpase']),\n 'ADP': Derived(fn=&lt;function moiety_1 at 0x7ff6bad36b60&gt;, args=['ATP', 'ATP_total'])}</pre> In\u00a0[16]: Copied! <pre>m = create_linear_chain_model()\n\n# Calculate fluxes\nprint_annotated(\n    \"Before update\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n\n# Update parameters\nm.update_parameters({\"k_in\": 2.0})\n\n# Calculate fluxes again\nprint_annotated(\n    \"After update\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  # Calculate fluxes print_annotated(     \"Before update\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), )  # Update parameters m.update_parameters({\"k_in\": 2.0})  # Calculate fluxes again print_annotated(     \"After update\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), ) <pre>Before update\nv0    1.0\nv1    1.0\nv2    0.5\ndtype: float64\n\nAfter update\nv0    2.0\nv1    1.0\nv2    0.5\ndtype: float64\n\n</pre> In\u00a0[17]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(\n        Model()\n        .add_parameters({\"stoich\": -1.0, \"k\": 1.0})\n        .add_variables({\"x\": 1.0})\n        .add_reaction(\n            \"name\",\n            proportional,\n            args=[\"x\", \"k\"],\n            # Define derived stoichiometry here\n            stoichiometry={\"x\": \"stoich\"},\n        )\n    )\n    .simulate(1)\n    # Update parameter the derived stoichiometry depends on\n    .update_parameter(\"stoich\", -4.0)\n    # Continue simulation\n    .simulate(5)\n    .get_result()\n)\n\n_, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(         Model()         .add_parameters({\"stoich\": -1.0, \"k\": 1.0})         .add_variables({\"x\": 1.0})         .add_reaction(             \"name\",             proportional,             args=[\"x\", \"k\"],             # Define derived stoichiometry here             stoichiometry={\"x\": \"stoich\"},         )     )     .simulate(1)     # Update parameter the derived stoichiometry depends on     .update_parameter(\"stoich\", -4.0)     # Continue simulation     .simulate(5)     .get_result() )  _, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[18]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v())\n    .simulate(t_end=10)  # simulate until t_end = 10 a.u.\n    .get_result()\n)\n\nfig, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v())     .simulate(t_end=10)  # simulate until t_end = 10 a.u.     .get_result() )  fig, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() <p>By default, the <code>Simulator</code> is initialised with the initial concentrations set in the <code>Model</code>. Optionally, you can overwrite the initial conditions using the <code>y0</code> argument.</p> <pre>Simulator(model, y0={name: value, ...})\n</pre> In\u00a0[19]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(create_linear_chain_model(), y0={\"S\": 2.0, \"P\": 0.0})\n    .simulate(10)\n    .get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3))\n_ = plot.lines(variables, ax=ax1)\n_ = plot.lines(fluxes, ax=ax2)\n\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(create_linear_chain_model(), y0={\"S\": 2.0, \"P\": 0.0})     .simulate(10)     .get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3)) _ = plot.lines(variables, ax=ax1) _ = plot.lines(fluxes, ax=ax2)  ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() In\u00a0[20]: Copied! <pre>from mxlpy import make_protocol\n\nprotocol = make_protocol(\n    [\n        (1, {\"k1\": 1}),  # for one second value of 1\n        (2, {\"k1\": 2}),  # for two seconds value of 2\n        (3, {\"k1\": 1}),  # for three seconds value of 1\n    ]\n)\nprotocol\n</pre> from mxlpy import make_protocol  protocol = make_protocol(     [         (1, {\"k1\": 1}),  # for one second value of 1         (2, {\"k1\": 2}),  # for two seconds value of 2         (3, {\"k1\": 1}),  # for three seconds value of 1     ] ) protocol Out[20]: k1 Timedelta 0 days 00:00:01 1 0 days 00:00:03 2 0 days 00:00:06 1 <p>Now instead of running <code>simulate</code> or <code>simulate_time_course</code> we use <code>simulate_over_protocol</code></p> In\u00a0[21]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v()).simulate_over_protocol(protocol).get_result()\n)\n\nfig, ax = plt.subplots()\nplot.lines(variables, ax=ax)\nplot.shade_protocol(protocol[\"k1\"], ax=ax, alpha=0.1)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v()).simulate_over_protocol(protocol).get_result() )  fig, ax = plt.subplots() plot.lines(variables, ax=ax) plot.shade_protocol(protocol[\"k1\"], ax=ax, alpha=0.1) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[22]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v())  # optionally supply initial conditions\n    .simulate_to_steady_state()\n    .get_result()\n)\n\nfig, ax = plot.bars(variables)\nax.set(xlabel=\"Variable / a.u.\", ylabel=\"Concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v())  # optionally supply initial conditions     .simulate_to_steady_state()     .get_result() )  fig, ax = plot.bars(variables) ax.set(xlabel=\"Variable / a.u.\", ylabel=\"Concentration / a.u.\") plt.show() In\u00a0[23]: Copied! <pre>from mxlpy import sbml\n\nmodel = sbml.read(Path(\"assets\") / \"00001-sbml-l3v2.xml\")\nvariables, fluxes = unwrap(Simulator(model).simulate(10).get_result())\n_ = plot.lines(variables)\n</pre> from mxlpy import sbml  model = sbml.read(Path(\"assets\") / \"00001-sbml-l3v2.xml\") variables, fluxes = unwrap(Simulator(model).simulate(10).get_result()) _ = plot.lines(variables) <p>When exporting a model, you can supply additional meta-information like units and compartmentalisation. See the official sbml documentation for more information of legal values.</p> In\u00a0[24]: Copied! <pre>sbml.write(\n    model,\n    file=Path(\".cache\") / \"model.xml\",\n    extent_units=\"mole\",\n    substance_units=\"mole\",\n    time_units=\"second\",\n)\n</pre> sbml.write(     model,     file=Path(\".cache\") / \"model.xml\",     extent_units=\"mole\",     substance_units=\"mole\",     time_units=\"second\", ) Out[24]: <pre>PosixPath('.cache/model.xml')</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about model building and simulation in mxlpy.           Congratulations!  In\u00a0[25]: Copied! <pre>def time_dependency() -&gt; Model:\n    return (\n        Model()\n        .add_variable(\"x\", 1.0)\n        .add_reaction(\n            \"v1\",\n            proportional,\n            args=[\"time\", \"x\"],\n            stoichiometry={\"x\": -1},\n        )\n    )\n\n\nmodel = time_dependency()\n\n# Watch our for explicit time dependency here!\nprint_annotated(\n    \"Fluxes at time = 1.0\",\n    model.get_fluxes(time=1.0),\n)\nprint_annotated(\n    \"Fluxes at time = 2.0\",\n    model.get_fluxes(time=2.0),\n)\n\n# During simulations the time is automatically taken care of\n_ = unwrap(Simulator(model).simulate(t_end=10).get_result()).variables.plot(\n    xlabel=\"time / a.u.\",\n    ylabel=\"amount / a.u.\",\n    title=\"Time-dependent reaction\",\n)\n</pre> def time_dependency() -&gt; Model:     return (         Model()         .add_variable(\"x\", 1.0)         .add_reaction(             \"v1\",             proportional,             args=[\"time\", \"x\"],             stoichiometry={\"x\": -1},         )     )   model = time_dependency()  # Watch our for explicit time dependency here! print_annotated(     \"Fluxes at time = 1.0\",     model.get_fluxes(time=1.0), ) print_annotated(     \"Fluxes at time = 2.0\",     model.get_fluxes(time=2.0), )  # During simulations the time is automatically taken care of _ = unwrap(Simulator(model).simulate(t_end=10).get_result()).variables.plot(     xlabel=\"time / a.u.\",     ylabel=\"amount / a.u.\",     title=\"Time-dependent reaction\", ) <pre>Fluxes at time = 1.0\nv1    1.0\ndtype: float64\n\nFluxes at time = 2.0\nv1    2.0\ndtype: float64\n\n</pre> In\u00a0[26]: Copied! <pre>def model_derived() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"ATP\": 1.0})\n        .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})\n        .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])\n        .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])\n        .add_reaction(\n            \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}\n        )\n    )\n\n\nm = Model().add_parameters({\"x1\": 1.0}).add_derived(\"x1d\", constant, args=[\"x1\"])\nprint(\"Derived Parameters:\", m.derived_parameters)\nprint(\"Derived Variables:\", m.derived_variables)\n\nprint(\"\\nMaking x1 dynamic\")\nm.make_parameter_dynamic(\"x1\")\nprint(\"Derived Parameters:\", m.derived_parameters)\nprint(\"Derived Variables:\", m.derived_variables)\n</pre> def model_derived() -&gt; Model:     return (         Model()         .add_variables({\"ATP\": 1.0})         .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})         .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])         .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])         .add_reaction(             \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}         )     )   m = Model().add_parameters({\"x1\": 1.0}).add_derived(\"x1d\", constant, args=[\"x1\"]) print(\"Derived Parameters:\", m.derived_parameters) print(\"Derived Variables:\", m.derived_variables)  print(\"\\nMaking x1 dynamic\") m.make_parameter_dynamic(\"x1\") print(\"Derived Parameters:\", m.derived_parameters) print(\"Derived Variables:\", m.derived_variables) <pre>Derived Parameters: {'x1d': Derived(fn=&lt;function constant at 0x7ff6bbacb4c0&gt;, args=['x1'])}\nDerived Variables: {}\n\nMaking x1 dynamic\nDerived Parameters: {}\nDerived Variables: {'x1d': Derived(fn=&lt;function constant at 0x7ff6bbacb4c0&gt;, args=['x1'])}\n</pre> In\u00a0[27]: Copied! <pre>import pandas as pd\n\n\ndef average(light: pd.Series) -&gt; float:\n    return light.mean()\n\n\ndef model_data(light: pd.Series) -&gt; Model:\n    return (\n        Model()\n        .add_data(\"light\", light)\n        .add_derived(\"averge_light\", average, args=[\"light\"])\n    )\n\n\nlights = pd.Series(\n    data={\"400nm\": 200, \"500nm\": 300, \"600nm\": 400},\n    dtype=float,\n)\n\nmodel_data(lights).get_dependent()\n</pre> import pandas as pd   def average(light: pd.Series) -&gt; float:     return light.mean()   def model_data(light: pd.Series) -&gt; Model:     return (         Model()         .add_data(\"light\", light)         .add_derived(\"averge_light\", average, args=[\"light\"])     )   lights = pd.Series(     data={\"400nm\": 200, \"500nm\": 300, \"600nm\": 400},     dtype=float, )  model_data(lights).get_dependent() Out[27]: <pre>time              0.0\naverge_light    300.0\ndtype: float64</pre>"},{"location":"basics.html#model-building-basics","title":"Model building basics\u00b6","text":"<p>In the following you will learn how to build and simulate your first model using <code>mxlpy</code>.</p> <p>This will allow you to create time courses and do steady-state analysis as shown below.</p>"},{"location":"basics.html#defining-your-first-model","title":"Defining your first model\u00b6","text":"<p>Let's say you want to model the following chemical network of a linear chain of reactions</p> <p>$$ \\Large \\varnothing \\xrightarrow{v_0} S \\xrightarrow{v_1} P \\xrightarrow{v_2} \\varnothing $$</p> <p>We can translate this into a system of ordinary differential equations (ODEs)</p> <p>$$\\begin{align*} \\frac{dS}{dt} &amp;= v_0 - v_1     \\\\ \\frac{dP}{dt} &amp;= v_1 - v_2 \\\\ \\end{align*} $$</p> <p>Note that the rates $v$ effect the variables by certain factors, known as stoichiometries. We can explicity write out these factors like this:</p> <p>$$\\begin{align*} \\frac{dS}{dt} &amp;= 1 \\cdot v_0 -1 \\cdot v_1     \\\\ \\frac{dP}{dt} &amp;= 1\\cdot v_1 -1 \\cdot v_2 \\\\ \\end{align*} $$</p> <p>In the example the stoichiometries are all $1$ or $-1$, however, they can have any real value. We can write out the stoichiometries using a stoichiometric matrix:</p> Variable $v_0$ $v_1$ $v_2$ S 1 -1 0 P 0 1 -1 <p>Which we can read as (ignoring the 0 entries):</p> <ul> <li><code>S</code> is produced by $v_0$ and consumed by $v_1$</li> <li><code>P</code> is produced by $v_1$ and consumed by $v_2$</li> </ul> <p>Lastly we choose rate equations for each rate to get the flux vector $v$</p> <p>$$\\begin{align*}     v_0 &amp;= k_{in} \\\\     v_1 &amp;= k_1 * S \\\\     v_2 &amp;= k_{out} * P \\\\ \\end{align*}$$</p>"},{"location":"basics.html#implementing-your-first-model","title":"Implementing your first model\u00b6","text":"<p>Now let's implement this first model in mxlpy. We start by creating the rate functions $\\textbf{v}$. Note that these should be general and re-usable whenever possible, to make your model clear to people reading it. Try to give these functions names that are meaningful to your audience, e.g. a rate function <code>k * s</code> could be named proportional or mass-action.</p>"},{"location":"basics.html#derived-quantities","title":"Derived quantities\u00b6","text":"<p>Frequently it makes sense to derive one quantity in a model from other quantities. This can be done for</p> <ul> <li>parameters derived from other parameters</li> <li>variables derived from parameters or other variables</li> <li>stoichiometries derived from parameters or variables (more on this later)</li> </ul> <p>mxlpy offers a unified interface for derived parameters and variables usign <code>Model.add_derived()</code>.</p>"},{"location":"basics.html#introspection","title":"Introspection\u00b6","text":"<p>If the simulation didn't show the expected results, it is usually a good idea to try to pinpoint the error. <code>mxlpy</code> offers a variety of methods to access intermediate results.</p> <p>The first is to check whether all derived quantities were calculate correctly. For this, you can use the <code>get_args</code> method, which is named consistently with the <code>args</code> argument in all methods like <code>add_reaction</code>.</p>"},{"location":"basics.html#crud","title":"CRUD\u00b6","text":"<p>The model has a complete create, read, update, delete API for all it's elements. The methods and attributes are named consistenly, with <code>add</code> instead of <code>create</code> and <code>get</code> instead of <code>read</code>. Note that the elements itself are accessible as <code>properties</code>, e.g. <code>.parameters</code> which will return copies of the data. Only use the supplied methods to change the internal state of the model.</p> <p>Here are some example methods and attributes for parameters</p> Functionality Parameters Create <code>.add_parameter()</code>, <code>.add_parameters()</code> Read <code>.parameters</code>, <code>.get_parameter_names()</code> Update <code>.update_parameter()</code>, <code>.update_parameters()</code>, <code>.scale_parameter()</code>, <code>scale.parameters()</code> Delete <code>.remove_parameter()</code>, <code>.remove_parameters()</code> <p>and variables</p> Functionality Variables Create <code>.add_variable()</code>, <code>.add_variables()</code> Read <code>.variables</code>, <code>.get_variable_names()</code>, <code>get_initial_conditions()</code> Update <code>.update_variable()</code>, <code>.update_variables()</code> Delete <code>.remove_parameter()</code>, <code>.remove_parameters()</code>"},{"location":"basics.html#derived-stoichiometries","title":"Derived stoichiometries\u00b6","text":"<p>To define derived stoichiometries can make them dependent on parameters in the model or use the <code>Derived</code> class as a value in the stoichiometries.</p> <p>So instead of defining them like this</p> <p><code>stoichiometry={\"x\": 1.0}</code></p> <p>you can use</p> <p><code>stoichiometry={\"x\": \"stoich\"}</code></p> <p>or for more advanced uses you use the <code>Derived</code> class as the value</p> <p><code>stoichiometry={\"x\": Derived(fn=constant, args=[\"stoich\"])}</code></p>"},{"location":"basics.html#simulations-time-courses","title":"Simulations: time courses\u00b6","text":"<p>Time courses are simulations over time</p> <p></p> <p>You can obtain the time course of integration using the <code>simulate</code> method. There are two ways how you can define the time points this function returns.</p> <ol> <li>supply the end time <code>t_end</code></li> <li>supply both end time and number of steps with <code>t_end</code> and <code>steps</code></li> </ol> <p>If you want to set the exact time points to be returned use <code>simulate_time_course</code></p> <pre>simulate(t_end=10)\nsimulate(t_end=10, steps=10)\nsimulate_time_course(np.linspace(0, 10, 11))\n</pre>"},{"location":"basics.html#simulations-protocol-time-course","title":"Simulations: protocol time course\u00b6","text":"<p>Protocols are used to make parameter changes discrete in time, such as turning a light on and off. This is useful reproducing experimental time courses where a parameter was changed at fixed time points.</p> <p></p> <p>The protocol is defined as a <code>pandas.DataFrame</code> using <code>pd.Timedelta</code> values as in index, and the parameter values at the respective time interval as values.</p> pd.Timedelta p1 p2 0 days 00:00:01 1 0 0 days 00:00:03 2 1 0 days 00:00:06 1 2 <p>You can use as many parameters as you want.</p> <p>Note mxlpy assigns one second of the <code>Timedelta</code> to one time unit of the integration. mxlpy does not take into account whether your integration might use a different time unit.</p> <p>For convenience, we supply the <code>make_protocol</code> function, which takes in a pair of the duration of the time-step on the respective parameter values.</p>"},{"location":"basics.html#simulations-steady-state","title":"Simulations: steady-state\u00b6","text":"<p>A steady-state describes a state at which the concentrations of the system don't change anymore (also called fixed points).</p> <p></p> <p>You can simulate until the model reaches a steady-state using the <code>simulate_to_steady_state</code> method.</p>"},{"location":"basics.html#sbml","title":"SBML\u00b6","text":"<p>The systems biology markup language (SBML) is a widely used file format for sharing models between different software packages and programming languages.</p> <p><code>mxlpy</code> supports reading and writing sbml models using the <code>sbml.read</code> and <code>sbml.write</code> functions.</p>"},{"location":"basics.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"basics.html#time-dependent-reactions","title":"Time-dependent reactions\u00b6","text":"<p>You can use the special name <code>time</code> to refer to the actual integration time in the rare case a reaction or module depends on it explicitly. This is why the methods <code>get_args</code>, <code>get_fluxes</code> etc. also take an additional <code>time</code> argument.</p>"},{"location":"basics.html#derived-parameters-and-variables","title":"Derived parameters and variables\u00b6","text":"<p>Internally mxlpy differentiates between derived parameters and derived variables. This differentiation is just-in-time before any calculation and thus might change if you change the nature of a parameter / variable.</p> <p>If you are interested in which category mxlpy has placed the derived quantities, you can access <code>.derived_parameters</code> and <code>.derived_variables</code> as well.</p>"},{"location":"basics.html#data","title":"Data\u00b6","text":"<p>You can add references to data using <code>add_data</code>. That way, you can, for example, dynamically derive aggregates over them.</p>"},{"location":"carousel.html","title":"Reaction carousel","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom mxlpy import Model, Simulator, fit, fns, plot, unwrap\nfrom mxlpy.carousel import Carousel, ReactionTemplate\n\n\ndef get_sir() -&gt; Model:\n    \"\"\"Create a simple SIR model.\"\"\"\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\ncarousel = Carousel(\n    get_sir(),\n    {\n        \"infection\": [\n            ReactionTemplate(fn=fns.mass_action_2s, args=[\"s\", \"i\", \"beta\"]),\n            ReactionTemplate(\n                fn=fns.michaelis_menten_2s,\n                args=[\"s\", \"i\", \"beta\", \"km_bs\", \"km_bi\"],\n                additional_parameters={\"km_bs\": 0.1, \"km_bi\": 1.0},\n            ),\n        ],\n        \"recovery\": [\n            ReactionTemplate(fn=fns.mass_action_1s, args=[\"i\", \"gamma\"]),\n            ReactionTemplate(\n                fn=fns.michaelis_menten_1s,\n                args=[\"i\", \"gamma\", \"km_gi\"],\n                additional_parameters={\"km_gi\": 0.1},\n            ),\n        ],\n    },\n)\n</pre> import numpy as np  from mxlpy import Model, Simulator, fit, fns, plot, unwrap from mxlpy.carousel import Carousel, ReactionTemplate   def get_sir() -&gt; Model:     \"\"\"Create a simple SIR model.\"\"\"     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   carousel = Carousel(     get_sir(),     {         \"infection\": [             ReactionTemplate(fn=fns.mass_action_2s, args=[\"s\", \"i\", \"beta\"]),             ReactionTemplate(                 fn=fns.michaelis_menten_2s,                 args=[\"s\", \"i\", \"beta\", \"km_bs\", \"km_bi\"],                 additional_parameters={\"km_bs\": 0.1, \"km_bi\": 1.0},             ),         ],         \"recovery\": [             ReactionTemplate(fn=fns.mass_action_1s, args=[\"i\", \"gamma\"]),             ReactionTemplate(                 fn=fns.michaelis_menten_1s,                 args=[\"i\", \"gamma\", \"km_gi\"],                 additional_parameters={\"km_gi\": 0.1},             ),         ],     }, ) In\u00a0[2]: Copied! <pre>carousel_time_course = carousel.time_course(np.linspace(0, 100, 101))\nvariables_by_model = carousel_time_course.get_variables_by_model()\n\nfig, ax = plot.one_axes()\nplot.line_mean_std(variables_by_model[\"s\"].unstack().T, label=\"s\", ax=ax)\nplot.line_mean_std(variables_by_model[\"i\"].unstack().T, label=\"i\", ax=ax)\nplot.line_mean_std(variables_by_model[\"r\"].unstack().T, label=\"r\", ax=ax)\nax.legend()\nplot.show()\n</pre> carousel_time_course = carousel.time_course(np.linspace(0, 100, 101)) variables_by_model = carousel_time_course.get_variables_by_model()  fig, ax = plot.one_axes() plot.line_mean_std(variables_by_model[\"s\"].unstack().T, label=\"s\", ax=ax) plot.line_mean_std(variables_by_model[\"i\"].unstack().T, label=\"i\", ax=ax) plot.line_mean_std(variables_by_model[\"r\"].unstack().T, label=\"r\", ax=ax) ax.legend() plot.show() <pre>\r  0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 1/4 [00:00&lt;00:00,  9.73it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 25.36it/s]</pre> <pre>\n</pre> In\u00a0[3]: Copied! <pre>data = unwrap(\n    Simulator(get_sir().update_parameters({\"beta\": 0.3, \"gamma\": 0.15}))\n    .simulate(100, steps=11)\n    .get_result()\n).variables\n\ndata.head()\n</pre> data = unwrap(     Simulator(get_sir().update_parameters({\"beta\": 0.3, \"gamma\": 0.15}))     .simulate(100, steps=11)     .get_result() ).variables  data.head() Out[3]: s i r 0.000000 0.900000 0.100000 0.000000 9.090909 0.590585 0.198774 0.210641 18.181818 0.344478 0.175340 0.480182 27.272727 0.238034 0.096976 0.664990 36.363636 0.197740 0.044539 0.757722 In\u00a0[4]: Copied! <pre>res = fit.carousel_time_course(\n    carousel,\n    p0={\n        \"beta\": 0.1,\n        \"gamma\": 0.1,\n        # specific to reaction templates\n        # \"km_bi\": 1.0,\n    },\n    data=data,\n)\n\nbest = res.get_best_fit().model\n\nfig, ax = plot.one_axes()\nplot.lines(\n    unwrap(Simulator(best).simulate(100).get_result()).variables,\n    ax=ax,\n)\nplot.reset_prop_cycle(ax=ax)\nplot.lines(data, linestyle=\"dashed\", ax=ax, legend=False)\nplot.show()\n</pre> res = fit.carousel_time_course(     carousel,     p0={         \"beta\": 0.1,         \"gamma\": 0.1,         # specific to reaction templates         # \"km_bi\": 1.0,     },     data=data, )  best = res.get_best_fit().model  fig, ax = plot.one_axes() plot.lines(     unwrap(Simulator(best).simulate(100).get_result()).variables,     ax=ax, ) plot.reset_prop_cycle(ax=ax) plot.lines(data, linestyle=\"dashed\", ax=ax, legend=False) plot.show() <pre>\r  0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 1/4 [00:07&lt;00:23,  7.75s/it]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 3/4 [00:10&lt;00:03,  3.17s/it]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:10&lt;00:00,  2.74s/it]</pre> <pre>\n</pre> In\u00a0[5]: Copied! <pre>best_fit = res.get_best_fit()\n\nprint(best_fit.best_pars)\nprint([rxn.fn.__name__ for rxn in best_fit.model.reactions.values()])\n</pre> best_fit = res.get_best_fit()  print(best_fit.best_pars) print([rxn.fn.__name__ for rxn in best_fit.model.reactions.values()]) <pre>{'beta': np.float64(0.30825359997952245), 'gamma': np.float64(0.03983034955062395)}\n['mass_action_2s', 'michaelis_menten_1s']\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"carousel.html#simulate-carousel-ensemble","title":"Simulate carousel ensemble\u00b6","text":""},{"location":"carousel.html#fitting","title":"Fitting\u00b6","text":""},{"location":"citing.html","title":"Citing","text":"<p>If you use this software in your scientific work, please cite this article:</p> <ul> <li>doi</li> <li>bibtex file</li> </ul>"},{"location":"comparisons.html","title":"Comparing models","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom example_models import get_sir, get_sird\nfrom mxlpy import compare, make_protocol\n</pre> import numpy as np  from example_models import get_sir, get_sird from mxlpy import compare, make_protocol In\u00a0[2]: Copied! <pre>ssc = compare.steady_states(get_sir(), get_sird())\n</pre> ssc = compare.steady_states(get_sir(), get_sird()) <p>This returns a <code>SteadyStateComparison</code> object, for which you can either access the direct comparisons</p> In\u00a0[3]: Copied! <pre>ssc.variables\n</pre> ssc.variables Out[3]: m1 m2 diff rel_diff d NaN 7.121887e-02 NaN NaN i 6.676138e-12 3.794859e-12 -2.881278e-12 -0.431579 r 8.282883e-01 7.121887e-01 -1.160997e-01 -0.140168 s 1.717117e-01 2.165925e-01 4.488079e-02 0.261373 In\u00a0[4]: Copied! <pre>ssc.fluxes\n</pre> ssc.fluxes Out[4]: m1 m2 diff rel_diff death NaN 3.794859e-14 NaN NaN infection 2.292742e-13 1.643876e-13 -6.488657e-14 -0.283009 recovery 6.676138e-13 3.794859e-13 -2.881278e-13 -0.431579 <p>or plot the results</p> In\u00a0[5]: Copied! <pre>_ = ssc.plot_variables()\n_ = ssc.plot_fluxes()\n_ = ssc.plot_all()\n</pre> _ = ssc.plot_variables() _ = ssc.plot_fluxes() _ = ssc.plot_all() In\u00a0[6]: Copied! <pre>pc = compare.time_courses(\n    get_sir(),\n    get_sird(),\n    time_points=np.linspace(0, 100, 101),\n)\n\n_ = pc.plot_variables_relative_difference()\n_ = pc.plot_fluxes_relative_difference()\n</pre> pc = compare.time_courses(     get_sir(),     get_sird(),     time_points=np.linspace(0, 100, 101), )  _ = pc.plot_variables_relative_difference() _ = pc.plot_fluxes_relative_difference() In\u00a0[7]: Copied! <pre>pc = compare.protocol_time_courses(\n    get_sir(),\n    get_sird(),\n    protocol=make_protocol(\n        [\n            (10, {\"beta\": 0.2}),\n            (10, {\"beta\": 1.0}),\n            (80, {\"beta\": 0.2}),\n        ]\n    ),\n)\n\n_ = pc.plot_variables_relative_difference()\n</pre> pc = compare.protocol_time_courses(     get_sir(),     get_sird(),     protocol=make_protocol(         [             (10, {\"beta\": 0.2}),             (10, {\"beta\": 1.0}),             (80, {\"beta\": 0.2}),         ]     ), )  _ = pc.plot_variables_relative_difference() <p>Optionally, if you want to indicate one of the protocol parameters on the plots, you can use the <code>shade_protocol_variable</code> argument</p> In\u00a0[8]: Copied! <pre>_ = pc.plot_variables_relative_difference(shade_protocol_variable=\"beta\")\n_ = pc.plot_fluxes_relative_difference(shade_protocol_variable=\"beta\")\n</pre> _ = pc.plot_variables_relative_difference(shade_protocol_variable=\"beta\") _ = pc.plot_fluxes_relative_difference(shade_protocol_variable=\"beta\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"comparisons.html#comparisons","title":"Comparisons\u00b6","text":"<p><code>mxlpy</code> provides simple routines to numerically compare two models. For this, we use the <code>compare</code> module.</p>"},{"location":"comparisons.html#steady-states","title":"Steady-states\u00b6","text":"<p>You can compare the steady-states of two models using the <code>compare_steady_states</code> function.</p>"},{"location":"comparisons.html#time-courses","title":"Time courses\u00b6","text":"<p>For comparing time courses, you can use the <code>compare_time_courses</code> function. This returns a <code>TimeCourseComparison</code> object, which you can directly use to plot for example the relative differences of variables or fluxes.</p>"},{"location":"comparisons.html#protocol-time-courses","title":"Protocol time courses\u00b6","text":"<p>For comparing protocol time courses, you can use the <code>protocol_time_courses</code> function. This returns a <code>ProtocolComparison</code> object, which you can directly use to plot for example the relative differences of variables or fluxes.</p>"},{"location":"examples.html","title":"Examples","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\nfrom mxlpy import Model, Simulator, fns, plot, unwrap\n</pre> import matplotlib.pyplot as plt  from mxlpy import Model, Simulator, fns, plot, unwrap In\u00a0[2]: Copied! <pre>def sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\nres = unwrap(Simulator(sir()).simulate(100).get_result())\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5))\n_ = plot.lines(res.variables, ax=ax1)\n_ = plot.lines(res.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\nax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\")\nplt.show()\n</pre> def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   res = unwrap(Simulator(sir()).simulate(100).get_result())  fig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5)) _ = plot.lines(res.variables, ax=ax1) _ = plot.lines(res.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\") ax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\") plt.show() <p>We can now easily extend the original model by adding an additional compartment and transition.</p> <p>The SIRD model for example differentiates between recovered and deceased individuals.</p> <p>So there exists an additional compartment for deceased individuals and a transition for infected to deceased individuals, proportional to the amount of infected individuals and the mortality $\\mu$ of the infection: $\\mu I$</p> In\u00a0[3]: Copied! <pre>def sird() -&gt; Model:\n    return (\n        sir()\n        .add_variable(\"d\", 0.0)\n        .add_parameter(\"mu\", 0.01)\n        .add_reaction(\n            \"death\",\n            fns.mass_action_1s,\n            args=[\"i\", \"mu\"],\n            stoichiometry={\"i\": -1, \"d\": 1},\n        )\n    )\n\n\nres = unwrap(Simulator(sird()).simulate(100).get_result())\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5))\n_ = plot.lines(res.variables, ax=ax1)\n_ = plot.lines(res.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\nax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\")\nplt.show()\n</pre> def sird() -&gt; Model:     return (         sir()         .add_variable(\"d\", 0.0)         .add_parameter(\"mu\", 0.01)         .add_reaction(             \"death\",             fns.mass_action_1s,             args=[\"i\", \"mu\"],             stoichiometry={\"i\": -1, \"d\": 1},         )     )   res = unwrap(Simulator(sird()).simulate(100).get_result())  fig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5)) _ = plot.lines(res.variables, ax=ax1) _ = plot.lines(res.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\") ax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples.html#sir-and-sird-models","title":"SIR and SIRD models\u00b6","text":"<p>In epidemiology, compartmental models are often applied to model infectious diseases.</p> <p>Common compartments include ones for Susceptible, Infectious and Recovered individuals, which are included in the SIR model.</p> <p>In this model there are two transitions (<code>reactions</code> in mxlpy) between those compartments.</p> <ul> <li>susceptible individuals can become infected by contact with an infected person: $\\beta S  I$</li> <li>infected people can recover with a rate proportional: $\\gamma I$</li> </ul> <p>These transitions are scaled by the average number of contacts per person per time ($\\beta$) and the inverse of the average infection time $\\gamma$.</p>"},{"location":"fitting.html","title":"Fitting","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import minimize\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy import Simulator, fit, make_protocol, plot, unwrap\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize  from example_models import get_linear_chain_2v from mxlpy import Simulator, fit, make_protocol, plot, unwrap In\u00a0[2]: Copied! <pre># As a small trick, let's define a variable for the model function\n# That way, we can re-use it all over the file and easily replace\n# it with another model\nmodel_fn = get_linear_chain_2v\n\nres = unwrap(\n    Simulator(model_fn())\n    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n    .simulate_time_course(np.linspace(0, 10, 101))\n    .get_result()\n).get_combined()\n\nfig, ax = plot.lines(res)\nax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\")\nplt.show()\n</pre> # As a small trick, let's define a variable for the model function # That way, we can re-use it all over the file and easily replace # it with another model model_fn = get_linear_chain_2v  res = unwrap(     Simulator(model_fn())     .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})     .simulate_time_course(np.linspace(0, 10, 101))     .get_result() ).get_combined()  fig, ax = plot.lines(res) ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\") plt.show() In\u00a0[3]: Copied! <pre>data = res.iloc[-1]\ndata.head()\n</pre> data = res.iloc[-1] data.head() Out[3]: <pre>x     0.500000\ny     1.000045\nv1    1.000000\nv2    1.000000\nv3    1.000045\nName: 10.0, dtype: float64</pre> In\u00a0[4]: Copied! <pre>fit_result = unwrap(\n    fit.steady_state(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=res.iloc[-1],\n    )\n)\n\nfit_result.best_pars\n</pre> fit_result = unwrap(     fit.steady_state(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=res.iloc[-1],     ) )  fit_result.best_pars Out[4]: <pre>{'k1': np.float64(1.000015202475239),\n 'k2': np.float64(2.0000309249184327),\n 'k3': np.float64(0.9999697802169417)}</pre> <p>If only some of the data is required, you can use a subset of it. The fitting routine will only try to fit concentrations and fluxes contained in that series.</p> In\u00a0[5]: Copied! <pre>fit_result = unwrap(\n    fit.steady_state(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=data.loc[[\"x\", \"y\"]],\n    )\n)\nfit_result.best_pars\n</pre> fit_result = unwrap(     fit.steady_state(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=data.loc[[\"x\", \"y\"]],     ) ) fit_result.best_pars Out[5]: <pre>{'k1': np.float64(0.9829433889293213),\n 'k2': np.float64(1.9658867533095319),\n 'k3': np.float64(0.9828987681888647)}</pre> In\u00a0[6]: Copied! <pre>fit_result = unwrap(\n    fit.time_course(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=res,\n    )\n)\n\nfit_result.best_pars\n</pre> fit_result = unwrap(     fit.time_course(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=res,     ) )  fit_result.best_pars Out[6]: <pre>{'k1': np.float64(0.9999999948101959),\n 'k2': np.float64(1.9999999615864308),\n 'k3': np.float64(0.9999999922253802)}</pre> In\u00a0[7]: Copied! <pre>protocol = make_protocol(\n    [\n        (1, {\"k1\": 1.0}),\n        (1, {\"k1\": 2.0}),\n        (1, {\"k1\": 1.0}),\n    ]\n)\n\nres_protocol = unwrap(\n    Simulator(model_fn())\n    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n    .simulate_over_protocol(\n        protocol,\n        time_points_per_step=10,\n    )\n    .get_result()\n).get_combined()\n\nfig, ax = plot.lines(res_protocol)\nax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\")\nplt.show()\n</pre> protocol = make_protocol(     [         (1, {\"k1\": 1.0}),         (1, {\"k1\": 2.0}),         (1, {\"k1\": 1.0}),     ] )  res_protocol = unwrap(     Simulator(model_fn())     .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})     .simulate_over_protocol(         protocol,         time_points_per_step=10,     )     .get_result() ).get_combined()  fig, ax = plot.lines(res_protocol) ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\") plt.show() <p>For the protocol time course fit we need three inputs</p> <ol> <li>an initial parameter guess</li> <li>the time course data, which we supply as a <code>pandas.DataFrame</code></li> <li>the protocol, which we supply as a <code>pandas.DataFrame</code></li> </ol> <p>Note that the parameter given by the protocol cannot be fitted anymore</p> <p>In contrast to the other fitting routines, there is another important distinction</p> <p>The routine will only compare the time points of the supplied <code>data</code> with the ones created by the simulation if they match. You can use the <code>time_points_per_step</code> argument to create more points in between or make sure that for every data point that you have there is a corresponding point in the protocol. That way, you can guarantee that the point will be compared against</p> In\u00a0[8]: Copied! <pre>fit_result = unwrap(\n    fit.time_course_over_protocol(\n        model_fn(),\n        p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol\n        data=res_protocol,\n        protocol=protocol,\n        time_points_per_step=10,\n    )\n)\n\nfit_result.best_pars\n</pre> fit_result = unwrap(     fit.time_course_over_protocol(         model_fn(),         p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol         data=res_protocol,         protocol=protocol,         time_points_per_step=10,     ) )  fit_result.best_pars Out[8]: <pre>{'k2': np.float64(1.9999999995061162), 'k3': np.float64(1.000000000653317)}</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about fitting in mxlpy.           Congratulations!  In\u00a0[9]: Copied! <pre>from functools import partial\nfrom typing import TYPE_CHECKING, cast\n\nfrom mxlpy.fit import LossFn\nfrom mxlpy.integrators import Scipy\n\nif TYPE_CHECKING:\n    import pandas as pd\n\n    from mxlpy.fit import ResidualFn\n    from mxlpy.model import Model\n    from mxlpy.types import Array, IntegratorType\n</pre> from functools import partial from typing import TYPE_CHECKING, cast  from mxlpy.fit import LossFn from mxlpy.integrators import Scipy  if TYPE_CHECKING:     import pandas as pd      from mxlpy.fit import ResidualFn     from mxlpy.model import Model     from mxlpy.types import Array, IntegratorType In\u00a0[10]: Copied! <pre>def mean_absolute_error(\n    x: pd.DataFrame | pd.Series,\n    y: pd.DataFrame | pd.Series,\n) -&gt; float:\n    \"\"\"Mean absolute error between two dataframes.\"\"\"\n    return cast(float, np.mean(np.abs(x - y)))\n\n\nfit.time_course(\n    model_fn(),\n    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n    data=res,\n    loss_fn=mean_absolute_error,\n)\n</pre> def mean_absolute_error(     x: pd.DataFrame | pd.Series,     y: pd.DataFrame | pd.Series, ) -&gt; float:     \"\"\"Mean absolute error between two dataframes.\"\"\"     return cast(float, np.mean(np.abs(x - y)))   fit.time_course(     model_fn(),     p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},     data=res,     loss_fn=mean_absolute_error, ) Out[10]: <pre>FitResult(model=Model(_ids={'x': 'variable', 'y': 'variable', 'k1': 'parameter', 'k2': 'parameter', 'k3': 'parameter', 'v1': 'reaction', 'v2': 'reaction', 'v3': 'reaction'}, _variables={'x': 1.0, 'y': 1.0}, _parameters={'k1': np.float64(0.9999999602399153), 'k2': np.float64(1.999999919411726), 'k3': np.float64(0.9999999475129249)}, _derived={}, _readouts={}, _reactions={'v1': Reaction(fn=&lt;function constant at 0x7f8538cba200&gt;, stoichiometry={'x': 1}, args=['k1']), 'v2': Reaction(fn=&lt;function mass_action_1s at 0x7f8538cba980&gt;, stoichiometry={'x': -1, 'y': 1}, args=['k2', 'x']), 'v3': Reaction(fn=&lt;function mass_action_1s at 0x7f8538cba980&gt;, stoichiometry={'y': -1}, args=['k3', 'y'])}, _surrogates={}, _cache=None, _data={}), best_pars={'k1': np.float64(0.9999999602399153), 'k2': np.float64(1.999999919411726), 'k3': np.float64(0.9999999475129249)}, loss=np.float64(2.7234822410494783e-08))</pre> In\u00a0[11]: Copied! <pre>fit_result = unwrap(\n    fit.time_course(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=res,\n        integrator=partial(Scipy, rtol=1e-6, atol=1e-6),\n    )\n)\n\nfit_result.best_pars\n</pre> fit_result = unwrap(     fit.time_course(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=res,         integrator=partial(Scipy, rtol=1e-6, atol=1e-6),     ) )  fit_result.best_pars Out[11]: <pre>{'k1': np.float64(0.9999999887485048),\n 'k2': np.float64(2.0000000418475845),\n 'k3': np.float64(0.9999999287055419)}</pre> In\u00a0[12]: Copied! <pre>from mxlpy.fit import MinResult\n\n\ndef nelder_mead(\n    residual_fn: ResidualFn,\n    p0: dict[str, float],\n) -&gt; MinResult | None:\n    res = minimize(\n        residual_fn,\n        x0=list(p0.values()),\n        method=\"Nelder-Mead\",\n    )\n    if res.success:\n        return MinResult(\n            parameters=dict(\n                zip(\n                    p0,\n                    res.x,\n                    strict=True,\n                )\n            ),\n            residual=res.fun,\n        )\n    return None\n\n\nfit_result = unwrap(\n    fit.time_course(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=res,\n        minimize_fn=nelder_mead,\n    )\n)\n\nfit_result.best_pars\n</pre> from mxlpy.fit import MinResult   def nelder_mead(     residual_fn: ResidualFn,     p0: dict[str, float], ) -&gt; MinResult | None:     res = minimize(         residual_fn,         x0=list(p0.values()),         method=\"Nelder-Mead\",     )     if res.success:         return MinResult(             parameters=dict(                 zip(                     p0,                     res.x,                     strict=True,                 )             ),             residual=res.fun,         )     return None   fit_result = unwrap(     fit.time_course(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=res,         minimize_fn=nelder_mead,     ) )  fit_result.best_pars Out[12]: <pre>{'k1': np.float64(1.0000044128393781),\n 'k2': np.float64(1.9999586259064912),\n 'k3': np.float64(1.000005095705572)}</pre> In\u00a0[13]: Copied! <pre>def time_course_residual(\n    par_values: Array,\n    # This will be filled out by partial\n    par_names: list[str],\n    data: pd.DataFrame,\n    model: Model,\n    y0: dict[str, float] | None,\n    integrator: IntegratorType,\n    loss_fn: LossFn,\n) -&gt; float:\n    \"\"\"Calculate residual error between model time course and experimental data.\n\n    Args:\n        par_values: Parameter values to test\n        data: Experimental time course data\n        model: Model instance to simulate\n        y0: Initial conditions\n        par_names: Names of parameters being fit\n        integrator: ODE integrator class to use\n        loss_fn: Loss function to use for residual calculation\n\n    Returns:\n        float: Root mean square error between model and data\n\n    \"\"\"\n    res = (\n        Simulator(\n            model.update_parameters(dict(zip(par_names, par_values, strict=True))),\n            y0=y0,\n            integrator=integrator,\n        )\n        .simulate_time_course(cast(list, data.index))\n        .get_result()\n    )\n    if res is None:\n        return cast(float, np.inf)\n    results_ss = res.get_combined()\n\n    return loss_fn(\n        results_ss.loc[:, cast(list, data.columns)],\n        data,\n    )\n\n\nfit_result = unwrap(\n    fit.time_course(\n        model_fn(),\n        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n        data=res,\n        residual_fn=time_course_residual,\n    )\n)\n\nfit_result.best_pars\n</pre> def time_course_residual(     par_values: Array,     # This will be filled out by partial     par_names: list[str],     data: pd.DataFrame,     model: Model,     y0: dict[str, float] | None,     integrator: IntegratorType,     loss_fn: LossFn, ) -&gt; float:     \"\"\"Calculate residual error between model time course and experimental data.      Args:         par_values: Parameter values to test         data: Experimental time course data         model: Model instance to simulate         y0: Initial conditions         par_names: Names of parameters being fit         integrator: ODE integrator class to use         loss_fn: Loss function to use for residual calculation      Returns:         float: Root mean square error between model and data      \"\"\"     res = (         Simulator(             model.update_parameters(dict(zip(par_names, par_values, strict=True))),             y0=y0,             integrator=integrator,         )         .simulate_time_course(cast(list, data.index))         .get_result()     )     if res is None:         return cast(float, np.inf)     results_ss = res.get_combined()      return loss_fn(         results_ss.loc[:, cast(list, data.columns)],         data,     )   fit_result = unwrap(     fit.time_course(         model_fn(),         p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},         data=res,         residual_fn=time_course_residual,     ) )  fit_result.best_pars Out[13]: <pre>{'k1': np.float64(0.9999999948101959),\n 'k2': np.float64(1.9999999615864308),\n 'k3': np.float64(0.9999999922253802)}</pre>"},{"location":"fitting.html#fitting","title":"Fitting\u00b6","text":"<p>Almost every model at some point needs to be fitted to experimental data to be validated.</p> <p>mxlpy offers highly customisable routines for fitting either time series or steady-states.</p> <p></p> <p>For this tutorial we are going to use the <code>fit</code> module to optimise our parameter values and the <code>plot</code> module to plot some results.</p> <p>Let's get started!</p>"},{"location":"fitting.html#creating-synthetic-data","title":"Creating synthetic data\u00b6","text":"<p>Normally, you would fit your model to experimental data. Here, for the sake of simplicity, we will generate some synthetic data.</p> <p>Checkout the basics tutorial if you need a refresher on building and simulating models.</p>"},{"location":"fitting.html#steady-states","title":"Steady-states\u00b6","text":"<p>For the steady-state fit we need two inputs:</p> <ol> <li>the steady state data, which we supply as a <code>pandas.Series</code></li> <li>an initial parameter guess</li> </ol> <p>The fitting routine will compare all data contained in that series to the model output.</p> <p>Note that the data both contains concentrations and fluxes!</p>"},{"location":"fitting.html#time-course","title":"Time course\u00b6","text":"<p>For the time course fit we need again need two inputs</p> <ol> <li>the time course data, which we supply as a <code>pandas.DataFrame</code></li> <li>an initial parameter guess</li> </ol> <p>The fitting routine will create data at every time points specified in the <code>DataFrame</code> and compare all of them.</p> <p>Other than that, the same rules of the steady-state fitting apply.</p>"},{"location":"fitting.html#protcol-time-courses","title":"Protcol time courses\u00b6","text":"<p>Normally, you would fit your model to experimental data. Here, again, for the sake of simplicity, we will generate some synthetic data.</p>"},{"location":"fitting.html#advanced-topics-customisation","title":"Advanced topics / customisation\u00b6","text":"<p>All fitting routines internally are build in a way that they will call a tree of functions.</p> <ul> <li><code>minimize_fn</code><ul> <li><code>residual_fn</code><ul> <li><code>integrator</code></li> <li><code>loss_fn</code></li> </ul> </li> </ul> </li> </ul> <p>You can therefore use dependency injection to overwrite the minimisation function, the loss function, the residual function and the integrator if need be.</p>"},{"location":"fitting.html#custom-loss-function","title":"Custom loss function\u00b6","text":"<p>You can change the loss function that is being passed to the minimsation function using the <code>loss_fn</code> keyword. Depending on the use case (time course vs steady state) this function will be passed two pandas <code>DataFrame</code>s or <code>Series</code>.</p>"},{"location":"fitting.html#custom-integrator","title":"Custom integrator\u00b6","text":"<p>You can change the default integrator to an integrator of your choice by partially application of the class of any of the existing ones.</p> <p>Here, for example, we choose the <code>Scipy</code> solver suite and set the default relative and absolute tolerances to <code>1e-6</code> respectively.</p>"},{"location":"fitting.html#custom-minimisation","title":"Custom minimisation\u00b6","text":"<p>You can change the default <code>minimize_fn</code> from <code>L-BFGS-B</code> to any other function that takes a <code>ResidualFn</code> and minimizes it.</p>"},{"location":"fitting.html#custom-residual-function","title":"Custom residual function\u00b6","text":"<p>You can change the residual function to include further behaviour.</p> <p>The barebones implementation is given below</p>"},{"location":"integrators.html","title":"Integrator configuration","text":"In\u00a0[1]: Copied! <pre>from functools import partial\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy import Simulator, unwrap\nfrom mxlpy.integrators import Scipy\n\nmodel = get_linear_chain_2v()\n\n# You can explicitly set an integrator for the simulation\ns = Simulator(model, integrator=Scipy)\n\n# You can also change the default settings of each integrator\ns = Simulator(model, integrator=partial(Scipy, atol=1e-6, rtol=1e-6))\ns.simulate(5)\n\n# You can change integration settings mid simulation\n# As not all integrators have the same settings, we recommend explicitly checking\n# which integrator is currently set\nif isinstance(s.integrator, Scipy):\n    s.integrator.atol = 1e-8  # set absolute tolerance\n    s.integrator.rtol = 1e-8  # set relative tolerance\n\nunwrap(s.simulate(10).get_result()).variables.plot()\n</pre> from functools import partial  from example_models import get_linear_chain_2v from mxlpy import Simulator, unwrap from mxlpy.integrators import Scipy  model = get_linear_chain_2v()  # You can explicitly set an integrator for the simulation s = Simulator(model, integrator=Scipy)  # You can also change the default settings of each integrator s = Simulator(model, integrator=partial(Scipy, atol=1e-6, rtol=1e-6)) s.simulate(5)  # You can change integration settings mid simulation # As not all integrators have the same settings, we recommend explicitly checking # which integrator is currently set if isinstance(s.integrator, Scipy):     s.integrator.atol = 1e-8  # set absolute tolerance     s.integrator.rtol = 1e-8  # set relative tolerance  unwrap(s.simulate(10).get_result()).variables.plot() Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"integrators.html#integrator-configuration","title":"Integrator configuration\u00b6","text":"<p>You can explicitly control which integrator is used for the simulations. As all integrators have different settings, changing them is done on the integrator object itself, which can be found at <code>Simulator().integrator</code>.</p> <p>By default, the <code>Assimulo</code> integrator is used. However, that package currenlty requires installation via <code>conda-forge</code>. If <code>mxlpy</code> was installed from <code>pypi</code>, this package is not available and <code>mxlpy</code> will fall back to the <code>Scipy</code> package. Thus, when setting integrator settings you should always check which integrator you are actually working with, as this otherwise might lead bugs on other systems.</p>"},{"location":"label-models.html","title":"Label models","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom typing import Any\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_linear_chain_2v, get_tpi_ald_model\nfrom mxlpy import (\n    LabelMapper,\n    LinearLabelMapper,\n    Simulator,\n    plot,\n    unwrap,\n)\n\n\ndef print_annotated(description: str, value: Any) -&gt; None:\n    print(\n        description,\n        value,\n        sep=\"\\n\",\n        end=\"\\n\\n\",\n    )\n</pre> from __future__ import annotations  from typing import Any  import matplotlib.pyplot as plt  from example_models import get_linear_chain_2v, get_tpi_ald_model from mxlpy import (     LabelMapper,     LinearLabelMapper,     Simulator,     plot,     unwrap, )   def print_annotated(description: str, value: Any) -&gt; None:     print(         description,         value,         sep=\"\\n\",         end=\"\\n\\n\",     ) In\u00a0[2]: Copied! <pre>mapper = LabelMapper(\n    get_tpi_ald_model(),\n    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n    label_maps={\n        \"TPIf\": [2, 1, 0],\n        \"TPIr\": [2, 1, 0],\n        \"ALDf\": [0, 1, 2, 3, 4, 5],\n        \"ALDr\": [0, 1, 2, 3, 4, 5],\n    },\n)\n\n\nlabels = unwrap(\n    Simulator(mapper.build_model(initial_labels={\"GAP\": 0})).simulate(20).get_result()\n).variables\n\nfig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3)\nplt.show()\n</pre> mapper = LabelMapper(     get_tpi_ald_model(),     label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},     label_maps={         \"TPIf\": [2, 1, 0],         \"TPIr\": [2, 1, 0],         \"ALDf\": [0, 1, 2, 3, 4, 5],         \"ALDr\": [0, 1, 2, 3, 4, 5],     }, )   labels = unwrap(     Simulator(mapper.build_model(initial_labels={\"GAP\": 0})).simulate(20).get_result() ).variables  fig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3) plt.show() In\u00a0[3]: Copied! <pre>model_fn = get_tpi_ald_model()\n\nconcs, fluxes = unwrap(Simulator(model_fn).simulate(20).get_result())\n\n\nmapper = LinearLabelMapper(\n    model=model_fn,\n    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n    label_maps={\n        \"TPIf\": [2, 1, 0],\n        \"TPIr\": [2, 1, 0],\n        \"ALDf\": [0, 1, 2, 3, 4, 5],\n        \"ALDr\": [0, 1, 2, 3, 4, 5],\n    },\n)\n\n\nlabels = unwrap(\n    Simulator(\n        mapper.build_model(\n            concs=concs.iloc[-1],\n            fluxes=fluxes.iloc[-1],\n            initial_labels={\"GAP\": 0},\n        )\n    )\n    .simulate(20)\n    .get_result()\n).variables\nfig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3)\nplt.show()\n</pre> model_fn = get_tpi_ald_model()  concs, fluxes = unwrap(Simulator(model_fn).simulate(20).get_result())   mapper = LinearLabelMapper(     model=model_fn,     label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},     label_maps={         \"TPIf\": [2, 1, 0],         \"TPIr\": [2, 1, 0],         \"ALDf\": [0, 1, 2, 3, 4, 5],         \"ALDr\": [0, 1, 2, 3, 4, 5],     }, )   labels = unwrap(     Simulator(         mapper.build_model(             concs=concs.iloc[-1],             fluxes=fluxes.iloc[-1],             initial_labels={\"GAP\": 0},         )     )     .simulate(20)     .get_result() ).variables fig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3) plt.show() First finish line     With that you now know most of what you will need from a day-to-day basis about labelled models in mxlpy.           Congratulations!  In\u00a0[4]: Copied! <pre>model = get_linear_chain_2v()\nconcs, fluxes = unwrap(Simulator(model).simulate(100).get_result())\nmapper = LinearLabelMapper(\n    model,\n    label_variables={\"x\": 2, \"y\": 2},\n    label_maps={\n        \"v1\": [0, 1],\n        \"v2\": [0, 1],\n        \"v3\": [0, 1],\n    },\n)\n\nlabel_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n)\n\n# Access the external label pool\nprint(label_model.parameters[\"EXT\"])\n\n# A reaction that consumes the external label pool\nprint(label_model.reactions[\"v1__0\"].args)\n\n# A reaction that doesn't require the external label pool\nprint(label_model.reactions[\"v2__0\"].args)\n</pre> model = get_linear_chain_2v() concs, fluxes = unwrap(Simulator(model).simulate(100).get_result()) mapper = LinearLabelMapper(     model,     label_variables={\"x\": 2, \"y\": 2},     label_maps={         \"v1\": [0, 1],         \"v2\": [0, 1],         \"v3\": [0, 1],     }, )  label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1], )  # Access the external label pool print(label_model.parameters[\"EXT\"])  # A reaction that consumes the external label pool print(label_model.reactions[\"v1__0\"].args)  # A reaction that doesn't require the external label pool print(label_model.reactions[\"v2__0\"].args) <pre>1.0\n['EXT', 'v1']\n['x__0', 'v2']\n</pre> <p>You can modify the external concentration to your liking by simply updating the parameter value.</p> In\u00a0[5]: Copied! <pre>fig, ax = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model)\n        .update_parameter(\"EXT\", 1.0)  # update exeternal label to fully labelled\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"Fully labelled external pool\")\nplt.show()\n</pre> fig, ax = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model)         .update_parameter(\"EXT\", 1.0)  # update exeternal label to fully labelled         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"Fully labelled external pool\") plt.show() In\u00a0[6]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model)\n        .update_parameter(\"EXT\", 0.5)  # update external label to half labelled\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"Half labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model)         .update_parameter(\"EXT\", 0.5)  # update external label to half labelled         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"Half labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>Somewhat trivially, if you have no external label, there is no influx of labels</p> In\u00a0[7]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model).update_parameter(\"EXT\", 0.0).simulate(20).get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model).update_parameter(\"EXT\", 0.0).simulate(20).get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"No labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>However, we can imagine a scenario where some initial labels are given, even though there is no external labeling. You can achieve that by updating the initial conditions like so.</p> In\u00a0[8]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model, y0=label_model.get_initial_conditions() | {\"x__0\": 1.0})\n        .update_parameter(\"EXT\", 0.0)\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model, y0=label_model.get_initial_conditions() | {\"x__0\": 1.0})         .update_parameter(\"EXT\", 0.0)         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"No labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>For convenience, the <code>build_model</code> function also allows you to set the external labels and the initial labels. Here, <code>initial_labels</code> specifies the position at which the initial label is given.</p> In\u00a0[9]: Copied! <pre>label_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n    external_label=0.0,\n    initial_labels={\"x\": 0},\n)\n\nfig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(Simulator(label_model).simulate(20).get_result()).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No external label, but initial label in C1 of x\")\nplt.show()\n</pre> label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1],     external_label=0.0,     initial_labels={\"x\": 0}, )  fig, axs = plot.relative_label_distribution(     mapper,     unwrap(Simulator(label_model).simulate(20).get_result()).variables,     n_cols=3, ) fig.suptitle(\"No external label, but initial label in C1 of x\") plt.show() <p>You can also distribute that initial label across multiple label positions of the variable.</p> In\u00a0[10]: Copied! <pre>label_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n    external_label=0.0,\n    initial_labels={\"x\": [0, 1]},\n)\n\nfig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(Simulator(label_model).simulate(20).get_result()).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No external label, but initial label in C1 &amp; C2 of x\")\nplt.show()\n</pre> label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1],     external_label=0.0,     initial_labels={\"x\": [0, 1]}, )  fig, axs = plot.relative_label_distribution(     mapper,     unwrap(Simulator(label_model).simulate(20).get_result()).variables,     n_cols=3, ) fig.suptitle(\"No external label, but initial label in C1 &amp; C2 of x\") plt.show()"},{"location":"label-models.html#labeled-models","title":"Labeled models\u00b6","text":"<p>Labelled models allow explicitly mapping the transitions between isotopomers variables. This, for example, allows building models of the Calvin-Benson-Bassham cycle, in which each carbon atom can be labelled individually:</p> <p>mxlpy includes a <code>LabelMapper</code> that takes</p> <ul> <li>a model</li> <li>a dictionary mapping the variables to the amount of label positions they have</li> <li>a transition map</li> </ul> <p>to auto-generate all possible <code>2^n</code> variants of the variables and reaction transitions between them.</p> <p>As an example let's take triose phosphate isomerase, which catalyzes the interconversion of glyceraldehyde 3-phosphate (GAP) and dihydroxyacetone phosphate (DHAP). As illustrated below, in the case of the forward reaction the first and last carbon atoms are swapped</p> <p>So DHAP(1) is build from GAP(3), DHAP(2) from GAP(2) and DHAP(3) from GAP(1). We notate this using normal 0-based indexing as follows</p> <pre>label_maps = {\"TPIf\": [2, 1, 0]}\n</pre>"},{"location":"label-models.html#linear-label-mapper","title":"Linear label mapper\u00b6","text":"<p>The <code>LabelMapper</code> makes no assumptions about the state of the model, which causes a lot of complexity. In steady-state however, the space of possible solutions is reduced and the labelling dynamics can be represented by a set of linear differential equations. See Sokol and Portais 2015 for the theory of dynamic label propagation under the stationary assumption.</p>"},{"location":"label-models.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"label-models.html#external-initial-labels","title":"External &amp; initial labels\u00b6","text":"<p>In the case of open models, we make the assumption that there is a static pool of external labels. For example, this could be the labelled portion of ambient carbon dioxide. We denote that external label pool with <code>EXT</code> and by default set the value <code>1.0</code> to it, which means that it is fully labelled.</p>"},{"location":"mca.html","title":"MCA","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_upper_glycolysis\nfrom mxlpy import plot\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt  from example_models import get_upper_glycolysis from mxlpy import plot In\u00a0[2]: Copied! <pre>from mxlpy import mca\n</pre> from mxlpy import mca In\u00a0[3]: Copied! <pre>elas = mca.variable_elasticities(\n    get_upper_glycolysis(),\n    to_scan=[\"GLC\", \"F6P\"],\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n)\n\n_ = plot.heatmap(elas)\nplt.show()\n</pre> elas = mca.variable_elasticities(     get_upper_glycolysis(),     to_scan=[\"GLC\", \"F6P\"],     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     }, )  _ = plot.heatmap(elas) plt.show() In\u00a0[4]: Copied! <pre>elas = mca.parameter_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"k1\", \"k2\"],\n)\n\n_ = plot.heatmap(elas)\nplt.show()\n</pre> elas = mca.parameter_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"k1\", \"k2\"], )  _ = plot.heatmap(elas) plt.show() In\u00a0[5]: Copied! <pre>crcs, frcs = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n_ = plot.heatmap(crcs, ax=ax1)\n_ = plot.heatmap(frcs, ax=ax2)\nplt.show()\n</pre> crcs, frcs = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"], )  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4)) _ = plot.heatmap(crcs, ax=ax1) _ = plot.heatmap(frcs, ax=ax2) plt.show() <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:03,  1.77it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:00&lt;00:00,  6.39it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:01&lt;00:00,  6.47it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:01&lt;00:00,  6.12it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about metabolic control analysis in mxlpy.           Congratulations!  In\u00a0[6]: Copied! <pre>_ = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n    normalized=False,\n)\n</pre> _ = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],     normalized=False, ) <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:02,  2.56it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:00&lt;00:00,  7.86it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00,  9.48it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>_ = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n    displacement=1e-2,\n)\n</pre> _ = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],     displacement=1e-2, ) <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:03,  1.73it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:01&lt;00:00,  5.41it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:01&lt;00:00,  6.15it/s]</pre> <pre>\n</pre>"},{"location":"mca.html#metabolic-control-analysis","title":"Metabolic control analysis\u00b6","text":"<p>Metabolic control analysis answers the question: what happens to the concentrations and fluxes if I slightly perturb the system? It is thus a local measurement about which reactions hold the most control.</p> <p>The most common measurements are elasticities and response coefficients. The main difference between them is that response coefficients are calculated at steady-state, while elasticities can be calculated at every arbitrary state.</p> <p>All the required functionality can be found in the <code>mxlpy.mca</code> module.</p> <p>As an example, we will use the upper glycolysis model from the Systems Biology textbook by Klipp et al. (2005).</p>"},{"location":"mca.html#variable-elasticities","title":"Variable elasticities\u00b6","text":"<p>Variable elasticities are the sensitivity of reactions to a small change in the concentration of a variable. They are not a steady-state measurement and can be calculated for any arbitrary state.</p> <p></p> <p>Both the <code>concs</code> and <code>variables</code> arguments are optional. If <code>concs</code> is not supplied, the routine will use the initial conditions from the model. If <code>variables</code> is not supplied, the elasticities will be calculated for all variables.</p>"},{"location":"mca.html#parameter-elasticities","title":"Parameter elasticities\u00b6","text":"<p>Similarly, parameter elasticities are the sensitivity of reactions to a small change in the concentration of a variable. They are not a steady-state measurement and can be calculated for any arbitrary state.</p> <p></p> <p>Both the <code>concs</code> and <code>parameters</code> arguments are optional. If <code>concs</code> is not supplied, the routine will use the initial conditions from the model. If <code>parameters</code> is not supplied, the elasticities will be calculated for all parameters.</p>"},{"location":"mca.html#response-coefficients","title":"Response coefficients\u00b6","text":"<p>Response coefficients show the sensitivity of variables and reactions at steady-state to a small change in a parameter.</p> <p></p> <p>If the parameter is proportional to the rate, they are also called control coefficients.</p> <p>Calculation of these is run in parallel by default.</p>"},{"location":"mca.html#advanced-concepts-customisation","title":"Advanced concepts / customisation\u00b6","text":""},{"location":"mca.html#normalisation","title":"Normalisation\u00b6","text":"<p>By default the elasticities and response coefficients are normalised, so e.g. for the response coefficients the following is calculated:</p> <p>$$C^J_{v_i} = \\left( \\frac{dJ}{dp} \\frac{p}{J} \\right) \\bigg/ \\left( \\frac{\\partial v_i}{\\partial  p}\\frac{p}{v_i} \\right)$$</p> <p>You can also obtain the non-normalised coefficients, by setting <code>normalized=False</code>, which amounts to the following calculation:</p> <p>$$C^J_{v_i} = \\left( \\frac{dJ}{dp} \\frac{p}{J} \\right)$$</p>"},{"location":"mca.html#displacement","title":"Displacement\u00b6","text":"<p>We wrote above that we slightly change the value, but by how much exactly? By default the relative change is set to <code>1e-4</code>. <code>mxlpy</code> uses a central finite difference approximation, which means that in this case change the value to $$\\textrm{value} \\cdot \\left(1 \\pm 10^{-4} \\right)$$</p> <p>which amounts to a change of <code>0.01 %</code>.</p> <p>You can set that using the <code>displacement</code> argument.</p>"},{"location":"metaprogramming.html","title":"Metaprogramming","text":"In\u00a0[1]: Copied! <pre>from example_models import get_linear_chain_1v, get_linear_chain_2v\nfrom mxlpy.meta import (\n    generate_latex_code,\n    generate_model_code_py,\n    generate_mxlpy_code,\n)\n</pre> from example_models import get_linear_chain_1v, get_linear_chain_2v from mxlpy.meta import (     generate_latex_code,     generate_model_code_py,     generate_mxlpy_code, ) In\u00a0[2]: Copied! <pre>print(generate_mxlpy_code(get_linear_chain_1v()))\n</pre> print(generate_mxlpy_code(get_linear_chain_1v())) <pre>from mxlpy import Model\n\ndef constant(k_in: float) -&gt; float:\n    return k_in\n    \n\ndef mass_action_1s(k_out: float, x: float) -&gt; float:\n    return k_out*x\n    \ndef create_model() -&gt; Model:\n    return (\n        Model()\n        .add_parameters({'k_in': 1.0, 'k_out': 1.0})\n        .add_variables({'x': 1.0})\n        .add_reaction(\n                \"v_in\",\n                fn=constant,\n                args=['k_in'],\n                stoichiometry={\"x\": 1},\n            )\n        .add_reaction(\n                \"v_out\",\n                fn=mass_action_1s,\n                args=['k_out', 'x'],\n                stoichiometry={\"x\": -1},\n            )\n    )\n</pre> <p><code>mxlpy</code> can also generate a generic python function from the source code. The plan here is to generalise this to be able to export models into other programming languages as well.</p> In\u00a0[3]: Copied! <pre>print(generate_model_code_py(get_linear_chain_2v()))\n</pre> print(generate_model_code_py(get_linear_chain_2v())) <pre>from collections.abc import Iterable\n\nfrom mxlpy.types import Float\n\ndef model(t: Float, variables: Float) -&gt; Iterable[Float]:\n    x, y = variables\n    k1 = 1.0\n    k2 = 2.0\n    k3 = 1.0\n    v1 = k1\n    v2 = k2*x\n    v3 = k3*y\n    dxdt = v1 -v2\n    dydt = v2 -v3\n    return dxdt, dydt\n</pre> In\u00a0[4]: Copied! <pre>print(generate_latex_code(get_linear_chain_1v()))\n</pre> print(generate_latex_code(get_linear_chain_1v())) <pre>\\documentclass[fleqn]{article}\n\\usepackage[english]{babel}\n\\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}\n\\usepackage{amsmath, amssymb, array, booktabs,\n            breqn, caption, longtable, mathtools, placeins,\n            ragged2e, tabularx, titlesec, titling}\n\\newcommand{\\sectionbreak}{\\clearpage}\n\\setlength{\\parindent}{0pt}\n\\allowdisplaybreaks\n\n\\title{Model construction}\n\\date{} % clear date\n\\author{mxlpy}\n\\begin{document}\n\\maketitle\n\\FloatBarrier\\subsection*{Variables}\n\\begin{longtable}{c|c}\n    Model name &amp; Initial concentration \\\\\n    \\hline\n    \\endhead\n    x &amp; 1.00e+00 \\\\\n    \\caption[Model variables]{Model variables}\n    \\label{table:model-vars}\n\\end{longtable}\n\n\\FloatBarrier\\subsection*{Parameters}\n\\begin{longtable}{c|c}\n    Parameter name &amp; Parameter value \\\\\n    \\hline\n    \\endhead\n    k\\_in &amp; 1.00e+00 \\\\\n    k\\_out &amp; 1.00e+00 \\\\\n    \\caption[Model parameters]{Model parameters}\n    \\label{table:model-pars}\n\\end{longtable}\n\n\\FloatBarrier\\subsection*{Reactions}\n\\begin{align*}\n\\mathrm{v\\_in} &amp;= \\mathrm{k\\_in} \\\\\n\\mathrm{v\\_out} &amp;= \\mathrm{k\\_out} \\cdot \\mathrm{x} \\\\\n\\end{align*}\n\n\\FloatBarrier\\subsection*{Differential\\_equations}\n\\begin{align*}\n\\frac{d\\left(\\mathrm{x}\\right)}{dt} &amp;= v\\_{in} - v\\_{out} \\\\\n\\end{align*}\n\\end{document}\n\n</pre>"},{"location":"metaprogramming.html#metaprogramming","title":"Metaprogramming\u00b6","text":""},{"location":"metaprogramming.html#code-generation","title":"code generation\u00b6","text":"<p>Currently, the limitation here is that functions used for reactions etc. cannot call other functions.</p> <p><code>mxlpy</code> can generate own source code from a model.</p>"},{"location":"metaprogramming.html#latex-export","title":"LaTeX export\u00b6","text":"<p>Currently, the limitation here is that functions used for reactions etc. cannot call other functions.</p> <p><code>mxlpy</code> supports writing out your model as <code>LaTeX</code>.</p>"},{"location":"monte-carlo.html","title":"Monte Carlo methods","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport mxlpy as mb2\nfrom example_models import (\n    get_lin_chain_two_circles,\n    get_linear_chain_2v,\n    get_upper_glycolysis,\n)\nfrom mxlpy import make_protocol, mc, mca, plot\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np import pandas as pd  import mxlpy as mb2 from example_models import (     get_lin_chain_two_circles,     get_linear_chain_2v,     get_upper_glycolysis, ) from mxlpy import make_protocol, mc, mca, plot In\u00a0[2]: Copied! <pre>from mxlpy.distributions import LogNormal, Uniform, sample\n\nsample(\n    {\n        \"k2\": Uniform(1.0, 2.0),\n        \"k3\": LogNormal(mean=1.0, sigma=1.0),\n    },\n    n=5,\n)\n</pre> from mxlpy.distributions import LogNormal, Uniform, sample  sample(     {         \"k2\": Uniform(1.0, 2.0),         \"k3\": LogNormal(mean=1.0, sigma=1.0),     },     n=5, ) Out[2]: k2 k3 0 1.773956 0.739205 1 1.438878 3.088978 2 1.858598 1.981308 3 1.697368 2.672993 4 1.094177 1.158303 In\u00a0[3]: Copied! <pre>ss = mc.steady_state(\n    get_linear_chain_2v(),\n    mc_to_scan=sample(\n        {\n            \"k1\": Uniform(0.9, 1.1),\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5), sharex=False)\nplot.violins(ss.variables, ax=ax1)\nplot.violins(ss.fluxes, ax=ax2)\nax1.set(xlabel=\"Variables\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Reactions\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> ss = mc.steady_state(     get_linear_chain_2v(),     mc_to_scan=sample(         {             \"k1\": Uniform(0.9, 1.1),             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5), sharex=False) plot.violins(ss.variables, ax=ax1) plot.violins(ss.fluxes, ax=ax2) ax1.set(xlabel=\"Variables\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Reactions\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:00&lt;00:00, 82.56it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 68.70it/s]</pre> <pre>\n</pre> In\u00a0[4]: Copied! <pre>tc = mc.time_course(\n    get_linear_chain_2v(),\n    time_points=np.linspace(0, 1, 11),\n    mc_to_scan=sample(\n        {\n            \"k1\": Uniform(0.9, 1.1),\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tc = mc.time_course(     get_linear_chain_2v(),     time_points=np.linspace(0, 1, 11),     mc_to_scan=sample(         {             \"k1\": Uniform(0.9, 1.1),             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 72.62it/s]</pre> <pre>\n</pre> In\u00a0[5]: Copied! <pre>tc = mc.time_course_over_protocol(\n    get_linear_chain_2v(),\n    time_points_per_step=10,\n    protocol=make_protocol(\n        [\n            (1, {\"k1\": 1}),\n            (2, {\"k1\": 2}),\n            (3, {\"k1\": 1}),\n        ]\n    ),\n    mc_to_scan=sample(\n        {\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2)\nfor ax in (ax1, ax2):\n    plot.shade_protocol(tc.protocol[\"k1\"], ax=ax, alpha=0.1)\n\nax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tc = mc.time_course_over_protocol(     get_linear_chain_2v(),     time_points_per_step=10,     protocol=make_protocol(         [             (1, {\"k1\": 1}),             (2, {\"k1\": 2}),             (3, {\"k1\": 1}),         ]     ),     mc_to_scan=sample(         {             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2) for ax in (ax1, ax2):     plot.shade_protocol(tc.protocol[\"k1\"], ax=ax, alpha=0.1)  ax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00&lt;00:00, 33.10it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 41.58it/s]</pre> <pre>\n</pre> In\u00a0[6]: Copied! <pre>mc_elas = mc.variable_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"GLC\", \"F6P\"],\n    mc_to_scan=sample(\n        {\n            # \"k1\": LogNormal(mean=np.log(0.25), sigma=1.0),\n            # \"k2\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            \"k3\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k4\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k5\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k6\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k7\": LogNormal(mean=np.log(2.5), sigma=1.0),\n        },\n        n=5,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(mc_elas)\nplt.show()\n</pre> mc_elas = mc.variable_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"GLC\", \"F6P\"],     mc_to_scan=sample(         {             # \"k1\": LogNormal(mean=np.log(0.25), sigma=1.0),             # \"k2\": LogNormal(mean=np.log(1.0), sigma=1.0),             \"k3\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k4\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k5\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k6\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k7\": LogNormal(mean=np.log(2.5), sigma=1.0),         },         n=5,     ), )  _ = plot.violins_from_2d_idx(mc_elas) plt.show() <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 35.99it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>elas = mc.parameter_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"k1\", \"k2\", \"k3\"],\n    mc_to_scan=sample(\n        {\n            \"k3\": LogNormal(mean=np.log(0.25), sigma=1.0),\n        },\n        n=5,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(elas)\nplt.show()\n</pre> elas = mc.parameter_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"k1\", \"k2\", \"k3\"],     mc_to_scan=sample(         {             \"k3\": LogNormal(mean=np.log(0.25), sigma=1.0),         },         n=5,     ), )  _ = plot.violins_from_2d_idx(elas) plt.show() <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 36.71it/s]</pre> <pre>\n</pre> In\u00a0[8]: Copied! <pre># Compare with \"normal\" control coefficients\nrc = mca.response_coefficients(\n    get_lin_chain_two_circles(),\n    to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],\n)\n_ = plot.heatmap(rc.variables)\n\nmrc = mc.response_coefficients(\n    get_lin_chain_two_circles(),\n    to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],\n    mc_to_scan=sample(\n        {\n            \"k0\": LogNormal(np.log(1.0), 1.0),\n            \"k4\": LogNormal(np.log(0.5), 1.0),\n        },\n        n=10,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(mrc.variables, n_cols=len(mrc.variables.columns))\n</pre> # Compare with \"normal\" control coefficients rc = mca.response_coefficients(     get_lin_chain_two_circles(),     to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"], ) _ = plot.heatmap(rc.variables)  mrc = mc.response_coefficients(     get_lin_chain_two_circles(),     to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],     mc_to_scan=sample(         {             \"k0\": LogNormal(np.log(1.0), 1.0),             \"k4\": LogNormal(np.log(0.5), 1.0),         },         n=10,     ), )  _ = plot.violins_from_2d_idx(mrc.variables, n_cols=len(mrc.variables.columns)) <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.96it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 11.99it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00,  9.19it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.65it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.59it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.22it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.50it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.62it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.50it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.22it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.51it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.61it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.46it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.47it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r 10%|\u2588         | 1/10 [00:01&lt;00:13,  1.48s/it]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.64it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.64it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.62it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.61it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.61it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.20it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.20it/s]</pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 2/10 [00:02&lt;00:08,  1.10s/it]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.16it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.18it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:02,  1.63it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.56it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.73it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.22it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.60it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.68it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:01&lt;00:01,  1.61it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.16it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.57it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.58it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&lt;00:02,  1.72it/s]</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.69it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.15it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:01,  1.62it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.70it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.29it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.16it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.70it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.69it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.28it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:02&lt;00:00,  1.62it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.60it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.14it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.15it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.29it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.31it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:03&lt;00:00,  1.64it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:03&lt;00:00,  1.63it/s]</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&lt;00:03,  1.19it/s]</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.66it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.43it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.87it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.83it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.58it/s]</pre> <pre>\n</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&lt;00:00,  2.16it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  4.06it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.76it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:05&lt;00:00,  2.46it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:05&lt;00:00,  1.76it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about monte carlo methods in mxlpy.           Congratulations!  In\u00a0[9]: Copied! <pre>mcss = mc.scan_steady_state(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),\n    mc_to_scan=sample(\n        {\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nplot.violins_from_2d_idx(mcss.variables)\nplt.show()\n</pre> mcss = mc.scan_steady_state(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),     mc_to_scan=sample(         {             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  plot.violins_from_2d_idx(mcss.variables) plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\n---------------------------------------------------------------------------\nRemoteTraceback                           Traceback (most recent call last)\nRemoteTraceback: Traceback (most recent call last):\n  File \"/home/runner/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pebble/common/process.py\", line 65, in process_execute\n    return Result(ResultStatus.SUCCESS, function(*args, **kwargs))\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/MxlPy/MxlPy/src/mxlpy/parallel.py\", line 86, in _load_or_run\n    res = fn(v)\n          ^^^^^\n  File \"/home/runner/work/MxlPy/MxlPy/src/mxlpy/scan.py\", line 67, in _update_parameters_and_initial_conditions\n    return fn(model)\n           ^^^^^^^^^\nTypeError: _parameter_scan_worker() got an unexpected keyword argument 'y0'\n\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 mcss = mc.scan_steady_state(\n      2     get_linear_chain_2v(),\n      3     to_scan=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),\n      4     mc_to_scan=sample(\n      5         {\n      6             \"k2\": Uniform(1.0, 1.3),\n      7             \"k3\": LogNormal(mean=1.0, sigma=0.2),\n      8         },\n      9         n=10,\n     10     ),\n     11 )\n     13 plot.violins_from_2d_idx(mcss.variables)\n     14 plt.show()\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/mc.py:336, in scan_steady_state(model, to_scan, mc_to_scan, y0, max_workers, cache, rel_norm, worker, integrator)\n    333 if y0 is not None:\n    334     model.update_variables(y0)\n--&gt; 336 res = parallelise(\n    337     partial(\n    338         _update_parameters_and_initial_conditions,\n    339         fn=partial(\n    340             worker,\n    341             parameters=to_scan,\n    342             rel_norm=rel_norm,\n    343             integrator=integrator,\n    344             y0=None,\n    345         ),\n    346         model=model,\n    347     ),\n    348     inputs=list(mc_to_scan.iterrows()),\n    349     cache=cache,\n    350     max_workers=max_workers,\n    351 )\n    352 concs = {k: v.variables.T for k, v in res}\n    353 fluxes = {k: v.fluxes.T for k, v in res}\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/parallel.py:158, in parallelise(fn, inputs, cache, parallel, max_workers, timeout, disable_tqdm, tqdm_desc)\n    156 while True:\n    157     try:\n--&gt; 158         key, value = next(it)\n    159         pbar.update(1)\n    160         results.append((key, value))\n\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pebble/pool/base_pool.py:231, in MapResults.next(self)\n    227         return result.value\n    229     result = result.value\n--&gt; 231 raise result\n\nTypeError: _parameter_scan_worker() got an unexpected keyword argument 'y0'</pre> In\u00a0[10]: Copied! <pre># FIXME: no idea how to plot this yet. Ridge plots?\n# Maybe it's just a bit much :D\n\nmcss = mc.scan_steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(0, 1, 3),\n            \"k2\": np.linspace(0, 1, 3),\n        }\n    ),\n    mc_to_scan=sample(\n        {\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nmcss.variables.head()\n</pre> # FIXME: no idea how to plot this yet. Ridge plots? # Maybe it's just a bit much :D  mcss = mc.scan_steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(0, 1, 3),             \"k2\": np.linspace(0, 1, 3),         }     ),     mc_to_scan=sample(         {             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  mcss.variables.head() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\n---------------------------------------------------------------------------\nRemoteTraceback                           Traceback (most recent call last)\nRemoteTraceback: Traceback (most recent call last):\n  File \"/home/runner/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pebble/common/process.py\", line 65, in process_execute\n    return Result(ResultStatus.SUCCESS, function(*args, **kwargs))\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/MxlPy/MxlPy/src/mxlpy/parallel.py\", line 86, in _load_or_run\n    res = fn(v)\n          ^^^^^\n  File \"/home/runner/work/MxlPy/MxlPy/src/mxlpy/scan.py\", line 67, in _update_parameters_and_initial_conditions\n    return fn(model)\n           ^^^^^^^^^\nTypeError: _parameter_scan_worker() got an unexpected keyword argument 'y0'\n\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\nCell In[10], line 4\n      1 # FIXME: no idea how to plot this yet. Ridge plots?\n      2 # Maybe it's just a bit much :D\n----&gt; 4 mcss = mc.scan_steady_state(\n      5     get_linear_chain_2v(),\n      6     to_scan=mb2.cartesian_product(\n      7         {\n      8             \"k1\": np.linspace(0, 1, 3),\n      9             \"k2\": np.linspace(0, 1, 3),\n     10         }\n     11     ),\n     12     mc_to_scan=sample(\n     13         {\n     14             \"k3\": LogNormal(mean=1.0, sigma=0.2),\n     15         },\n     16         n=10,\n     17     ),\n     18 )\n     20 mcss.variables.head()\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/mc.py:336, in scan_steady_state(model, to_scan, mc_to_scan, y0, max_workers, cache, rel_norm, worker, integrator)\n    333 if y0 is not None:\n    334     model.update_variables(y0)\n--&gt; 336 res = parallelise(\n    337     partial(\n    338         _update_parameters_and_initial_conditions,\n    339         fn=partial(\n    340             worker,\n    341             parameters=to_scan,\n    342             rel_norm=rel_norm,\n    343             integrator=integrator,\n    344             y0=None,\n    345         ),\n    346         model=model,\n    347     ),\n    348     inputs=list(mc_to_scan.iterrows()),\n    349     cache=cache,\n    350     max_workers=max_workers,\n    351 )\n    352 concs = {k: v.variables.T for k, v in res}\n    353 fluxes = {k: v.fluxes.T for k, v in res}\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/parallel.py:158, in parallelise(fn, inputs, cache, parallel, max_workers, timeout, disable_tqdm, tqdm_desc)\n    156 while True:\n    157     try:\n--&gt; 158         key, value = next(it)\n    159         pbar.update(1)\n    160         results.append((key, value))\n\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pebble/pool/base_pool.py:231, in MapResults.next(self)\n    227         return result.value\n    229     result = result.value\n--&gt; 231 raise result\n\nTypeError: _parameter_scan_worker() got an unexpected keyword argument 'y0'</pre> In\u00a0[11]: Copied! <pre>from dataclasses import dataclass\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from mxlpy.types import Array\n\n\n@dataclass\nclass MyOwnDistribution:\n    loc: float = 0.0\n    scale: float = 1.0\n\n    def sample(\n        self,\n        num: int,\n        rng: np.random.Generator | None = None,\n    ) -&gt; Array:\n        if rng is None:\n            rng = np.random.default_rng()\n        return rng.normal(loc=self.loc, scale=self.scale, size=num)\n\n\nsample({\"p1\": MyOwnDistribution()}, n=5)\n</pre> from dataclasses import dataclass from typing import TYPE_CHECKING  if TYPE_CHECKING:     from mxlpy.types import Array   @dataclass class MyOwnDistribution:     loc: float = 0.0     scale: float = 1.0      def sample(         self,         num: int,         rng: np.random.Generator | None = None,     ) -&gt; Array:         if rng is None:             rng = np.random.default_rng()         return rng.normal(loc=self.loc, scale=self.scale, size=num)   sample({\"p1\": MyOwnDistribution()}, n=5) Out[11]: p1 0 -0.375136 1 1.692536 2 -1.814079 3 -0.541971 4 -0.059027 In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"monte-carlo.html#monte-carlo-methods","title":"Monte Carlo methods\u00b6","text":"<p>Almost every parameter in biology is better described with a distribution than a single value. Monte-carlo methods allow you to capture the range of possible behaviour your model can exhibit. This is especially useful when you want to understand the uncertainty in your model's predictions.</p> <p>mxlpy offers these Monte Carlo methods for all scans  ...</p> + = <p>and even for metabolic control analysis</p> + = <p>In this tutorial we will mostly use the <code>mxlpy.distributions</code> and <code>mxlpy.mca</code> modules, which contain the functionality to sample from distributions and run distributed analyses.</p>"},{"location":"monte-carlo.html#sample-values","title":"Sample values\u00b6","text":"<p>To do any Monte-Carlo analysis, we first need to be able to sample values.</p> <p>For that, you can use the <code>sample</code> function and distributions supplied by mxlpy. These are mostly thin wrappers around the <code>numpy</code> and <code>scipy</code> sampling methods.</p>"},{"location":"monte-carlo.html#steady-state","title":"Steady-state\u00b6","text":"<p>Using <code>mc.steady_state</code> you can calculate the steady-state distribution given the monte-carlo parameters.</p> <p>This works analogously to the <code>scan.steady_state</code> function, except the index of the dataframes is always just an integer.</p> <p>The parameters used can be obtained by <code>result.parameters</code>.</p> <p>We will use a linear chain of reactions with two circles as an example model for this notebook.</p> <p>$$ \\begin{array}{c|c}     \\mathrm{Reaction} &amp; \\mathrm{Stoichiometry} \\\\     \\hline     v_0 &amp; \\varnothing \\rightarrow{} \\mathrm{x_1} \\\\     v_1 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_2} \\\\     v_2 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_3} \\\\     v_3 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_4} \\\\     v_4 &amp; -\\mathrm{x_4} \\rightarrow{} \\varnothing\\\\     v_5 &amp; -\\mathrm{x_2} \\rightarrow{} \\mathrm{x_1} \\\\     v_6 &amp; -\\mathrm{x_3} \\rightarrow{} \\mathrm{x_1} \\\\ \\end{array} $$</p>"},{"location":"monte-carlo.html#time-course","title":"Time course\u00b6","text":"<p>Using <code>mc.time_course</code> you can calculate time courses for sampled parameters.</p> + = <p>This function works analogously to <code>scan.time_course</code>.</p> <p>The <code>pandas.DataFrame</code>s for concentrations and fluxes have a <code>n x time</code> <code>pandas.MultiIndex</code>.</p> <p>The corresponding parameters can be found in <code>result.parameters</code></p>"},{"location":"monte-carlo.html#protocol-time-course","title":"Protocol time course\u00b6","text":"<p>Using <code>mc.time_course_over_protocol</code> you can calculate time courses for sampled parameters given a discrete protocol.</p> + = <p>The <code>pandas.DataFrame</code>s for concentrations and fluxes have a <code>n x time</code> <code>pandas.MultiIndex</code>. The corresponding parameters can be found in <code>scan.parameters</code></p>"},{"location":"monte-carlo.html#metabolic-control-analysis","title":"Metabolic control analysis\u00b6","text":"<p>mxlpy further has routines for monte-carlo distributed metabolic control analysis. This allows quantifying, whether the coefficients obtained from the MCA analysis are robust against parameter changes or whether they are just an artifact of a particular choice of parameters.</p>"},{"location":"monte-carlo.html#variable-elasticities","title":"Variable elasticities\u00b6","text":"+ = <p>The returned <code>pandas.DataFrame</code> has a <code>pd.MultiIndex</code> of shape <code>n x reaction</code>.</p>"},{"location":"monte-carlo.html#parameter-elasticities","title":"Parameter elasticities\u00b6","text":"+ ="},{"location":"monte-carlo.html#response-coefficients","title":"Response coefficients\u00b6","text":"+ ="},{"location":"monte-carlo.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"monte-carlo.html#parameter-scans","title":"Parameter scans\u00b6","text":"<p>Vary both monte carlo parameters as well as systematically scan for other parameters</p>"},{"location":"monte-carlo.html#custom-distributions","title":"Custom distributions\u00b6","text":"<p>If you want to create custom distributions, all you need to do is to create a class that follows the <code>Distribution</code> protocol, e.g. implements a sample function.</p> <p>For API consistency, the <code>sample</code> method has to take <code>rng</code> argument, which can be ignored if not applicable.</p>"},{"location":"mxl.html","title":"Introduction","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom functools import partial\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom numpy.polynomial.polynomial import Polynomial\n\nfrom example_models.linear_chain import get_linear_chain_2v\nfrom mxlpy import Model, Simulator, fns, npe, plot, scan, surrogates\nfrom mxlpy.distributions import LogNormal, Normal, sample\nfrom mxlpy.types import AbstractSurrogate, unwrap\n</pre> from __future__ import annotations  from functools import partial  import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from numpy.polynomial.polynomial import Polynomial  from example_models.linear_chain import get_linear_chain_2v from mxlpy import Model, Simulator, fns, npe, plot, scan, surrogates from mxlpy.distributions import LogNormal, Normal, sample from mxlpy.types import AbstractSurrogate, unwrap In\u00a0[2]: Copied! <pre>m = Model()\nm.add_variable(\"x\", 1.0)\nm.add_surrogate(\n    \"surrogate\",\n    surrogates.poly.Surrogate(\n        model=Polynomial(coef=[2]),\n        args=[\"x\"],\n        outputs=[\"y\"],\n    ),\n)\nm.add_derived(\"z\", fns.add, args=[\"x\", \"y\"])\n\n# Check output\nm.get_dependent()\n</pre> m = Model() m.add_variable(\"x\", 1.0) m.add_surrogate(     \"surrogate\",     surrogates.poly.Surrogate(         model=Polynomial(coef=[2]),         args=[\"x\"],         outputs=[\"y\"],     ), ) m.add_derived(\"z\", fns.add, args=[\"x\", \"y\"])  # Check output m.get_dependent() Out[2]: <pre>x       1.0\ntime    0.0\ny       2.0\nz       3.0\ndtype: float64</pre> <p>Next we extend that idea to create a reaction. The only thing we need to change here is to also add the <code>stoichiometries</code> of the respective output variable.</p> <p>I've renamed the output to <code>v1</code> here to fit convention, but that is not technically necessary. <code>mxlpy</code> will always infer structurally into what kind of value your surrogate will be translated.</p> In\u00a0[3]: Copied! <pre>m = Model()\nm.add_variable(\"x\", 1.0)\nm.add_surrogate(\n    \"surrogate\",\n    surrogates.poly.Surrogate(\n        model=Polynomial(coef=[2]),\n        args=[\"x\"],\n        outputs=[\"v1\"],\n        stoichiometries={\"v1\": {\"x\": -1}},\n    ),\n)\nm.add_derived(\"z\", fns.add, args=[\"x\", \"v1\"])\n\n# Check output\nm.get_right_hand_side()\n</pre> m = Model() m.add_variable(\"x\", 1.0) m.add_surrogate(     \"surrogate\",     surrogates.poly.Surrogate(         model=Polynomial(coef=[2]),         args=[\"x\"],         outputs=[\"v1\"],         stoichiometries={\"v1\": {\"x\": -1}},     ), ) m.add_derived(\"z\", fns.add, args=[\"x\", \"v1\"])  # Check output m.get_right_hand_side() Out[3]: <pre>x   -2.0\ndtype: float64</pre> <p>Note that if you have multiple outputs, it is perfectly fine for them to mix between derived values and reactions.</p> <pre>Surrogate(\n    model=...,\n    args=[\"x\", \"y\"],\n    outputs=[\"d1\", \"v1\"],               # outputs derived value d1 and rate v1\n    stoichiometries={\"v1\": {\"x\": -1}},  # only rate v1 is given stoichiometries\n)\n</pre> <p>We will start with a simple linear chain model</p> <p>$$ \\Large \\varnothing \\xrightarrow{v_1} x \\xrightarrow{v_2} y \\xrightarrow{v_3} \\varnothing $$</p> <p>where we want to read out the steady-state rate of $v_3$ dependent on the fixed concentration of $x$, while ignoring the inner state of the model.</p> <p>$$ \\Large  x \\xrightarrow{} ... \\xrightarrow{v_3}$$</p> <p>Since we need to fix a <code>variable</code> as an <code>parameter</code>, we can use the <code>make_variable_static</code> method to do that.</p> In\u00a0[4]: Copied! <pre># Now \"x\" is a parameter\nget_linear_chain_2v().make_variable_static(\"x\").parameters\n</pre> # Now \"x\" is a parameter get_linear_chain_2v().make_variable_static(\"x\").parameters Out[4]: <pre>{'k1': 1.0, 'k2': 2.0, 'k3': 1.0, 'x': 1.0}</pre> <p>And we can already create a function to create a model, which will take our surrogate as an input.</p> In\u00a0[5]: Copied! <pre>def get_model_with_surrogate(surrogate: AbstractSurrogate) -&gt; Model:\n    model = Model()\n    model.add_variables({\"x\": 1.0, \"z\": 0.0})\n\n    # Adding the surrogate\n    model.add_surrogate(\n        \"surrogate\",\n        surrogate,\n        args=[\"x\"],\n        outputs=[\"v2\"],\n        stoichiometries={\n            \"v2\": {\"x\": -1, \"z\": 1},\n        },\n    )\n\n    # Note that besides the surrogate we haven't defined any other reaction!\n    # We could have though\n    return model\n</pre> def get_model_with_surrogate(surrogate: AbstractSurrogate) -&gt; Model:     model = Model()     model.add_variables({\"x\": 1.0, \"z\": 0.0})      # Adding the surrogate     model.add_surrogate(         \"surrogate\",         surrogate,         args=[\"x\"],         outputs=[\"v2\"],         stoichiometries={             \"v2\": {\"x\": -1, \"z\": 1},         },     )      # Note that besides the surrogate we haven't defined any other reaction!     # We could have though     return model In\u00a0[6]: Copied! <pre>surrogate_features = pd.DataFrame({\"x\": np.geomspace(1e-12, 2.0, 21)})\n\nsurrogate_targets = scan.steady_state(\n    get_linear_chain_2v().make_variable_static(\"x\"),\n    to_scan=surrogate_features,\n).fluxes.loc[:, [\"v3\"]]\n\n# It's always a good idea to check the inputs and outputs\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False)\n_ = plot.violins(surrogate_features, ax=ax1)[1].set(\n    title=\"Features\", ylabel=\"Flux / a.u.\"\n)\n_ = plot.violins(surrogate_targets, ax=ax2)[1].set(\n    title=\"Targets\", ylabel=\"Flux / a.u.\"\n)\nplt.show()\n</pre> surrogate_features = pd.DataFrame({\"x\": np.geomspace(1e-12, 2.0, 21)})  surrogate_targets = scan.steady_state(     get_linear_chain_2v().make_variable_static(\"x\"),     to_scan=surrogate_features, ).fluxes.loc[:, [\"v3\"]]  # It's always a good idea to check the inputs and outputs fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False) _ = plot.violins(surrogate_features, ax=ax1)[1].set(     title=\"Features\", ylabel=\"Flux / a.u.\" ) _ = plot.violins(surrogate_targets, ax=ax2)[1].set(     title=\"Targets\", ylabel=\"Flux / a.u.\" ) plt.show() <pre>\r  0%|          | 0/21 [00:00&lt;?, ?it/s]</pre> <pre>\r 29%|\u2588\u2588\u258a       | 6/21 [00:00&lt;00:00, 58.55it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:00&lt;00:00, 80.97it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>surrogate, info = surrogates.poly.train(\n    surrogate_features[\"x\"],\n    surrogate_targets[\"v3\"],\n)\n\nprint(\"Model\", surrogate.model, end=\"\\n\\n\")\nprint(info[\"score\"])\n</pre> surrogate, info = surrogates.poly.train(     surrogate_features[\"x\"],     surrogate_targets[\"v3\"], )  print(\"Model\", surrogate.model, end=\"\\n\\n\") print(info[\"score\"]) <pre>Model 2.0 + 2.0\u00b7(-1.0 + 1.0x)\n\ndegree\n1     2.0\n2     4.0\n3     6.0\n4     8.0\n5    10.0\n6    12.0\n7    14.0\nName: score, dtype: float64\n</pre> <p>You can then insert the surrogate into the model using the function we defined earlier</p> In\u00a0[8]: Copied! <pre>concs, fluxes = unwrap(\n    Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(8, 3))\nplot.lines(concs, ax=ax1)\nplot.lines(fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> concs, fluxes = unwrap(     Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(8, 3)) plot.lines(concs, ax=ax1) plot.lines(fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() <p>While polynomial regression can model nonlinear relationships between variables, it often struggles when the underlying relationship is more complex than a polynomial function. You will learn about using neural networks in the next section.</p> In\u00a0[9]: Copied! <pre>surrogate, loss = surrogates.torch.train(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    batch_size=100,\n    epochs=250,\n)\n\nax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1])\nax.set_ylim(0, None)\nplt.show()\n</pre> surrogate, loss = surrogates.torch.train(     features=surrogate_features,     targets=surrogate_targets,     batch_size=100,     epochs=250, )  ax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1]) ax.set_ylim(0, None) plt.show() <pre>\r  0%|          | 0/250 [00:00&lt;?, ?it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 108/250 [00:00&lt;00:00, 1068.38it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 219/250 [00:00&lt;00:00, 1092.00it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [00:00&lt;00:00, 1085.50it/s]</pre> <pre>\n</pre> <p>As before, you can then insert the surrogate into the model using the function we defined earlier</p> In\u00a0[10]: Copied! <pre>concs, fluxes = unwrap(\n    Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(8, 3))\nplot.lines(concs, ax=ax1)\nplot.lines(fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> concs, fluxes = unwrap(     Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(8, 3)) plot.lines(concs, ax=ax1) plot.lines(fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() In\u00a0[11]: Copied! <pre>trainer = surrogates.torch.Trainer(\n    features=surrogate_features,\n    targets=surrogate_targets,\n)\n\n# First training epochs\ntrainer.train(epochs=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Decide to continue training\ntrainer.train(epochs=150)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\nsurrogate = trainer.get_surrogate(surrogate_outputs=[\"x\"])\n</pre> trainer = surrogates.torch.Trainer(     features=surrogate_features,     targets=surrogate_targets, )  # First training epochs trainer.train(epochs=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Decide to continue training trainer.train(epochs=150) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  surrogate = trainer.get_surrogate(surrogate_outputs=[\"x\"]) <pre>\r  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1060.07it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/150 [00:00&lt;?, ?it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 112/150 [00:00&lt;00:00, 1117.74it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 150/150 [00:00&lt;00:00, 1115.23it/s]</pre> <pre>\n</pre> In\u00a0[12]: Copied! <pre>print(surrogate.predict_raw(np.array([-0.1])))\nprint(surrogate.predict_raw(np.array([0.0])))\nprint(surrogate.predict_raw(np.array([0.1])))\n</pre> print(surrogate.predict_raw(np.array([-0.1]))) print(surrogate.predict_raw(np.array([0.0]))) print(surrogate.predict_raw(np.array([0.1]))) <pre>[-0.0156231]\n[-0.00136776]\n[0.1977348]\n</pre> In\u00a0[13]: Copied! <pre>surrogate, loss = surrogates.keras.train(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    batch_size=100,\n    epochs=250,\n)\n\nax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1])\nax.set_ylim(0, None)\nplt.show()\n</pre> surrogate, loss = surrogates.keras.train(     features=surrogate_features,     targets=surrogate_targets,     batch_size=100,     epochs=250, )  ax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1]) ax.set_ylim(0, None) plt.show() <pre>2025-05-30 07:22:34.027119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748589754.041214    2993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748589754.045529    2993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1748589754.057267    2993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1748589754.057278    2993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1748589754.057280    2993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1748589754.057281    2993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-05-30 07:22:34.061198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n</pre> <pre>2025-05-30 07:22:39.013373: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n</pre> In\u00a0[14]: Copied! <pre># Note that now the parameters are the targets\nnpe_targets = sample(\n    {\n        \"k1\": LogNormal(mean=1.0, sigma=0.3),\n    },\n    n=1_000,\n)\n\n# And the generated data are the features\nnpe_features = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=npe_targets,\n).results.loc[:, [\"y\", \"v2\", \"v3\"]]\n\n# It's always a good idea to check the inputs and outputs\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False)\n_ = plot.violins(npe_features, ax=ax1)[1].set(title=\"Features\", ylabel=\"Flux / a.u.\")\n_ = plot.violins(npe_targets, ax=ax2)[1].set(title=\"Targets\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> # Note that now the parameters are the targets npe_targets = sample(     {         \"k1\": LogNormal(mean=1.0, sigma=0.3),     },     n=1_000, )  # And the generated data are the features npe_features = scan.steady_state(     get_linear_chain_2v(),     to_scan=npe_targets, ).results.loc[:, [\"y\", \"v2\", \"v3\"]]  # It's always a good idea to check the inputs and outputs fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False) _ = plot.violins(npe_features, ax=ax1)[1].set(title=\"Features\", ylabel=\"Flux / a.u.\") _ = plot.violins(npe_targets, ax=ax2)[1].set(title=\"Targets\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 5/1000 [00:00&lt;00:20, 48.20it/s]</pre> <pre>\r  2%|\u258f         | 23/1000 [00:00&lt;00:07, 123.96it/s]</pre> <pre>\r  4%|\u258d         | 42/1000 [00:00&lt;00:06, 152.20it/s]</pre> <pre>\r  6%|\u258c         | 60/1000 [00:00&lt;00:05, 157.56it/s]</pre> <pre>\r  8%|\u258a         | 79/1000 [00:00&lt;00:05, 166.36it/s]</pre> <pre>\r 10%|\u2589         | 98/1000 [00:00&lt;00:05, 171.46it/s]</pre> <pre>\r 12%|\u2588\u258f        | 116/1000 [00:00&lt;00:05, 173.79it/s]</pre> <pre>\r 13%|\u2588\u258e        | 134/1000 [00:00&lt;00:04, 174.80it/s]</pre> <pre>\r 15%|\u2588\u258c        | 153/1000 [00:00&lt;00:04, 177.63it/s]</pre> <pre>\r 17%|\u2588\u258b        | 171/1000 [00:01&lt;00:04, 175.68it/s]</pre> <pre>\r 19%|\u2588\u2589        | 190/1000 [00:01&lt;00:04, 171.36it/s]</pre> <pre>\r 21%|\u2588\u2588        | 210/1000 [00:01&lt;00:04, 174.88it/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 230/1000 [00:01&lt;00:04, 175.52it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 250/1000 [00:01&lt;00:04, 176.18it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 269/1000 [00:01&lt;00:04, 176.95it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 288/1000 [00:01&lt;00:04, 177.57it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 307/1000 [00:01&lt;00:03, 180.26it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 326/1000 [00:01&lt;00:03, 174.71it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 344/1000 [00:02&lt;00:03, 170.60it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 362/1000 [00:02&lt;00:03, 172.92it/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 380/1000 [00:02&lt;00:03, 169.97it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 400/1000 [00:02&lt;00:03, 172.48it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 418/1000 [00:02&lt;00:03, 172.00it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 436/1000 [00:02&lt;00:03, 172.67it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 454/1000 [00:02&lt;00:03, 173.83it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 472/1000 [00:02&lt;00:03, 167.73it/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 492/1000 [00:02&lt;00:02, 172.61it/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 512/1000 [00:02&lt;00:02, 175.44it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 531/1000 [00:03&lt;00:02, 175.13it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 549/1000 [00:03&lt;00:02, 176.07it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 567/1000 [00:03&lt;00:02, 174.97it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 585/1000 [00:03&lt;00:02, 174.49it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 603/1000 [00:03&lt;00:02, 174.29it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 622/1000 [00:03&lt;00:02, 174.18it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 640/1000 [00:03&lt;00:02, 175.83it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 658/1000 [00:03&lt;00:01, 174.04it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 676/1000 [00:03&lt;00:01, 170.58it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 695/1000 [00:04&lt;00:01, 171.23it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 715/1000 [00:04&lt;00:01, 176.73it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 733/1000 [00:04&lt;00:01, 175.47it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 751/1000 [00:04&lt;00:01, 175.13it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 769/1000 [00:04&lt;00:01, 174.59it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 787/1000 [00:04&lt;00:01, 169.78it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 806/1000 [00:04&lt;00:01, 172.96it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 825/1000 [00:04&lt;00:00, 175.98it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 843/1000 [00:04&lt;00:00, 174.62it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 861/1000 [00:05&lt;00:00, 175.83it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 879/1000 [00:05&lt;00:00, 173.86it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 898/1000 [00:05&lt;00:00, 175.99it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 916/1000 [00:05&lt;00:00, 174.47it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 935/1000 [00:05&lt;00:00, 174.41it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 953/1000 [00:05&lt;00:00, 173.97it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 971/1000 [00:05&lt;00:00, 175.22it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 989/1000 [00:05&lt;00:00, 175.98it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:05&lt;00:00, 169.92it/s]</pre> <pre>\n</pre> In\u00a0[15]: Copied! <pre>estimator, losses = npe.torch.train_steady_state(\n    features=npe_features,\n    targets=npe_targets,\n    epochs=100,\n    batch_size=100,\n)\n\nax = losses.plot(figsize=(4, 2.5))\nax.set(xlabel=\"epoch\", ylabel=\"loss\")\nax.set_ylim(0, None)\nplt.show()\n</pre> estimator, losses = npe.torch.train_steady_state(     features=npe_features,     targets=npe_targets,     epochs=100,     batch_size=100, )  ax = losses.plot(figsize=(4, 2.5)) ax.set(xlabel=\"epoch\", ylabel=\"loss\") ax.set_ylim(0, None) plt.show() <pre>\r  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> <pre>\r  9%|\u2589         | 9/100 [00:00&lt;00:01, 86.90it/s]</pre> <pre>\r 18%|\u2588\u258a        | 18/100 [00:00&lt;00:00, 87.41it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 27/100 [00:00&lt;00:00, 88.00it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 36/100 [00:00&lt;00:00, 88.25it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 45/100 [00:00&lt;00:00, 88.52it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 54/100 [00:00&lt;00:00, 88.53it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 63/100 [00:00&lt;00:00, 88.60it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 72/100 [00:00&lt;00:00, 88.70it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 81/100 [00:00&lt;00:00, 88.80it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 90/100 [00:01&lt;00:00, 88.71it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 99/100 [00:01&lt;00:00, 88.64it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 88.42it/s]</pre> <pre>\n</pre> In\u00a0[16]: Copied! <pre>fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2))\n\nax = sns.kdeplot(npe_targets, fill=True, ax=ax1)\nax.set_title(\"Prior\")\n\nposterior = estimator.predict(npe_features)\nax = sns.kdeplot(posterior, fill=True, ax=ax2)\nax.set_title(\"Posterior\")\nplt.show()\n</pre> fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2))  ax = sns.kdeplot(npe_targets, fill=True, ax=ax1) ax.set_title(\"Prior\")  posterior = estimator.predict(npe_features) ax = sns.kdeplot(posterior, fill=True, ax=ax2) ax.set_title(\"Posterior\") plt.show() In\u00a0[17]: Copied! <pre>trainer = npe.torch.SteadyStateTrainer(\n    features=npe_features,\n    targets=npe_targets,\n)\n\n# Initial training\ntrainer.train(epochs=20, batch_size=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Continue training\ntrainer.train(epochs=20, batch_size=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Get trainer if loss is deemed suitable\nestimator = trainer.get_estimator()\n</pre> trainer = npe.torch.SteadyStateTrainer(     features=npe_features,     targets=npe_targets, )  # Initial training trainer.train(epochs=20, batch_size=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Continue training trainer.train(epochs=20, batch_size=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Get trainer if loss is deemed suitable estimator = trainer.get_estimator() <pre>\r  0%|          | 0/20 [00:00&lt;?, ?it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 9/20 [00:00&lt;00:00, 86.47it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 18/20 [00:00&lt;00:00, 87.53it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 87.19it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/20 [00:00&lt;?, ?it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 9/20 [00:00&lt;00:00, 88.57it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 18/20 [00:00&lt;00:00, 88.70it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 88.28it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about labelled models in mxlpy.           Congratulations!  In\u00a0[18]: Copied! <pre>from typing import TYPE_CHECKING\n\nimport torch\n\nfrom mxlpy import LinearLabelMapper, Simulator\nfrom mxlpy.distributions import sample\nfrom mxlpy.fns import michaelis_menten_1s\nfrom mxlpy.parallel import parallelise\n\nif TYPE_CHECKING:\n    from mxlpy.types import AbstractEstimator\n</pre> from typing import TYPE_CHECKING  import torch  from mxlpy import LinearLabelMapper, Simulator from mxlpy.distributions import sample from mxlpy.fns import michaelis_menten_1s from mxlpy.parallel import parallelise  if TYPE_CHECKING:     from mxlpy.types import AbstractEstimator In\u00a0[19]: Copied! <pre>def mean_abs(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n    return torch.mean(torch.abs(x - y))\n\n\ntrainer = surrogates.torch.Trainer(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    loss_fn=mean_abs,\n)\n\ntrainer = npe.torch.SteadyStateTrainer(\n    features=npe_features,\n    targets=npe_targets,\n    loss_fn=mean_abs,\n)\n\ntrainer = npe.torch.TimeCourseTrainer(\n    features=npe_features,\n    targets=npe_targets,\n    loss_fn=mean_abs,\n)\n</pre> def mean_abs(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:     return torch.mean(torch.abs(x - y))   trainer = surrogates.torch.Trainer(     features=surrogate_features,     targets=surrogate_targets,     loss_fn=mean_abs, )  trainer = npe.torch.SteadyStateTrainer(     features=npe_features,     targets=npe_targets,     loss_fn=mean_abs, )  trainer = npe.torch.TimeCourseTrainer(     features=npe_features,     targets=npe_targets,     loss_fn=mean_abs, ) In\u00a0[20]: Copied! <pre># FIXME: todo\n# Show how to change Adam settings or user other optimizers\n# Show how to change the surrogate network\n</pre> # FIXME: todo # Show how to change Adam settings or user other optimizers # Show how to change the surrogate network In\u00a0[21]: Copied! <pre>def get_closed_cycle() -&gt; tuple[Model, dict[str, int], dict[str, list[int]]]:\n    \"\"\"\n\n    | Reaction       | Labelmap |\n    | -------------- | -------- |\n    | x1 -&gt;[v1] x2   | [0, 1]   |\n    | x2 -&gt;[v2a] x3  | [0, 1]   |\n    | x2 -&gt;[v2b] x3  | [1, 0]   |\n    | x3 -&gt;[v3] x1   | [0, 1]   |\n\n    \"\"\"\n    model = (\n        Model()\n        .add_parameters(\n            {\n                \"vmax_1\": 1.0,\n                \"km_1\": 0.5,\n                \"vmax_2a\": 1.0,\n                \"vmax_2b\": 1.0,\n                \"km_2\": 0.5,\n                \"vmax_3\": 1.0,\n                \"km_3\": 0.5,\n            }\n        )\n        .add_variables({\"x1\": 1.0, \"x2\": 0.0, \"x3\": 0.0})\n        .add_reaction(\n            \"v1\",\n            michaelis_menten_1s,\n            stoichiometry={\"x1\": -1, \"x2\": 1},\n            args=[\"x1\", \"vmax_1\", \"km_1\"],\n        )\n        .add_reaction(\n            \"v2a\",\n            michaelis_menten_1s,\n            stoichiometry={\"x2\": -1, \"x3\": 1},\n            args=[\"x2\", \"vmax_2a\", \"km_2\"],\n        )\n        .add_reaction(\n            \"v2b\",\n            michaelis_menten_1s,\n            stoichiometry={\"x2\": -1, \"x3\": 1},\n            args=[\"x2\", \"vmax_2b\", \"km_2\"],\n        )\n        .add_reaction(\n            \"v3\",\n            michaelis_menten_1s,\n            stoichiometry={\"x3\": -1, \"x1\": 1},\n            args=[\"x3\", \"vmax_3\", \"km_3\"],\n        )\n    )\n    label_variables: dict[str, int] = {\"x1\": 2, \"x2\": 2, \"x3\": 2}\n    label_maps: dict[str, list[int]] = {\n        \"v1\": [0, 1],\n        \"v2a\": [0, 1],\n        \"v2b\": [1, 0],\n        \"v3\": [0, 1],\n    }\n    return model, label_variables, label_maps\n</pre> def get_closed_cycle() -&gt; tuple[Model, dict[str, int], dict[str, list[int]]]:     \"\"\"      | Reaction       | Labelmap |     | -------------- | -------- |     | x1 -&gt;[v1] x2   | [0, 1]   |     | x2 -&gt;[v2a] x3  | [0, 1]   |     | x2 -&gt;[v2b] x3  | [1, 0]   |     | x3 -&gt;[v3] x1   | [0, 1]   |      \"\"\"     model = (         Model()         .add_parameters(             {                 \"vmax_1\": 1.0,                 \"km_1\": 0.5,                 \"vmax_2a\": 1.0,                 \"vmax_2b\": 1.0,                 \"km_2\": 0.5,                 \"vmax_3\": 1.0,                 \"km_3\": 0.5,             }         )         .add_variables({\"x1\": 1.0, \"x2\": 0.0, \"x3\": 0.0})         .add_reaction(             \"v1\",             michaelis_menten_1s,             stoichiometry={\"x1\": -1, \"x2\": 1},             args=[\"x1\", \"vmax_1\", \"km_1\"],         )         .add_reaction(             \"v2a\",             michaelis_menten_1s,             stoichiometry={\"x2\": -1, \"x3\": 1},             args=[\"x2\", \"vmax_2a\", \"km_2\"],         )         .add_reaction(             \"v2b\",             michaelis_menten_1s,             stoichiometry={\"x2\": -1, \"x3\": 1},             args=[\"x2\", \"vmax_2b\", \"km_2\"],         )         .add_reaction(             \"v3\",             michaelis_menten_1s,             stoichiometry={\"x3\": -1, \"x1\": 1},             args=[\"x3\", \"vmax_3\", \"km_3\"],         )     )     label_variables: dict[str, int] = {\"x1\": 2, \"x2\": 2, \"x3\": 2}     label_maps: dict[str, list[int]] = {         \"v1\": [0, 1],         \"v2a\": [0, 1],         \"v2b\": [1, 0],         \"v3\": [0, 1],     }     return model, label_variables, label_maps In\u00a0[22]: Copied! <pre>def _worker(\n    x: tuple[tuple[int, pd.Series], tuple[int, pd.Series]],\n    mapper: LinearLabelMapper,\n    time: float,\n    initial_labels: dict[str, int | list[int]],\n) -&gt; pd.Series:\n    (_, y_ss), (_, v_ss) = x\n    return unwrap(\n        Simulator(mapper.build_model(y_ss, v_ss, initial_labels=initial_labels))\n        .simulate(time)\n        .get_result()\n    ).variables.iloc[-1]\n\n\ndef get_label_distribution_at_time(\n    model: Model,\n    label_variables: dict[str, int],\n    label_maps: dict[str, list[int]],\n    time: float,\n    initial_labels: dict[str, int | list[int]],\n    ss_concs: pd.DataFrame,\n    ss_fluxes: pd.DataFrame,\n) -&gt; pd.DataFrame:\n    mapper = LinearLabelMapper(\n        model,\n        label_variables=label_variables,\n        label_maps=label_maps,\n    )\n\n    return pd.DataFrame(\n        parallelise(\n            partial(_worker, mapper=mapper, time=time, initial_labels=initial_labels),\n            inputs=list(\n                enumerate(zip(ss_concs.iterrows(), ss_fluxes.iterrows(), strict=True))\n            ),\n            cache=None,\n        )\n    ).T\n\n\ndef inverse_parameter_elasticity(\n    estimator: AbstractEstimator,\n    datum: pd.Series,\n    *,\n    normalized: bool = True,\n    displacement: float = 1e-4,\n) -&gt; pd.DataFrame:\n    ref = estimator.predict(datum).iloc[0, :]\n\n    coefs = {}\n    for name, value in datum.items():\n        up = coefs[name] = estimator.predict(\n            pd.Series(datum.to_dict() | {name: value * 1 + displacement})\n        ).iloc[0, :]\n        down = coefs[name] = estimator.predict(\n            pd.Series(datum.to_dict() | {name: value * 1 - displacement})\n        ).iloc[0, :]\n        coefs[name] = (up - down) / (2 * displacement * value)\n\n    coefs = pd.DataFrame(coefs)\n    if normalized:\n        coefs *= datum / ref.to_numpy()\n\n    return coefs\n</pre> def _worker(     x: tuple[tuple[int, pd.Series], tuple[int, pd.Series]],     mapper: LinearLabelMapper,     time: float,     initial_labels: dict[str, int | list[int]], ) -&gt; pd.Series:     (_, y_ss), (_, v_ss) = x     return unwrap(         Simulator(mapper.build_model(y_ss, v_ss, initial_labels=initial_labels))         .simulate(time)         .get_result()     ).variables.iloc[-1]   def get_label_distribution_at_time(     model: Model,     label_variables: dict[str, int],     label_maps: dict[str, list[int]],     time: float,     initial_labels: dict[str, int | list[int]],     ss_concs: pd.DataFrame,     ss_fluxes: pd.DataFrame, ) -&gt; pd.DataFrame:     mapper = LinearLabelMapper(         model,         label_variables=label_variables,         label_maps=label_maps,     )      return pd.DataFrame(         parallelise(             partial(_worker, mapper=mapper, time=time, initial_labels=initial_labels),             inputs=list(                 enumerate(zip(ss_concs.iterrows(), ss_fluxes.iterrows(), strict=True))             ),             cache=None,         )     ).T   def inverse_parameter_elasticity(     estimator: AbstractEstimator,     datum: pd.Series,     *,     normalized: bool = True,     displacement: float = 1e-4, ) -&gt; pd.DataFrame:     ref = estimator.predict(datum).iloc[0, :]      coefs = {}     for name, value in datum.items():         up = coefs[name] = estimator.predict(             pd.Series(datum.to_dict() | {name: value * 1 + displacement})         ).iloc[0, :]         down = coefs[name] = estimator.predict(             pd.Series(datum.to_dict() | {name: value * 1 - displacement})         ).iloc[0, :]         coefs[name] = (up - down) / (2 * displacement * value)      coefs = pd.DataFrame(coefs)     if normalized:         coefs *= datum / ref.to_numpy()      return coefs In\u00a0[23]: Copied! <pre>model, label_variables, label_maps = get_closed_cycle()\n\nss_concs, ss_fluxes = unwrap(\n    Simulator(model)\n    .update_parameters({\"vmax_2a\": 1.0, \"vmax_2b\": 0.5})\n    .simulate_to_steady_state()\n    .get_result()\n)\nmapper = LinearLabelMapper(\n    model,\n    label_variables=label_variables,\n    label_maps=label_maps,\n)\n\n_, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(\n            mapper.build_model(\n                ss_concs.iloc[-1], ss_fluxes.iloc[-1], initial_labels={\"x1\": 0}\n            )\n        )\n        .simulate(5)\n        .get_result()\n    ).variables,\n    sharey=True,\n    n_cols=3,\n)\n\naxs[0].set_ylabel(\"Relative label distribution\")\naxs[1].set_xlabel(\"Time / s\")\nplt.show()\n</pre> model, label_variables, label_maps = get_closed_cycle()  ss_concs, ss_fluxes = unwrap(     Simulator(model)     .update_parameters({\"vmax_2a\": 1.0, \"vmax_2b\": 0.5})     .simulate_to_steady_state()     .get_result() ) mapper = LinearLabelMapper(     model,     label_variables=label_variables,     label_maps=label_maps, )  _, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(             mapper.build_model(                 ss_concs.iloc[-1], ss_fluxes.iloc[-1], initial_labels={\"x1\": 0}             )         )         .simulate(5)         .get_result()     ).variables,     sharey=True,     n_cols=3, )  axs[0].set_ylabel(\"Relative label distribution\") axs[1].set_xlabel(\"Time / s\") plt.show() <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[23], line 30\n      9 mapper = LinearLabelMapper(\n     10     model,\n     11     label_variables=label_variables,\n     12     label_maps=label_maps,\n     13 )\n     15 _, axs = plot.relative_label_distribution(\n     16     mapper,\n     17     unwrap(\n   (...)     27     n_cols=3,\n     28 )\n---&gt; 30 axs[0].set_ylabel(\"Relative label distribution\")\n     31 axs[1].set_xlabel(\"Time / s\")\n     32 plt.show()\n\nAttributeError: 'numpy.ndarray' object has no attribute 'set_ylabel'</pre> In\u00a0[24]: Copied! <pre>surrogate_targets = sample(\n    {\n        \"vmax_2b\": Normal(0.5, 0.1),\n    },\n    n=1000,\n).clip(lower=0)\n\nax = sns.kdeplot(surrogate_targets, fill=True)\nax.set_title(\"Prior\")\n</pre> surrogate_targets = sample(     {         \"vmax_2b\": Normal(0.5, 0.1),     },     n=1000, ).clip(lower=0)  ax = sns.kdeplot(surrogate_targets, fill=True) ax.set_title(\"Prior\") Out[24]: <pre>Text(0.5, 1.0, 'Prior')</pre> In\u00a0[25]: Copied! <pre>ss_concs, ss_fluxes = scan.steady_state(\n    model,\n    to_scan=surrogate_targets,\n)\n</pre> ss_concs, ss_fluxes = scan.steady_state(     model,     to_scan=surrogate_targets, ) <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 1/1000 [00:00&lt;01:50,  9.03it/s]</pre> <pre>\r  1%|          | 12/1000 [00:00&lt;00:15, 65.78it/s]</pre> <pre>\r  2%|\u258f         | 21/1000 [00:00&lt;00:13, 72.28it/s]</pre> <pre>\r  3%|\u258e         | 29/1000 [00:00&lt;00:38, 25.17it/s]</pre> <pre>\r  6%|\u258c         | 58/1000 [00:01&lt;00:14, 63.04it/s]</pre> <pre>\r  7%|\u258b         | 70/1000 [00:01&lt;00:13, 68.84it/s]</pre> <pre>\r  8%|\u258a         | 82/1000 [00:01&lt;00:12, 74.40it/s]</pre> <pre>\r  9%|\u2589         | 94/1000 [00:01&lt;00:11, 78.79it/s]</pre> <pre>\r 11%|\u2588         | 106/1000 [00:01&lt;00:10, 82.28it/s]</pre> <pre>\r 12%|\u2588\u258f        | 118/1000 [00:01&lt;00:10, 84.82it/s]</pre> <pre>\r 13%|\u2588\u258e        | 130/1000 [00:01&lt;00:10, 86.97it/s]</pre> <pre>\r 14%|\u2588\u258d        | 141/1000 [00:01&lt;00:09, 92.36it/s]</pre> <pre>\r 15%|\u2588\u258c        | 151/1000 [00:02&lt;00:09, 89.39it/s]</pre> <pre>\r 16%|\u2588\u258c        | 162/1000 [00:02&lt;00:09, 88.03it/s]</pre> <pre>\r 17%|\u2588\u258b        | 174/1000 [00:02&lt;00:09, 88.91it/s]</pre> <pre>\r 19%|\u2588\u258a        | 186/1000 [00:02&lt;00:09, 90.11it/s]</pre> <pre>\r 20%|\u2588\u2589        | 198/1000 [00:02&lt;00:08, 90.42it/s]</pre> <pre>\r 21%|\u2588\u2588        | 210/1000 [00:02&lt;00:08, 90.36it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 222/1000 [00:02&lt;00:08, 90.09it/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 234/1000 [00:03&lt;00:08, 91.14it/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 245/1000 [00:03&lt;00:07, 95.71it/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 255/1000 [00:03&lt;00:08, 91.21it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 266/1000 [00:03&lt;00:08, 88.89it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 278/1000 [00:03&lt;00:08, 89.44it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 290/1000 [00:03&lt;00:07, 89.31it/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 302/1000 [00:03&lt;00:07, 89.97it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588\u258f      | 314/1000 [00:03&lt;00:07, 90.35it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 326/1000 [00:04&lt;00:07, 90.53it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 338/1000 [00:04&lt;00:07, 91.13it/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258c      | 350/1000 [00:04&lt;00:07, 90.57it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 362/1000 [00:04&lt;00:07, 91.03it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 374/1000 [00:04&lt;00:06, 90.20it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u258a      | 386/1000 [00:04&lt;00:06, 90.60it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 396/1000 [00:04&lt;00:06, 92.67it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 406/1000 [00:04&lt;00:06, 90.18it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 416/1000 [00:05&lt;00:06, 92.30it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 426/1000 [00:05&lt;00:06, 89.47it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 435/1000 [00:05&lt;00:06, 89.53it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 445/1000 [00:05&lt;00:06, 88.11it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 455/1000 [00:05&lt;00:06, 88.21it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258b     | 465/1000 [00:05&lt;00:06, 87.22it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 475/1000 [00:05&lt;00:05, 89.97it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 485/1000 [00:05&lt;00:05, 88.26it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 495/1000 [00:05&lt;00:05, 91.29it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 505/1000 [00:06&lt;00:05, 87.38it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 516/1000 [00:06&lt;00:05, 91.90it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 526/1000 [00:06&lt;00:05, 89.87it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 536/1000 [00:06&lt;00:05, 91.65it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 546/1000 [00:06&lt;00:05, 89.42it/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 556/1000 [00:06&lt;00:04, 91.03it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 566/1000 [00:06&lt;00:04, 90.06it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 576/1000 [00:06&lt;00:04, 91.78it/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 586/1000 [00:06&lt;00:04, 87.98it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 597/1000 [00:07&lt;00:04, 89.17it/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 607/1000 [00:07&lt;00:04, 90.71it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 617/1000 [00:07&lt;00:04, 89.79it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 627/1000 [00:07&lt;00:04, 91.11it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 637/1000 [00:07&lt;00:04, 89.95it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 647/1000 [00:07&lt;00:03, 90.94it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 657/1000 [00:07&lt;00:03, 89.25it/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 667/1000 [00:07&lt;00:03, 91.37it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 677/1000 [00:07&lt;00:03, 87.75it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 688/1000 [00:08&lt;00:03, 87.66it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 698/1000 [00:08&lt;00:03, 90.14it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 708/1000 [00:08&lt;00:03, 89.41it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 718/1000 [00:08&lt;00:03, 91.69it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 728/1000 [00:08&lt;00:03, 89.37it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 738/1000 [00:08&lt;00:02, 91.19it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 748/1000 [00:08&lt;00:02, 89.60it/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 758/1000 [00:08&lt;00:02, 90.23it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 768/1000 [00:08&lt;00:02, 89.66it/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 778/1000 [00:09&lt;00:02, 90.36it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 788/1000 [00:09&lt;00:02, 90.14it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 798/1000 [00:09&lt;00:02, 88.86it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 807/1000 [00:09&lt;00:02, 89.10it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 818/1000 [00:09&lt;00:02, 87.47it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 829/1000 [00:09&lt;00:01, 93.30it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 839/1000 [00:09&lt;00:01, 88.79it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 850/1000 [00:09&lt;00:01, 86.64it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 862/1000 [00:09&lt;00:01, 88.77it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 874/1000 [00:10&lt;00:01, 89.97it/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 886/1000 [00:10&lt;00:01, 90.66it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 896/1000 [00:10&lt;00:01, 91.16it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 906/1000 [00:10&lt;00:01, 87.30it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 918/1000 [00:10&lt;00:00, 88.49it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 929/1000 [00:10&lt;00:00, 93.68it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 939/1000 [00:10&lt;00:00, 88.26it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 950/1000 [00:10&lt;00:00, 89.86it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 960/1000 [00:11&lt;00:00, 91.46it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 970/1000 [00:11&lt;00:00, 90.09it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 980/1000 [00:11&lt;00:00, 91.40it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 990/1000 [00:11&lt;00:00, 90.16it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:11&lt;00:00, 86.00it/s]</pre> <pre>\n</pre> In\u00a0[26]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n_, ax = plot.violins(ss_concs, ax=ax1)\nax.set_ylabel(\"Concentration / a.u.\")\n_, ax = plot.violins(ss_fluxes, ax=ax2)\nax.set_ylabel(\"Flux / a.u.\")\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4)) _, ax = plot.violins(ss_concs, ax=ax1) ax.set_ylabel(\"Concentration / a.u.\") _, ax = plot.violins(ss_fluxes, ax=ax2) ax.set_ylabel(\"Flux / a.u.\") Out[26]: <pre>Text(0, 0.5, 'Flux / a.u.')</pre> In\u00a0[27]: Copied! <pre>surrogate_features = get_label_distribution_at_time(\n    model=model,\n    label_variables=label_variables,\n    label_maps=label_maps,\n    time=5,\n    ss_concs=ss_concs,\n    ss_fluxes=ss_fluxes,\n    initial_labels={\"x1\": 0},\n)\n_, ax = plot.violins(surrogate_features)\nax.set_ylabel(\"Relative label distribution\")\n</pre> surrogate_features = get_label_distribution_at_time(     model=model,     label_variables=label_variables,     label_maps=label_maps,     time=5,     ss_concs=ss_concs,     ss_fluxes=ss_fluxes,     initial_labels={\"x1\": 0}, ) _, ax = plot.violins(surrogate_features) ax.set_ylabel(\"Relative label distribution\") <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 1/1000 [00:00&lt;02:40,  6.22it/s]</pre> <pre>\r  1%|          | 8/1000 [00:00&lt;00:27, 35.66it/s]</pre> <pre>\r  1%|\u258f         | 13/1000 [00:00&lt;00:29, 33.08it/s]</pre> <pre>\r  2%|\u258f         | 20/1000 [00:00&lt;00:22, 43.12it/s]</pre> <pre>\r  2%|\u258e         | 25/1000 [00:00&lt;00:24, 40.21it/s]</pre> <pre>\r  3%|\u258e         | 31/1000 [00:00&lt;00:21, 44.23it/s]</pre> <pre>\r  4%|\u258e         | 37/1000 [00:00&lt;00:22, 42.74it/s]</pre> <pre>\r  4%|\u258d         | 43/1000 [00:01&lt;00:21, 45.22it/s]</pre> <pre>\r  5%|\u258d         | 49/1000 [00:01&lt;00:21, 43.98it/s]</pre> <pre>\r  5%|\u258c         | 54/1000 [00:01&lt;00:20, 45.47it/s]</pre> <pre>\r  6%|\u258c         | 59/1000 [00:01&lt;00:20, 46.47it/s]</pre> <pre>\r  6%|\u258b         | 64/1000 [00:01&lt;00:20, 45.85it/s]</pre> <pre>\r  7%|\u258b         | 69/1000 [00:01&lt;00:22, 42.21it/s]</pre> <pre>\r  7%|\u258b         | 74/1000 [00:01&lt;00:21, 44.03it/s]</pre> <pre>\r  8%|\u258a         | 80/1000 [00:01&lt;00:20, 45.06it/s]</pre> <pre>\r  8%|\u258a         | 85/1000 [00:02&lt;00:21, 42.74it/s]</pre> <pre>\r  9%|\u2589         | 90/1000 [00:02&lt;00:20, 44.03it/s]</pre> <pre>\r 10%|\u2589         | 95/1000 [00:02&lt;00:19, 45.59it/s]</pre> <pre>\r 10%|\u2588         | 100/1000 [00:02&lt;00:20, 43.41it/s]</pre> <pre>\r 10%|\u2588         | 105/1000 [00:02&lt;00:20, 43.66it/s]</pre> <pre>\r 11%|\u2588         | 111/1000 [00:02&lt;00:19, 44.63it/s]</pre> <pre>\r 12%|\u2588\u258f        | 116/1000 [00:02&lt;00:20, 42.60it/s]</pre> <pre>\r 12%|\u2588\u258f        | 123/1000 [00:02&lt;00:19, 44.13it/s]</pre> <pre>\r 13%|\u2588\u258e        | 128/1000 [00:02&lt;00:19, 43.99it/s]</pre> <pre>\r 13%|\u2588\u258e        | 134/1000 [00:03&lt;00:18, 46.63it/s]</pre> <pre>\r 14%|\u2588\u258d        | 139/1000 [00:03&lt;00:20, 42.16it/s]</pre> <pre>\r 15%|\u2588\u258d        | 146/1000 [00:03&lt;00:18, 45.48it/s]</pre> <pre>\r 15%|\u2588\u258c        | 151/1000 [00:03&lt;00:19, 43.67it/s]</pre> <pre>\r 16%|\u2588\u258c        | 156/1000 [00:03&lt;00:18, 44.76it/s]</pre> <pre>\r 16%|\u2588\u258c        | 162/1000 [00:03&lt;00:19, 43.09it/s]</pre> <pre>\r 17%|\u2588\u258b        | 168/1000 [00:03&lt;00:17, 46.25it/s]</pre> <pre>\r 17%|\u2588\u258b        | 174/1000 [00:04&lt;00:18, 44.28it/s]</pre> <pre>\r 18%|\u2588\u258a        | 180/1000 [00:04&lt;00:17, 46.58it/s]</pre> <pre>\r 18%|\u2588\u258a        | 185/1000 [00:04&lt;00:17, 46.88it/s]</pre> <pre>\r 19%|\u2588\u2589        | 190/1000 [00:04&lt;00:18, 44.80it/s]</pre> <pre>\r 20%|\u2588\u2589        | 196/1000 [00:04&lt;00:18, 44.44it/s]</pre> <pre>\r 20%|\u2588\u2588        | 202/1000 [00:04&lt;00:17, 45.43it/s]</pre> <pre>\r 21%|\u2588\u2588        | 207/1000 [00:04&lt;00:17, 46.41it/s]</pre> <pre>\r 21%|\u2588\u2588        | 212/1000 [00:04&lt;00:17, 44.50it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 218/1000 [00:04&lt;00:17, 45.10it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 224/1000 [00:05&lt;00:17, 44.40it/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 230/1000 [00:05&lt;00:16, 45.73it/s]</pre> <pre>\r 24%|\u2588\u2588\u258e       | 236/1000 [00:05&lt;00:16, 45.50it/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 242/1000 [00:05&lt;00:16, 46.59it/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 248/1000 [00:05&lt;00:16, 44.98it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 254/1000 [00:05&lt;00:15, 46.68it/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 260/1000 [00:05&lt;00:16, 44.43it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 266/1000 [00:06&lt;00:15, 46.75it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 272/1000 [00:06&lt;00:16, 43.92it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 278/1000 [00:06&lt;00:15, 46.45it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 284/1000 [00:06&lt;00:16, 43.60it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 289/1000 [00:06&lt;00:15, 45.04it/s]</pre> <pre>\r 30%|\u2588\u2588\u2589       | 296/1000 [00:06&lt;00:16, 43.59it/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 303/1000 [00:06&lt;00:14, 49.68it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 309/1000 [00:06&lt;00:15, 45.82it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 315/1000 [00:07&lt;00:14, 47.60it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 320/1000 [00:07&lt;00:15, 43.10it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 326/1000 [00:07&lt;00:14, 46.62it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 332/1000 [00:07&lt;00:15, 44.33it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 337/1000 [00:07&lt;00:14, 45.27it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 342/1000 [00:07&lt;00:14, 45.66it/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258d      | 347/1000 [00:07&lt;00:14, 45.54it/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258c      | 352/1000 [00:07&lt;00:14, 43.66it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 358/1000 [00:08&lt;00:14, 44.58it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258b      | 363/1000 [00:08&lt;00:14, 44.09it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 369/1000 [00:08&lt;00:13, 47.75it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 374/1000 [00:08&lt;00:14, 43.50it/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 379/1000 [00:08&lt;00:14, 43.48it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u258a      | 386/1000 [00:08&lt;00:13, 44.05it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 391/1000 [00:08&lt;00:13, 44.45it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 396/1000 [00:08&lt;00:13, 45.48it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 402/1000 [00:09&lt;00:13, 43.09it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 409/1000 [00:09&lt;00:12, 46.54it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588\u258f     | 414/1000 [00:09&lt;00:13, 42.99it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 420/1000 [00:09&lt;00:12, 46.98it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258e     | 425/1000 [00:09&lt;00:13, 43.62it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 430/1000 [00:09&lt;00:13, 43.63it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 435/1000 [00:09&lt;00:12, 44.29it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 440/1000 [00:09&lt;00:12, 44.85it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 445/1000 [00:10&lt;00:13, 41.84it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 451/1000 [00:10&lt;00:12, 44.43it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 456/1000 [00:10&lt;00:12, 43.11it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 461/1000 [00:10&lt;00:13, 41.43it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 467/1000 [00:10&lt;00:12, 44.06it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 472/1000 [00:10&lt;00:12, 43.44it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 477/1000 [00:10&lt;00:12, 41.83it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 483/1000 [00:10&lt;00:11, 44.36it/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 488/1000 [00:11&lt;00:11, 43.14it/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 493/1000 [00:11&lt;00:12, 41.89it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 499/1000 [00:11&lt;00:11, 43.73it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 504/1000 [00:11&lt;00:11, 43.54it/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 509/1000 [00:11&lt;00:11, 42.05it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 515/1000 [00:11&lt;00:11, 43.66it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 520/1000 [00:11&lt;00:10, 44.07it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258e    | 525/1000 [00:11&lt;00:11, 42.20it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 531/1000 [00:12&lt;00:10, 43.52it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 536/1000 [00:12&lt;00:10, 43.92it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 541/1000 [00:12&lt;00:10, 42.03it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 546/1000 [00:12&lt;00:10, 43.65it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 551/1000 [00:12&lt;00:10, 44.52it/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 556/1000 [00:12&lt;00:10, 43.70it/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 561/1000 [00:12&lt;00:10, 42.34it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 566/1000 [00:12&lt;00:10, 42.67it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 572/1000 [00:12&lt;00:09, 44.69it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 577/1000 [00:13&lt;00:09, 43.21it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 583/1000 [00:13&lt;00:09, 45.01it/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 588/1000 [00:13&lt;00:09, 44.44it/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 593/1000 [00:13&lt;00:09, 44.44it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 599/1000 [00:13&lt;00:09, 44.13it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 604/1000 [00:13&lt;00:08, 45.19it/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 610/1000 [00:13&lt;00:08, 48.12it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 615/1000 [00:13&lt;00:08, 43.03it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 621/1000 [00:14&lt;00:08, 46.80it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 627/1000 [00:14&lt;00:08, 43.74it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 633/1000 [00:14&lt;00:07, 47.06it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 638/1000 [00:14&lt;00:07, 47.57it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 643/1000 [00:14&lt;00:08, 43.15it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 648/1000 [00:14&lt;00:07, 44.25it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 654/1000 [00:14&lt;00:07, 46.13it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 659/1000 [00:14&lt;00:07, 42.96it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 664/1000 [00:15&lt;00:07, 43.93it/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 669/1000 [00:15&lt;00:07, 43.94it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 675/1000 [00:15&lt;00:07, 43.09it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 681/1000 [00:15&lt;00:07, 44.27it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 686/1000 [00:15&lt;00:07, 44.58it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 691/1000 [00:15&lt;00:07, 42.98it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 697/1000 [00:15&lt;00:06, 43.75it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 702/1000 [00:15&lt;00:06, 43.22it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 707/1000 [00:15&lt;00:06, 44.53it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 712/1000 [00:16&lt;00:06, 45.51it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 717/1000 [00:16&lt;00:06, 42.94it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 722/1000 [00:16&lt;00:06, 44.74it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 728/1000 [00:16&lt;00:06, 44.94it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 733/1000 [00:16&lt;00:06, 42.85it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 739/1000 [00:16&lt;00:05, 46.21it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 744/1000 [00:16&lt;00:05, 43.63it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 749/1000 [00:16&lt;00:05, 44.78it/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 755/1000 [00:17&lt;00:05, 43.49it/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 760/1000 [00:17&lt;00:05, 43.61it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 766/1000 [00:17&lt;00:04, 46.87it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 771/1000 [00:17&lt;00:05, 42.98it/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 776/1000 [00:17&lt;00:05, 44.16it/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 781/1000 [00:17&lt;00:04, 45.21it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 786/1000 [00:17&lt;00:04, 45.04it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 791/1000 [00:17&lt;00:04, 43.33it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 797/1000 [00:18&lt;00:04, 44.66it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 802/1000 [00:18&lt;00:04, 45.02it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 807/1000 [00:18&lt;00:04, 44.37it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 813/1000 [00:18&lt;00:04, 44.41it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 818/1000 [00:18&lt;00:04, 44.99it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 824/1000 [00:18&lt;00:03, 48.76it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 829/1000 [00:18&lt;00:03, 43.18it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 834/1000 [00:18&lt;00:03, 43.30it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 841/1000 [00:19&lt;00:03, 43.57it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 847/1000 [00:19&lt;00:03, 47.23it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 852/1000 [00:19&lt;00:03, 46.65it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 857/1000 [00:19&lt;00:03, 41.99it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 864/1000 [00:19&lt;00:02, 45.80it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 869/1000 [00:19&lt;00:02, 44.16it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 875/1000 [00:19&lt;00:02, 45.46it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 880/1000 [00:19&lt;00:02, 44.97it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 885/1000 [00:19&lt;00:02, 45.24it/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 891/1000 [00:20&lt;00:02, 44.04it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 896/1000 [00:20&lt;00:02, 43.67it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 902/1000 [00:20&lt;00:02, 47.65it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 907/1000 [00:20&lt;00:02, 42.81it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 912/1000 [00:20&lt;00:01, 44.48it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 917/1000 [00:20&lt;00:01, 44.86it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 922/1000 [00:20&lt;00:01, 45.68it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 927/1000 [00:20&lt;00:01, 42.29it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 932/1000 [00:21&lt;00:01, 43.19it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 937/1000 [00:21&lt;00:01, 44.86it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 942/1000 [00:21&lt;00:01, 43.52it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 947/1000 [00:21&lt;00:01, 43.14it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 952/1000 [00:21&lt;00:01, 42.92it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 957/1000 [00:21&lt;00:00, 44.60it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 962/1000 [00:21&lt;00:00, 43.04it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 967/1000 [00:21&lt;00:00, 44.30it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 972/1000 [00:21&lt;00:00, 44.00it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 977/1000 [00:22&lt;00:00, 43.11it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 982/1000 [00:22&lt;00:00, 41.76it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 988/1000 [00:22&lt;00:00, 44.66it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 993/1000 [00:22&lt;00:00, 43.24it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 998/1000 [00:22&lt;00:00, 42.87it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:22&lt;00:00, 44.07it/s]</pre> <pre>\n</pre> <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/tmp/ipykernel_2993/4087817580.py in ?()\n      6     ss_concs=ss_concs,\n      7     ss_fluxes=ss_fluxes,\n      8     initial_labels={\"x1\": 0},\n      9 )\n---&gt; 10 _, ax = plot.violins(surrogate_features)\n     11 ax.set_ylabel(\"Relative label distribution\")\n\n~/work/MxlPy/MxlPy/src/mxlpy/plot.py in ?(df, ax, grid)\n   1010     grid: bool = True,\n   1011 ) -&gt; FigAx:\n   1012     \"\"\"Plot multiple violins on the same axis.\"\"\"\n   1013     fig, ax = _default_fig_ax(ax=ax, grid=grid)\n-&gt; 1014     sns.violinplot(df, ax=ax)\n   1015     _default_labels(ax=ax, xlabel=\"\", ylabel=None)\n   1016     return fig, ax\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/categorical.py in ?(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs)\n   1721     legend=\"auto\", scale=deprecated, scale_hue=deprecated, bw=deprecated,\n   1722     inner_kws=None, ax=None, **kwargs,\n   1723 ):\n   1724 \n-&gt; 1725     p = _CategoricalPlotter(\n   1726         data=data,\n   1727         variables=dict(x=x, y=y, hue=hue),\n   1728         order=order,\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/categorical.py in ?(self, data, variables, order, orient, require_numeric, color, legend)\n     63         color=None,\n     64         legend=\"auto\",\n     65     ):\n     66 \n---&gt; 67         super().__init__(data=data, variables=variables)\n     68 \n     69         # This method takes care of some bookkeeping that is necessary because the\n     70         # original categorical plots (prior to the 2021 refactor) had some rules that\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/_base.py in ?(self, data, variables)\n    630         # be better handled by an internal axis information object that tracks\n    631         # such information and is set up by the scale_* methods. The analogous\n    632         # information for numeric axes would be information about log scales.\n    633         self._var_ordered = {\"x\": False, \"y\": False}  # alt., used DefaultDict\n--&gt; 634         self.assign_variables(data, variables)\n    635 \n    636         # TODO Lots of tests assume that these are called to initialize the\n    637         # mappings to default values on class initialization. I'd prefer to\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/_base.py in ?(self, data, variables)\n    669         y = variables.get(\"y\", None)\n    670 \n    671         if x is None and y is None:\n    672             self.input_format = \"wide\"\n--&gt; 673             frame, names = self._assign_variables_wideform(data, **variables)\n    674         else:\n    675             # When dealing with long-form input, use the newer PlotData\n    676             # object (internal but introduced for the objects interface)\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/_base.py in ?(self, data, **kwargs)\n    791             # DataFrame objects from other libraries\n    792             wide_data = pd.DataFrame(data, copy=True)\n    793 \n    794             # At this point we should reduce the dataframe to numeric cols\n--&gt; 795             numeric_cols = [\n    796                 k for k, v in wide_data.items() if variable_type(v) == \"numeric\"\n    797             ]\n    798             wide_data = wide_data[numeric_cols]\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/seaborn/_base.py in ?(vector, boolean_type)\n   1519         )\n   1520         try:\n   1521             if np.isin(vector, [0, 1]).all():\n   1522                 return VariableType(boolean_type)\n-&gt; 1523         except TypeError:\n   1524             # .isin comparison is not guaranteed to be possible under NumPy\n   1525             # casting rules, depending on the (unknown) dtype of 'vector'\n   1526             pass\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py in ?(element, test_elements, assume_unique, invert, kind)\n   1134     array([[False,  True],\n   1135            [ True, False]])\n   1136     \"\"\"\n   1137     element = np.asarray(element)\n-&gt; 1138     return _in1d(element, test_elements, assume_unique=assume_unique,\n   1139                  invert=invert, kind=kind).reshape(element.shape)\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py in ?(ar1, ar2, assume_unique, invert, kind)\n    981                 mask &amp;= (ar1 != a)\n    982         else:\n    983             mask = np.zeros(len(ar1), dtype=bool)\n    984             for a in ar2:\n--&gt; 985                 mask |= (ar1 == a)\n    986         return mask\n    987 \n    988     # Otherwise use sorting\n\n~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pandas/core/generic.py in ?(self)\n   1575     @final\n   1576     def __nonzero__(self) -&gt; NoReturn:\n-&gt; 1577         raise ValueError(\n   1578             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n   1579             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\n   1580         )\n\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().</pre> In\u00a0[28]: Copied! <pre>estimator, losses = npe.torch.train_steady_state(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    batch_size=100,\n    epochs=250,\n)\n\nax = losses.plot()\nax.set_ylim(0, None)\n</pre> estimator, losses = npe.torch.train_steady_state(     features=surrogate_features,     targets=surrogate_targets,     batch_size=100,     epochs=250, )  ax = losses.plot() ax.set_ylim(0, None) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pandas/core/series.py:248, in _coerce_method.&lt;locals&gt;.wrapper(self)\n    247     return converter(self.iloc[0])\n--&gt; 248 raise TypeError(f\"cannot convert the series to {converter}\")\n\nTypeError: cannot convert the series to &lt;class 'float'&gt;\n\nThe above exception was the direct cause of the following exception:\n\nValueError                                Traceback (most recent call last)\nCell In[28], line 1\n----&gt; 1 estimator, losses = npe.torch.train_steady_state(\n      2     features=surrogate_features,\n      3     targets=surrogate_targets,\n      4     batch_size=100,\n      5     epochs=250,\n      6 )\n      8 ax = losses.plot()\n      9 ax.set_ylim(0, None)\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/npe/_torch.py:317, in train_steady_state(features, targets, epochs, batch_size, model, optimizer_cls, device)\n    280 def train_steady_state(\n    281     features: pd.DataFrame,\n    282     targets: pd.DataFrame,\n   (...)    287     device: torch.device = DefaultDevice,\n    288 ) -&gt; tuple[SteadyState, pd.Series]:\n    289     \"\"\"Train a PyTorch steady state estimator.\n    290 \n    291     This function trains a neural network model to estimate steady state data\n   (...)    309 \n    310     \"\"\"\n    311     trainer = SteadyStateTrainer(\n    312         features=features,\n    313         targets=targets,\n    314         model=model,\n    315         optimizer_cls=optimizer_cls,\n    316         device=device,\n--&gt; 317     ).train(epochs=epochs, batch_size=batch_size)\n    319     return trainer.get_estimator(), trainer.get_loss()\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/npe/_torch.py:159, in SteadyStateTrainer.train(self, epochs, batch_size)\n    147 def train(\n    148     self,\n    149     epochs: int,\n    150     batch_size: int | None = None,\n    151 ) -&gt; Self:\n    152     \"\"\"Train the model using the provided features and targets.\n    153 \n    154     Args:\n   (...)    157 \n    158     \"\"\"\n--&gt; 159     losses = train(\n    160         model=self.model,\n    161         features=self.features.to_numpy(),\n    162         targets=self.targets.to_numpy(),\n    163         epochs=epochs,\n    164         optimizer=self.optimizer,\n    165         batch_size=batch_size,\n    166         loss_fn=self.loss_fn,\n    167         device=self.device,\n    168     )\n    170     if len(self.losses) &gt; 0:\n    171         losses.index += self.losses[-1].index[-1]\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/nn/_torch.py:67, in train(model, features, targets, epochs, optimizer, device, batch_size, loss_fn)\n     48 \"\"\"Train the neural network using mini-batch gradient descent.\n     49 \n     50 Args:\n   (...)     62 \n     63 \"\"\"\n     64 losses = {}\n     66 data = TensorDataset(\n---&gt; 67     torch.tensor(features.astype(np.float32), dtype=torch.float32, device=device),\n     68     torch.tensor(targets.astype(np.float32), dtype=torch.float32, device=device),\n     69 )\n     70 data_loader = DataLoader(\n     71     data,\n     72     batch_size=len(features) if batch_size is None else batch_size,\n     73     shuffle=True,\n     74 )\n     76 for i in tqdm.trange(epochs):\n\nValueError: setting an array element with a sequence.</pre> In\u00a0[29]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(\n    1,\n    2,\n    figsize=(8, 3),\n    layout=\"constrained\",\n    sharex=True,\n    sharey=False,\n)\n\nax = sns.kdeplot(surrogate_targets, fill=True, ax=ax1)\nax.set_title(\"Prior\")\n\nposterior = estimator.predict(surrogate_features)\n\nax = sns.kdeplot(posterior, fill=True, ax=ax2)\nax.set_title(\"Posterior\")\nax2.set_ylim(*ax1.get_ylim())\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(     1,     2,     figsize=(8, 3),     layout=\"constrained\",     sharex=True,     sharey=False, )  ax = sns.kdeplot(surrogate_targets, fill=True, ax=ax1) ax.set_title(\"Prior\")  posterior = estimator.predict(surrogate_features)  ax = sns.kdeplot(posterior, fill=True, ax=ax2) ax.set_title(\"Posterior\") ax2.set_ylim(*ax1.get_ylim()) plt.show() <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[29], line 13\n     10 ax = sns.kdeplot(surrogate_targets, fill=True, ax=ax1)\n     11 ax.set_title(\"Prior\")\n---&gt; 13 posterior = estimator.predict(surrogate_features)\n     15 ax = sns.kdeplot(posterior, fill=True, ax=ax2)\n     16 ax.set_title(\"Posterior\")\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/npe/_torch.py:68, in SteadyState.predict(self, features)\n     66 \"\"\"Predict the target values for the given features.\"\"\"\n     67 with torch.no_grad():\n---&gt; 68     pred = self.model(torch.tensor(features.to_numpy(), dtype=torch.float32))\n     69     return pd.DataFrame(pred, columns=self.parameter_names)\n\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.</pre> In\u00a0[30]: Copied! <pre>_ = plot.heatmap(inverse_parameter_elasticity(estimator, surrogate_features.iloc[0]))\n</pre> _ = plot.heatmap(inverse_parameter_elasticity(estimator, surrogate_features.iloc[0])) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[30], line 1\n----&gt; 1 _ = plot.heatmap(inverse_parameter_elasticity(estimator, surrogate_features.iloc[0]))\n\nCell In[22], line 48, in inverse_parameter_elasticity(estimator, datum, normalized, displacement)\n     41 def inverse_parameter_elasticity(\n     42     estimator: AbstractEstimator,\n     43     datum: pd.Series,\n   (...)     46     displacement: float = 1e-4,\n     47 ) -&gt; pd.DataFrame:\n---&gt; 48     ref = estimator.predict(datum).iloc[0, :]\n     50     coefs = {}\n     51     for name, value in datum.items():\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/npe/_torch.py:68, in SteadyState.predict(self, features)\n     66 \"\"\"Predict the target values for the given features.\"\"\"\n     67 with torch.no_grad():\n---&gt; 68     pred = self.model(torch.tensor(features.to_numpy(), dtype=torch.float32))\n     69     return pd.DataFrame(pred, columns=self.parameter_names)\n\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.</pre> In\u00a0[31]: Copied! <pre>elasticities = pd.DataFrame(\n    {\n        k: inverse_parameter_elasticity(estimator, i).loc[\"vmax_2b\"]\n        for k, i in surrogate_features.iterrows()\n    }\n).T\n\n_ = plot.violins(elasticities)\n</pre> elasticities = pd.DataFrame(     {         k: inverse_parameter_elasticity(estimator, i).loc[\"vmax_2b\"]         for k, i in surrogate_features.iterrows()     } ).T  _ = plot.violins(elasticities) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[31], line 3\n      1 elasticities = pd.DataFrame(\n      2     {\n----&gt; 3         k: inverse_parameter_elasticity(estimator, i).loc[\"vmax_2b\"]\n      4         for k, i in surrogate_features.iterrows()\n      5     }\n      6 ).T\n      8 _ = plot.violins(elasticities)\n\nCell In[22], line 48, in inverse_parameter_elasticity(estimator, datum, normalized, displacement)\n     41 def inverse_parameter_elasticity(\n     42     estimator: AbstractEstimator,\n     43     datum: pd.Series,\n   (...)     46     displacement: float = 1e-4,\n     47 ) -&gt; pd.DataFrame:\n---&gt; 48     ref = estimator.predict(datum).iloc[0, :]\n     50     coefs = {}\n     51     for name, value in datum.items():\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/npe/_torch.py:68, in SteadyState.predict(self, features)\n     66 \"\"\"Predict the target values for the given features.\"\"\"\n     67 with torch.no_grad():\n---&gt; 68     pred = self.model(torch.tensor(features.to_numpy(), dtype=torch.float32))\n     69     return pd.DataFrame(pred, columns=self.parameter_names)\n\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"mxl.html#mechanistic-learning","title":"Mechanistic Learning\u00b6","text":"<p>Mechanistic learning is the intersection of mechanistic modelling and machine learning. mxlpy currently supports two such approaches: surrogates and neural posterior estimation.</p> <p>In the following we will mostly use the <code>mxlpy.surrogates</code> and <code>mxlpy.npe</code> modules to learn about both approaches.</p>"},{"location":"mxl.html#surrogate-models","title":"Surrogate models\u00b6","text":"<p>Surrogate models replace whole parts of a mechanistic model (or even the entire model) with machine learning models.</p> <p>This allows combining together multiple models of arbitrary size, without having to worry about the internal state of each model. They are especially useful for improving the description of boundary effects, e.g. a dynamic description of downstream consumption.</p>"},{"location":"mxl.html#manual-construction","title":"Manual construction\u00b6","text":"<p>Surrogates can have return two kind of values in <code>mxply</code>: <code>derived quantities</code> and <code>reactions</code>.</p> <p>We will start by defining a polynomial surrogate that will get the value of a variable <code>x</code> and output the derived quantity <code>y</code>. Note that due to their nature surrogates can take multiple inputs and return multiple outputs, so we will always use iterables when defining them.</p> <p>We then also add a derived value <code>z</code> that uses the output of our surrogate to see that we are getting the correct output.</p>"},{"location":"mxl.html#training-a-surrogate-from-data-and-using-it","title":"Training a surrogate from data and using it\u00b6","text":""},{"location":"mxl.html#create-data","title":"Create data\u00b6","text":"<p>The surrogates used in the following will all use the steady-state fluxes depending on the inputs.</p> <p>We can thus create the necessary training data usign <code>scan.steady_state</code>. Since this is usually a large amount of data, we recommend caching the results using <code>Cache</code>.</p>"},{"location":"mxl.html#polynomial-surrogate","title":"Polynomial surrogate\u00b6","text":"<p>We can train our polynomial surrogate using <code>train_polynomial_surrogate</code>. By default this will train polynomials for the degrees <code>(1, 2, 3, 4, 5, 6, 7)</code>, but you can change that by using the <code>degrees</code> argument. The function returns the trained surrogate and the training information for the different polynomial degrees.</p> <p>Currently the polynomial surrogates are limited to a single feature and a single target</p>"},{"location":"mxl.html#neural-network-surrogate-using-pytorch","title":"Neural network surrogate using PyTorch\u00b6","text":"<p>Neural networks are designed to capture highly complex and nonlinear relationships. Through layers of neurons and activation functions, neural networks can learn intricate patterns that are not easily represented by e.g. a polynomial. They have the flexibility to approximate any continuous function, given sufficient depth and appropriate training.</p> <p>You can train a neural network surrogate based on the popular PyTorch library using <code>train_torch_surrogate</code>. That function takes the <code>features</code>, <code>targets</code> and the number of <code>epochs</code> as inputs for it's training.</p> <p><code>train_torch_surrogate</code> returns the trained surrogate, as well as the training <code>loss</code>. It is always a good idea to check whether that training loss approaches 0.</p>"},{"location":"mxl.html#re-entrant-training","title":"Re-entrant training\u00b6","text":"<p>Quite often you don't know the amount of epochs you are going to need in order to reach the required loss. In this case, you can directly use the <code>TorchSurrogateTrainer</code> class to continue training.</p>"},{"location":"mxl.html#troubleshooting","title":"Troubleshooting\u00b6","text":"<p>It often can make sense to check specific predictions of the surrogate. For example, what does it predict when the inputs are all 0?</p>"},{"location":"mxl.html#using-keras-instead-of-torch","title":"Using keras instead of torch\u00b6","text":"<p>If you installed keras, you can use it with exactly the same interface torch</p>"},{"location":"mxl.html#neural-posterior-estimation","title":"Neural posterior estimation\u00b6","text":"<p>Neural posterior estimation answers the question: what parameters could have generated the data I measured? Here you use an ODE model and prior knowledge about the parameters of interest to create synthetic data. You then use the generated synthetic data as the features and the input parameters as the targets to train an inverse problem. Once that training is successful, the neural network can now predict the input parameters for real world data.</p> <p>You can use this technique for both steady-state as well as time course data. The only difference is in using <code>scan.time_course</code>.</p> <p>Take care here to save the targets as well in case you use cached data :)</p>"},{"location":"mxl.html#train-npe","title":"Train NPE\u00b6","text":"<p>You can then train your neural posterior estimator using <code>npe.train_torch_ss_estimator</code> (or <code>npe.train_torch_time_course_estimator</code> if you have time course data).</p>"},{"location":"mxl.html#sanity-check-do-prior-and-posterior-match","title":"Sanity check: do prior and posterior match?\u00b6","text":""},{"location":"mxl.html#re-entrant-training","title":"Re-entrant training\u00b6","text":"<p>As with the surrogates you often you don't know the amount of epochs you are going to need in order to reach the required loss. For the neural posterior estimation you can use the <code>npe.TorchSteadyStateTrainer</code> and <code>npe.TorchTimeCourseTrainer</code> respectively to continue training.</p>"},{"location":"mxl.html#custom-loss-function","title":"Custom loss function\u00b6","text":"<p>You can use a custom loss function by simply injecting a function that takes the predicted tensor <code>x</code> and the data <code>y</code> and produces another tensor.</p>"},{"location":"mxl.html#label-npe","title":"Label NPE\u00b6","text":""},{"location":"mxl.html#inverse-parameter-sensitivity","title":"Inverse parameter sensitivity\u00b6","text":""},{"location":"parameter_identifiability.html","title":"Identifiability","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom mxlpy import Model, Simulator, fns, plot, unwrap\nfrom mxlpy.identify import profile_likelihood\n</pre> import numpy as np  from mxlpy import Model, Simulator, fns, plot, unwrap from mxlpy.identify import profile_likelihood <p>We start with an SIR model, which we use to generate some data (this would usually be experimentally measured data)</p> In\u00a0[2]: Copied! <pre>def sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\ndata = unwrap(Simulator(sir()).simulate(100).get_result()).variables\n_ = plot.lines(data)\n</pre> def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   data = unwrap(Simulator(sir()).simulate(100).get_result()).variables _ = plot.lines(data) <p>We then, for <code>n</code> different values of each parameter we are interested in, we</p> <ul> <li>draw random samples for the remaining model parameters</li> <li>fit the model to the data (excluding the parameter we are interested in) and note the final error</li> <li>visualise the error for each parameter value</li> </ul> <p>The error for a parameter should show a clear minimum around the different values used, otherwise it is not identifiable</p> In\u00a0[3]: Copied! <pre>errors_beta = profile_likelihood(\n    sir(),\n    data=data,\n    parameter_name=\"beta\",\n    parameter_values=np.linspace(0.2 * 0.5, 0.2 * 1.5, 10),\n    n_random=10,\n)\n\nfig, ax = plot.lines(errors_beta, legend=False)\nax.set(title=\"beta\", xlabel=\"parameter value\", ylabel=\"abs(error)\")\nplot.show()\n</pre> errors_beta = profile_likelihood(     sir(),     data=data,     parameter_name=\"beta\",     parameter_values=np.linspace(0.2 * 0.5, 0.2 * 1.5, 10),     n_random=10, )  fig, ax = plot.lines(errors_beta, legend=False) ax.set(title=\"beta\", xlabel=\"parameter value\", ylabel=\"abs(error)\") plot.show() <pre>\rbeta:   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\rbeta:  10%|\u2588         | 1/10 [00:02&lt;00:26,  2.99s/it]</pre> <pre>\rbeta:  20%|\u2588\u2588        | 2/10 [00:05&lt;00:23,  2.91s/it]</pre> <pre>\rbeta:  30%|\u2588\u2588\u2588       | 3/10 [00:08&lt;00:20,  2.93s/it]</pre> <pre>\rbeta:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:12&lt;00:19,  3.22s/it]</pre> <pre>\rbeta:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:16&lt;00:16,  3.34s/it]</pre> <pre>\rbeta:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:19&lt;00:13,  3.45s/it]</pre> <pre>\rbeta:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:23&lt;00:10,  3.42s/it]</pre> <pre>\rbeta:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:26&lt;00:06,  3.34s/it]</pre> <pre>\rbeta:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:29&lt;00:03,  3.35s/it]</pre> <pre>\rbeta: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:32&lt;00:00,  3.35s/it]</pre> <pre>\rbeta: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:32&lt;00:00,  3.29s/it]</pre> <pre>\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 errors_beta = profile_likelihood(\n      2     sir(),\n      3     data=data,\n      4     parameter_name=\"beta\",\n      5     parameter_values=np.linspace(0.2 * 0.5, 0.2 * 1.5, 10),\n      6     n_random=10,\n      7 )\n      9 fig, ax = plot.lines(errors_beta, legend=False)\n     10 ax.set(title=\"beta\", xlabel=\"parameter value\", ylabel=\"abs(error)\")\n\nFile ~/work/MxlPy/MxlPy/src/mxlpy/identify.py:78, in profile_likelihood(model, data, parameter_name, parameter_values, n_random, loss_fn)\n     68     model.update_parameter(parameter_name, value)\n     69     res[value] = parallelise(\n     70         partial(\n     71             _mc_fit_time_course_worker, model=model, data=data, loss_fn=loss_fn\n   (...)     76         disable_tqdm=True,\n     77     )\n---&gt; 78 errors = pd.DataFrame(res, dtype=float).T.abs().mean(axis=1)\n     79 errors.index.name = \"fitting error\"\n     80 return errors\n\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pandas/core/generic.py:1719, in NDFrame.abs(self)\n   1651 @final\n   1652 def abs(self) -&gt; Self:\n   1653     \"\"\"\n   1654     Return a Series/DataFrame with absolute numeric value of each element.\n   1655 \n   (...)   1717     3    7   40  -50\n   1718     \"\"\"\n-&gt; 1719     res_mgr = self._mgr.apply(np.abs)\n   1720     return self._constructor_from_mgr(res_mgr, axes=res_mgr.axes).__finalize__(\n   1721         self, name=\"abs\"\n   1722     )\n\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:361, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n    358             kwargs[k] = obj[b.mgr_locs.indexer]\n    360 if callable(f):\n--&gt; 361     applied = b.apply(f, **kwargs)\n    362 else:\n    363     applied = getattr(b, f)(**kwargs)\n\nFile ~/work/MxlPy/MxlPy/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393, in Block.apply(self, func, **kwargs)\n    387 @final\n    388 def apply(self, func, **kwargs) -&gt; list[Block]:\n    389     \"\"\"\n    390     apply the function to my values; return a block if we are not\n    391     one\n    392     \"\"\"\n--&gt; 393     result = func(self.values, **kwargs)\n    395     result = maybe_coerce_values(result)\n    396     return self._split_op_result(result)\n\nTypeError: bad operand type for abs(): 'tuple'</pre>"},{"location":"parameter_identifiability.html#numerical-parameter-identifiability","title":"Numerical parameter identifiability\u00b6","text":"<p>See the course by Marisa Eisenberg for an excellent introduction into the topic</p>"},{"location":"parameterise.html","title":"Model parameterisation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom mxlpy import Model, fns, mc, plot\nfrom mxlpy.distributions import GaussianKde, sample\nfrom mxlpy.parameterise import get_km_and_kcat_from_brenda\n</pre> from pathlib import Path  import matplotlib.pyplot as plt  from mxlpy import Model, fns, mc, plot from mxlpy.distributions import GaussianKde, sample from mxlpy.parameterise import get_km_and_kcat_from_brenda In\u00a0[2]: Copied! <pre>kms, kcats = get_km_and_kcat_from_brenda(\n    ec=\"4.1.1.39\",\n    brenda_path=Path(\"assets\") / \"brenda_rubisco_only.json\",\n)\n\nprint(f\"Found: {len(kms)} michaelis constants\")\nkms.head()\n</pre> kms, kcats = get_km_and_kcat_from_brenda(     ec=\"4.1.1.39\",     brenda_path=Path(\"assets\") / \"brenda_rubisco_only.json\", )  print(f\"Found: {len(kms)} michaelis constants\") kms.head() <pre>Found: 668 michaelis constants\n</pre> Out[2]: value substrate organism uniprot sequence 0 0.0290 CO2 Amphicarpaea bracteata A0A1C3HPM0 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... 5 0.0510 CO2 Archaeoglobus fulgidus O28635 MAEFEIYREYVDKSYEPQKDDIVAVFRITPAEGFTIEDAAGAVAAE... 7 0.0279 CO2 Hordeum murinum A0A1C3HPQ4 MSPQTETKAGVGFKAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 8 0.0279 CO2 Hordeum brachyantherum A0A1C3HPQ0 MSPQTETKAGVGFQAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 9 0.0195 CO2 Glycine canescens A0A1C3HPP9 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... <p>As you can see above, this provides you with parameter values for different organisms and substrates. Thus, we first filter by the specific substrate we are interested in.</p> In\u00a0[3]: Copied! <pre># Filter out a specific substrate\nkms = kms[kms[\"substrate\"] == \"CO2\"]\nkcats = kcats[kcats[\"substrate\"] == \"CO2\"]\n\nprint(f\"Filtered to {len(kms)} michaelis constants\")\nkms.head()\n</pre> # Filter out a specific substrate kms = kms[kms[\"substrate\"] == \"CO2\"] kcats = kcats[kcats[\"substrate\"] == \"CO2\"]  print(f\"Filtered to {len(kms)} michaelis constants\") kms.head() <pre>Filtered to 443 michaelis constants\n</pre> Out[3]: value substrate organism uniprot sequence 0 0.0290 CO2 Amphicarpaea bracteata A0A1C3HPM0 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... 5 0.0510 CO2 Archaeoglobus fulgidus O28635 MAEFEIYREYVDKSYEPQKDDIVAVFRITPAEGFTIEDAAGAVAAE... 7 0.0279 CO2 Hordeum murinum A0A1C3HPQ4 MSPQTETKAGVGFKAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 8 0.0279 CO2 Hordeum brachyantherum A0A1C3HPQ0 MSPQTETKAGVGFQAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 9 0.0195 CO2 Glycine canescens A0A1C3HPP9 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... <p>Since these are sufficiently many values, we can create a Gaussian Kernel Density estimate of them.</p> In\u00a0[4]: Copied! <pre>km_dist = GaussianKde.from_data(kms[\"value\"])\nfig, ax = km_dist.plot(\n    xmin=kms[\"value\"].min() * 0.8,\n    xmax=kms[\"value\"].max() * 1.2,\n)\nax.set(title=f\"rubisco km for CO2, n={len(kms)}\")\nplt.show()\n</pre> km_dist = GaussianKde.from_data(kms[\"value\"]) fig, ax = km_dist.plot(     xmin=kms[\"value\"].min() * 0.8,     xmax=kms[\"value\"].max() * 1.2, ) ax.set(title=f\"rubisco km for CO2, n={len(kms)}\") plt.show() <p>This kernel density estimate we can now use exactly like other distribution in our <code>Monte-Carlo</code> routines (see the Monte Carlo notebook for more information).</p> <p>Here, we create a small toy model and then use the distribution obtained from the experimental data to calculate the steady-state distribution of the model concentration.</p> In\u00a0[5]: Copied! <pre>model = (\n    Model()\n    .add_parameters({\"k_out\": 1.0, \"km\": 1.0})\n    .add_variable(\"PGA\", 0)\n    .add_reaction(\n        \"rubisco\",\n        fns.constant,\n        args=[\"km\"],\n        stoichiometry={\"PGA\": 2},\n    )\n    .add_reaction(\n        \"outflux\",\n        fns.mass_action_1s,\n        args=[\"PGA\", \"k_out\"],\n        stoichiometry={\"PGA\": -1},\n    )\n)\n\nss = mc.steady_state(model, mc_to_scan=sample({\"km\": km_dist}, n=10))\n\nfig, ax = plt.subplots(figsize=(4, 3))\nax.set(ylabel=\"Steady-state concentration\")\nplot.violins(ss.variables, ax=ax)\nplt.show()\n</pre> model = (     Model()     .add_parameters({\"k_out\": 1.0, \"km\": 1.0})     .add_variable(\"PGA\", 0)     .add_reaction(         \"rubisco\",         fns.constant,         args=[\"km\"],         stoichiometry={\"PGA\": 2},     )     .add_reaction(         \"outflux\",         fns.mass_action_1s,         args=[\"PGA\", \"k_out\"],         stoichiometry={\"PGA\": -1},     ) )  ss = mc.steady_state(model, mc_to_scan=sample({\"km\": km_dist}, n=10))  fig, ax = plt.subplots(figsize=(4, 3)) ax.set(ylabel=\"Steady-state concentration\") plot.violins(ss.variables, ax=ax) plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:00&lt;00:00, 59.03it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 61.07it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about parameter scans in mxlpy.           Congratulations!"},{"location":"parameterise.html#model-parameterisation","title":"Model parameterisation\u00b6","text":"<p>Obtaining experimentally measured parameters can be challenging.</p> <p>Using the Brenda enzymes database we can obtain  distributions of enzymatic parameters for a wide range of organisms.</p> <p>We can do that with the <code>mxlpy.parameterise</code> module.</p> <p>These distributions can then in turn be used with our Monte-Carlo methods to capture the range of possible behaviour your model can exhibit.</p> + = <p>In order to obtain the parameters for a given Enzyme commision number (ec) we will manually download the database. You have to do this manually due to the brenda licensing terms.</p> <p>Note: we have created a small copy of just the rubisco data here to keep the documentation running. Adjust your <code>brenda_path</code> accordingly</p>"},{"location":"report.html","title":"Reporting","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom IPython.display import Markdown\nfrom matplotlib.figure import Figure\n\nfrom example_models import get_sir, get_sird\nfrom mxlpy import Model, Simulator, plot, report, unwrap\n\n\ndef plot_difference(r_old: pd.DataFrame, r_new: pd.DataFrame) -&gt; Figure:\n    rel_diff = (r_new - r_old) / r_old\n    largest_diff = rel_diff.abs().mean().fillna(0).sort_values().tail(n=3)\n\n    fig, ax = plot.one_axes()\n    plot.lines(r_new, ax=ax)\n    lines = dict(zip(r_new.columns, ax.lines, strict=True))\n    for f, i in enumerate(reversed(largest_diff.index), start=2):\n        line = lines[i]\n        line.set_linewidth(line.get_linewidth() * f)\n\n    plot.reset_prop_cycle(ax)\n    plot.lines(r_old, ax=ax, alpha=0.25, legend=False)\n    ax.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\n    return fig\n</pre> from pathlib import Path  import matplotlib.pyplot as plt import pandas as pd from IPython.display import Markdown from matplotlib.figure import Figure  from example_models import get_sir, get_sird from mxlpy import Model, Simulator, plot, report, unwrap   def plot_difference(r_old: pd.DataFrame, r_new: pd.DataFrame) -&gt; Figure:     rel_diff = (r_new - r_old) / r_old     largest_diff = rel_diff.abs().mean().fillna(0).sort_values().tail(n=3)      fig, ax = plot.one_axes()     plot.lines(r_new, ax=ax)     lines = dict(zip(r_new.columns, ax.lines, strict=True))     for f, i in enumerate(reversed(largest_diff.index), start=2):         line = lines[i]         line.set_linewidth(line.get_linewidth() * f)      plot.reset_prop_cycle(ax)     plot.lines(r_old, ax=ax, alpha=0.25, legend=False)     ax.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")     return fig In\u00a0[2]: Copied! <pre>md = report.markdown(\n    get_sir(),\n    get_sird(),\n)\n\n# IPython Display\nMarkdown(md)\n</pre> md = report.markdown(     get_sir(),     get_sird(), )  # IPython Display Markdown(md) Out[2]: <p>You can further expand the report with user-defined analysis functions that are being run for both models. Here for example we perform a normal simulation and then plot the time course, highlighting the variables that changed the most.</p> <p>All user-defined analysis functions have to take two models and the directory where plots are to be stored as an input and output a description in markdown as well as the path of the final image, so that it can be inserted into the report correctly.</p> In\u00a0[3]: Copied! <pre>def analyse_concentrations(m1: Model, m2: Model, img_dir: Path) -&gt; tuple[str, Path]:\n    r_old = unwrap(Simulator(m1).simulate(100).get_result())\n    r_new = unwrap(Simulator(m2).simulate(100).get_result())\n    fig = plot_difference(r_old.variables, r_new.variables)\n    fig.savefig((path := img_dir / \"concentration.png\"), dpi=300)\n    plt.close(fig)\n    return \"## Comparison of largest changing\", path\n\n\nmd = report.markdown(\n    get_sir(),\n    get_sird(),\n    analyses=[analyse_concentrations],\n)\n\n# IPython Display\nMarkdown(md)\n</pre> def analyse_concentrations(m1: Model, m2: Model, img_dir: Path) -&gt; tuple[str, Path]:     r_old = unwrap(Simulator(m1).simulate(100).get_result())     r_new = unwrap(Simulator(m2).simulate(100).get_result())     fig = plot_difference(r_old.variables, r_new.variables)     fig.savefig((path := img_dir / \"concentration.png\"), dpi=300)     plt.close(fig)     return \"## Comparison of largest changing\", path   md = report.markdown(     get_sir(),     get_sird(),     analyses=[analyse_concentrations], )  # IPython Display Markdown(md) Out[3]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"report.html#reports","title":"Reports\u00b6","text":"<p>To make it easy to communicate changes between two models, <code>mxlpy</code> has conveniece functions in the <code>report</code> module. By default, the <code>report.markdown</code> function will take two models as inputs and then compare both the structure of the two models as well as numerical differences in dependent values as well as the right hand side.</p> <p>The report is color-coded consistently, with green referring to new features, orange referring to updates / changes and red referring to deleted quantities.</p>"},{"location":"report.html#report-2025-05-30","title":"Report:  2025-05-30\u00b6","text":"Model component Old New variables 3 4 parameters 2 3 derived parameters 0 0 derived variables 0 0 reactions 2 3 surrogates 0 0"},{"location":"report.html#variables","title":"Variables\u00b6","text":"Name Old Value New Value d - 0.0"},{"location":"report.html#parameters","title":"Parameters\u00b6","text":"Name Old Value New Value mu - 0.01"},{"location":"report.html#reactions","title":"Reactions\u00b6","text":"Name Old Value New Value death - $i \\mu$"},{"location":"report.html#numerical-differences-of-right-hand-side-values","title":"Numerical differences of right hand side values\u00b6","text":"Name Old Value New Value Relative Change i 0.01 0.01 12.5%"},{"location":"report.html#report-2025-05-30","title":"Report:  2025-05-30\u00b6","text":"Model component Old New variables 3 4 parameters 2 3 derived parameters 0 0 derived variables 0 0 reactions 2 3 surrogates 0 0"},{"location":"report.html#variables","title":"Variables\u00b6","text":"Name Old Value New Value d - 0.0"},{"location":"report.html#parameters","title":"Parameters\u00b6","text":"Name Old Value New Value mu - 0.01"},{"location":"report.html#reactions","title":"Reactions\u00b6","text":"Name Old Value New Value death - $i \\mu$"},{"location":"report.html#numerical-differences-of-right-hand-side-values","title":"Numerical differences of right hand side values\u00b6","text":"Name Old Value New Value Relative Change i 0.01 0.01 12.5%"},{"location":"report.html#comparison-of-largest-changing","title":"Comparison of largest changing\u00b6","text":""},{"location":"scans.html","title":"Scans","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport mxlpy as mb2\nfrom example_models import (\n    get_linear_chain_2v,\n)\nfrom mxlpy import make_protocol, plot, scan\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np import pandas as pd  import mxlpy as mb2 from example_models import (     get_linear_chain_2v, ) from mxlpy import make_protocol, plot, scan In\u00a0[2]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 3, 11)}),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 3))\nplot.lines(res.variables, ax=ax1)  # access concentrations by name\nplot.lines(res.fluxes, ax=ax2)  # access fluxes by name\n\nax1.set(ylabel=\"Concentration / a.u.\")\nax2.set(ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(1, 3, 11)}), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 3)) plot.lines(res.variables, ax=ax1)  # access concentrations by name plot.lines(res.fluxes, ax=ax2)  # access fluxes by name  ax1.set(ylabel=\"Concentration / a.u.\") ax2.set(ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 9/11 [00:00&lt;00:00, 82.05it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 66.14it/s]</pre> <pre>\n</pre> <p>All scans return a result object, which allow multiple access patterns for convenience.</p> <p>Namely, the concentrations and fluxes can be accessed by name, unpacked or combined into a single dataframe.</p> In\u00a0[3]: Copied! <pre># Access by name\n_ = res.variables\n_ = res.fluxes\n\n# scan can be unpacked\nconcs, fluxes = res\n\n# combine concs and fluxes as single dataframe\n_ = res.results\n</pre> # Access by name _ = res.variables _ = res.fluxes  # scan can be unpacked concs, fluxes = res  # combine concs and fluxes as single dataframe _ = res.results In\u00a0[4]: Copied! <pre>mb2.cartesian_product(\n    {\n        \"k1\": [1, 2],\n        \"k2\": [3, 4],\n    }\n)\n</pre> mb2.cartesian_product(     {         \"k1\": [1, 2],         \"k2\": [3, 4],     } ) Out[4]: k1 k2 0 1 3 1 1 4 2 2 3 3 2 4 In\u00a0[5]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 3),\n            \"k2\": np.linspace(1, 2, 4),\n        }\n    ),\n)\n\nres.results.head()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 3),             \"k2\": np.linspace(1, 2, 4),         }     ), )  res.results.head() <pre>\r  0%|          | 0/12 [00:00&lt;?, ?it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 10/12 [00:00&lt;00:00, 92.76it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:00&lt;00:00, 84.03it/s]</pre> <pre>\n</pre> Out[5]: x y v1 v2 v3 k1 k2 1.0 1.000000 1.00 1.0 1.0 1.0 1.0 1.333333 0.75 1.0 1.0 1.0 1.0 1.666667 0.60 1.0 1.0 1.0 1.0 2.000000 0.50 1.0 1.0 1.0 1.0 1.5 1.000000 1.50 1.5 1.5 1.5 1.5 <p>You can plot the results of a single variable of this scan using a heatmap</p> In\u00a0[6]: Copied! <pre>plot.heatmap_from_2d_idx(res.variables, variable=\"x\")\nplt.show()\n</pre> plot.heatmap_from_2d_idx(res.variables, variable=\"x\") plt.show() <p>Or create heatmaps of all passed variables at once.</p> In\u00a0[7]: Copied! <pre>plot.heatmaps_from_2d_idx(res.variables)\nplt.show()\n</pre> plot.heatmaps_from_2d_idx(res.variables) plt.show() <p>You can also combine more than two parameters, however, visualisation then becomes challenging.</p> In\u00a0[8]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 3),\n            \"k2\": np.linspace(1, 2, 4),\n            \"k3\": np.linspace(1, 2, 4),\n        }\n    ),\n)\nres.results.head()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 3),             \"k2\": np.linspace(1, 2, 4),             \"k3\": np.linspace(1, 2, 4),         }     ), ) res.results.head() <pre>\r  0%|          | 0/48 [00:00&lt;?, ?it/s]</pre> <pre>\r 21%|\u2588\u2588        | 10/48 [00:00&lt;00:00, 98.08it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 30/48 [00:00&lt;00:00, 151.64it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 48/48 [00:00&lt;00:00, 132.60it/s]</pre> <pre>\n</pre> Out[8]: x y v1 v2 v3 k1 k2 k3 1.0 1.000000 1.000000 1.00 1.00 1.0 1.0 1.0 1.333333 1.00 0.75 1.0 1.0 1.0 1.666667 1.00 0.60 1.0 1.0 1.0 2.000000 1.00 0.50 1.0 1.0 1.0 1.333333 1.000000 0.75 1.00 1.0 1.0 1.0 In\u00a0[9]: Copied! <pre>tss = scan.time_course(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),\n    time_points=np.linspace(0, 1, 11),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tss = scan.time_course(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),     time_points=np.linspace(0, 1, 11), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)  ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 70.94it/s]</pre> <pre>\n</pre> <p>Again, this works for an arbitray number of parameters.</p> In\u00a0[10]: Copied! <pre>tss = scan.time_course(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 11),\n            \"k2\": np.linspace(1, 2, 4),\n        }\n    ),\n    time_points=np.linspace(0, 1, 11),\n)\n\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tss = scan.time_course(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 11),             \"k2\": np.linspace(1, 2, 4),         }     ),     time_points=np.linspace(0, 1, 11), )   fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/44 [00:00&lt;?, ?it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 14/44 [00:00&lt;00:00, 136.42it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 40/44 [00:00&lt;00:00, 208.07it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44/44 [00:00&lt;00:00, 181.70it/s]</pre> <pre>\n</pre> <p>The scan object returned has a <code>pandas.MultiIndex</code> of <code>n x time</code>, where <code>n</code> is an index that references parameter combinations. You can access the referenced parameters using <code>.parameters</code></p> In\u00a0[11]: Copied! <pre>tss.parameters.head()\n</pre> tss.parameters.head() Out[11]: k1 k2 0 1.0 1.000000 1 1.0 1.333333 2 1.0 1.666667 3 1.0 2.000000 4 1.1 1.000000 <p>You can also easily access common aggregates like <code>mean</code> and <code>standard deviation (std)</code> using <code>get_agg_per_time</code>.</p> In\u00a0[12]: Copied! <pre>tss.get_agg_per_time(\"std\").head()\n</pre> tss.get_agg_per_time(\"std\").head() Out[12]: x y v1 v2 v3 time 0.0 7.758641e-17 1.148299e-16 0.319884 0.376987 1.148299e-16 0.1 4.593190e-02 3.336533e-02 0.319884 0.328164 3.336533e-02 0.2 8.557149e-02 5.943832e-02 0.319884 0.293370 5.943832e-02 0.3 1.198715e-01 7.999096e-02 0.319884 0.270384 7.999096e-02 0.4 1.496277e-01 9.645527e-02 0.319884 0.256845 9.645527e-02 In\u00a0[13]: Copied! <pre>res = scan.time_course_over_protocol(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),\n    protocol=make_protocol(\n        [\n            (1, {\"k1\": 1}),\n            (2, {\"k1\": 2}),\n            (3, {\"k1\": 1}),\n        ]\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(res.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(res.fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\n\nfor ax in (ax1, ax2):\n    plot.shade_protocol(res.protocol[\"k1\"], ax=ax, alpha=0.2)\nplt.show()\n</pre> res = scan.time_course_over_protocol(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),     protocol=make_protocol(         [             (1, {\"k1\": 1}),             (2, {\"k1\": 2}),             (3, {\"k1\": 1}),         ]     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(res.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(res.fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")  for ax in (ax1, ax2):     plot.shade_protocol(res.protocol[\"k1\"], ax=ax, alpha=0.2) plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 5/11 [00:00&lt;00:00, 37.58it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 45.89it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about parameter scans in mxlpy.           Congratulations!  In\u00a0[14]: Copied! <pre>import pickle\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\n\nfrom mxlpy.parallel import Cache, parallelise\n\nif TYPE_CHECKING:\n    from collections.abc import Hashable\n</pre> import pickle from pathlib import Path from typing import TYPE_CHECKING, Any  from mxlpy.parallel import Cache, parallelise  if TYPE_CHECKING:     from collections.abc import Hashable In\u00a0[15]: Copied! <pre>def square(x: float) -&gt; float:\n    return x**2\n\n\noutput = parallelise(square, [(\"a\", 2), (\"b\", 3), (\"c\", 4)])\noutput\n</pre> def square(x: float) -&gt; float:     return x**2   output = parallelise(square, [(\"a\", 2), (\"b\", 3), (\"c\", 4)]) output <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 19.77it/s]</pre> <pre>\n</pre> Out[15]: <pre>[('a', 4), ('b', 9), ('c', 16)]</pre> In\u00a0[16]: Copied! <pre>output = parallelise(\n    square,\n    [(\"a\", 2), (\"b\", 3), (\"c\", 4)],\n    cache=Cache(),\n)\n</pre> output = parallelise(     square,     [(\"a\", 2), (\"b\", 3), (\"c\", 4)],     cache=Cache(), ) <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 21.61it/s]</pre> <pre>\n</pre> <p>To avoid overwriting cache results by different analyses we recommend saving each of them in a respective folder.</p> In\u00a0[17]: Copied! <pre>_ = Cache(tmp_dir=Path(\".cache\") / \"analysis-name\")\n</pre> _ = Cache(tmp_dir=Path(\".cache\") / \"analysis-name\") <p>By default the <code>key</code> of <code>parallelise</code> is used to create a pickle file called <code>{k}.p</code>. You can customise this behaviour by changing the <code>name_fn</code>, <code>load_fn</code> and <code>save_fn</code> arguments respectively.</p> In\u00a0[18]: Copied! <pre>def _pickle_name(k: Hashable) -&gt; str:\n    return f\"{k}.p\"\n\n\ndef _pickle_load(file: Path) -&gt; Any:\n    with file.open(\"rb\") as fp:\n        return pickle.load(fp)\n\n\ndef _pickle_save(file: Path, data: Any) -&gt; None:\n    with file.open(\"wb\") as fp:\n        pickle.dump(data, fp)\n\n\n_ = Cache(\n    name_fn=_pickle_name,\n    load_fn=_pickle_load,\n    save_fn=_pickle_save,\n)\n</pre> def _pickle_name(k: Hashable) -&gt; str:     return f\"{k}.p\"   def _pickle_load(file: Path) -&gt; Any:     with file.open(\"rb\") as fp:         return pickle.load(fp)   def _pickle_save(file: Path, data: Any) -&gt; None:     with file.open(\"wb\") as fp:         pickle.dump(data, fp)   _ = Cache(     name_fn=_pickle_name,     load_fn=_pickle_load,     save_fn=_pickle_save, ) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"scans.html#parameter-scans","title":"Parameter scans\u00b6","text":"<p>Parameter scans allow you to systematically assess the behaviour of your model dependent on the value of one or more parameters. mxlpy has routines to scan over, and easily visualise time courses, protocol time courses, and steady states for one or more parameters.</p> <p>For this, we import the <code>scan</code> and <code>plot</code> modules from which contain the respective routines.</p>"},{"location":"scans.html#steady-state","title":"Steady-state\u00b6","text":"<p>The steady-state scan takes a <code>pandas.DataFrame</code> of parameters to be scanned as an input and returns the steady-states at the respective parameter values.</p> <p>The DataFrame can take an arbitrary number of parameters and should be in the following format</p> n k1 0 1 1 1.2 2 1.4 <p>As an example we will use a linear chain of two reactions like this</p> <p>$$ \\varnothing \\xrightarrow{v_1} S \\xrightarrow{v_2} P \\xrightarrow{v_3} \\varnothing$$</p>"},{"location":"scans.html#combinations","title":"Combinations\u00b6","text":"<p>Often you want to scan over multiple parameters at the same time. The recommended way to do this is to use the <code>cartesian_product</code> function, which takes a <code>parameter_name: values</code> mapping and creates a <code>pandas.DataFrame</code> of their combinations from it (think nested for loop).</p> <p>In the case the parameters <code>DataFrame</code> contains more than one column, the returned <code>pandas.DataFrame</code> will contain a <code>pandas.MultiIndex</code>.</p>"},{"location":"scans.html#time-course","title":"Time course\u00b6","text":"<p>You can perform a time course for each of the parameter values, resulting in a distribution of time courses. The index now also contains the time, so even for one parameter a <code>pandas.MultiIndex</code> is used.</p>"},{"location":"scans.html#protocol","title":"Protocol\u00b6","text":"<p>The same can be done for protocols.</p>"},{"location":"scans.html#parallel-execution","title":"Parallel execution\u00b6","text":"<p>By default, all scans are executed in parallel. To do this, they internally use the <code>parallelise</code> function defined by <code>mxlpy</code>.</p> <p>Tip: You can also use this function for other analyses as it is not specific to any <code>mxlpy</code> constructs.</p> <p>The <code>parallelise</code> takes a function of type <code>T</code> and an iterable of a <code>key: T</code> pair. The key is used to construct a dictionary of results and for caching (see below).</p>"},{"location":"scans.html#caching","title":"Caching\u00b6","text":"<p>In case the simulations take a significant amount of time to run, it makes sense to cache the results on disk. You can do that by adding a <code>cache</code> to the <code>parallelise</code> function (and thus to all <code>scan</code> functions as well).</p> <pre>parallelise(...,  cache=Cache())\n</pre> <p>The first time the scan is run, the calculations are done, every subsequent time the results are loaded.</p>"},{"location":"stability.html","title":"Stability analysis","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom example_models import get_phase_plane\nfrom mxlpy import Simulator, plot, unwrap\n</pre> import numpy as np  from example_models import get_phase_plane from mxlpy import Simulator, plot, unwrap In\u00a0[2]: Copied! <pre>_ = plot.trajectories_2d(\n    get_phase_plane(),\n    x1=(\"s1\", np.linspace(0, 2, 20)),\n    x2=(\"s2\", np.linspace(0, 2, 20)),\n)\n</pre> _ = plot.trajectories_2d(     get_phase_plane(),     x1=(\"s1\", np.linspace(0, 2, 20)),     x2=(\"s2\", np.linspace(0, 2, 20)), ) <p>As always, <code>plot.trajectories_2d</code> returns matplotlib <code>Figure</code> and <code>Axes</code> objects, so you can further customise the plot. Below we visualise example trajectories for different initial conditions of the model.</p> In\u00a0[3]: Copied! <pre>fig, ax = plot.trajectories_2d(\n    get_phase_plane(),\n    x1=(\"s1\", np.linspace(0, 2, 20)),\n    x2=(\"s2\", np.linspace(0, 2, 20)),\n)\n\nfor s1 in np.linspace(0, 1, 4):\n    for s2 in np.linspace(0, 2, 4):\n        c = unwrap(\n            Simulator(get_phase_plane(), y0={\"s1\": s1, \"s2\": s2})\n            .simulate(1.5)\n            .get_result()\n        ).variables\n        ax.plot(c[\"s1\"], c[\"s2\"])\n</pre> fig, ax = plot.trajectories_2d(     get_phase_plane(),     x1=(\"s1\", np.linspace(0, 2, 20)),     x2=(\"s2\", np.linspace(0, 2, 20)), )  for s1 in np.linspace(0, 1, 4):     for s2 in np.linspace(0, 2, 4):         c = unwrap(             Simulator(get_phase_plane(), y0={\"s1\": s1, \"s2\": s2})             .simulate(1.5)             .get_result()         ).variables         ax.plot(c[\"s1\"], c[\"s2\"])"},{"location":"stability.html#stability-analysis","title":"Stability analysis\u00b6","text":"<p>mxlpy offers routines to easily visualise the stability of the model over a wide range of parameters.</p> <p><code>plot.trajectories2d</code>  shows the vector field depending on the values of two <code>variables</code> as a quiver plot.</p>"},{"location":"symbolic.html","title":"Symbolic","text":"In\u00a0[1]: Copied! <pre>import sympy\n\nfrom mxlpy import Model, fns, symbolic, to_symbolic_model\n\n\ndef sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\nsymbolic_model = to_symbolic_model(sir())\nsymbolic_model.jacobian()\n</pre> import sympy  from mxlpy import Model, fns, symbolic, to_symbolic_model   def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   symbolic_model = to_symbolic_model(sir()) symbolic_model.jacobian() Out[1]:  $\\displaystyle \\left[\\begin{matrix}- 1.0 \\beta i &amp; - 1.0 \\beta s &amp; 0\\\\1.0 \\beta i &amp; 1.0 \\beta s - 1.0 \\gamma &amp; 0\\\\0 &amp; 1.0 \\gamma &amp; 0\\end{matrix}\\right]$  In\u00a0[2]: Copied! <pre>res = symbolic.check_identifiability(\n    symbolic_model,\n    outputs=[sympy.Symbol(\"i\"), sympy.Symbol(\"r\")],\n)\nprint(res.summary())\n</pre> res = symbolic.check_identifiability(     symbolic_model,     outputs=[sympy.Symbol(\"i\"), sympy.Symbol(\"r\")], ) print(res.summary()) <pre>\rMain loop: 0it [00:00, ?it/s]</pre> <pre>\rMain loop: 2it [00:00, 25.79it/s]</pre> <pre>Summary\n=======\nThe model is not FISPO.\nIdentifiable parameters: [beta, gamma]\nUnidentifiable parameters: []\nIdentifiable variables: [s, i, r]\nUnidentifiable variables: []\nIdentifiable inputs: []\nUnidentifiable inputs: []\n\n</pre> <pre>\n</pre>"},{"location":"symbolic.html#identifiability","title":"Identifiability\u00b6","text":""},{"location":"tips.html","title":"Tips","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom cycler import cycler\n\nfrom mxlpy import plot\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd from cycler import cycler  from mxlpy import plot In\u00a0[2]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nfig, ax = plot.lines(\n    data.rename(\n        columns={\n            \"x1\": r\"$x_{1}$\",\n            \"x2\": r\"$x_{2}$\",\n            \"x3\": r\"$x_{3}$\",\n        }\n    )\n)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  fig, ax = plot.lines(     data.rename(         columns={             \"x1\": r\"$x_{1}$\",             \"x2\": r\"$x_{2}$\",             \"x3\": r\"$x_{3}$\",         }     ) ) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[3]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nwith plot.context(\n    colors=[\"r\", \"g\", \"b\"],\n    linewidth=2,\n):\n    fig, ax = plot.lines(data)\n    ax.set(xlabel=\"time\", ylabel=\"amplitude\")\n\nax.legend()\nplot.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  with plot.context(     colors=[\"r\", \"g\", \"b\"],     linewidth=2, ):     fig, ax = plot.lines(data)     ax.set(xlabel=\"time\", ylabel=\"amplitude\")  ax.legend() plot.show() In\u00a0[4]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nwith plot.context(\n    rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) + cycler(linestyle=[\"-\", \"--\"])},\n):\n    plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])\n    plot.show()\n\nwith plot.context(\n    rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) * cycler(linestyle=[\"-\", \"--\"])},\n):\n    plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])\n    plot.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  with plot.context(     rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) + cycler(linestyle=[\"-\", \"--\"])}, ):     plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])     plot.show()  with plot.context(     rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) * cycler(linestyle=[\"-\", \"--\"])}, ):     plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])     plot.show()"},{"location":"tips.html#tips-and-tricks","title":"Tips and tricks\u00b6","text":""},{"location":"tips.html#renaming-plots-arguments","title":"Renaming plots arguments\u00b6","text":"<p>The easiest way to rename plot arguments, e.g. for <code>LaTeX</code> display, is to work on the <code>pandas.DataFrame</code> directly. This conveniently offers a <code>rename</code> method, to which you can supply a dictionary of desired names.</p>"},{"location":"tips.html#custom-plot-styling","title":"Custom plot styling\u00b6","text":"<p>To change the style of plot elements, we recommend using <code>plot.context</code>, which is a convenience wrapper around <code>plt.rc_context</code>, see the matplotlib documentation.</p> <p>That way, our plotting routines can easily be re-used with completely different styling options.</p> <p>We opted for this way of styling plots so that you can use new features introduced by <code>matplotlib</code> immediately and don't have to wait for us to support every single update an every single plotting function.</p>"},{"location":"tips.html#advanced-plot-styling","title":"Advanced plot styling\u00b6","text":"<p>In case the our convenience arguments are not enough, you can use the entirety of the the matplotlib rc customizing arguments using the <code>rc</code> keyword argument of <code>plot.context</code>.</p> <p>Here, you have to spell out the exact name that <code>matplotlib</code> expects, e.g. <code>axes.prop_cycle</code> instead of just <code>colors</code> in case that was everything you wanted to change.</p> <p>Hint: watch out for the difference between <code>cycler + cycler</code> and <code>cycler * cycler</code>.</p>"}]}