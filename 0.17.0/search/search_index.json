{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About","text":""},{"location":"index.html#mxlpy","title":"mxlpy","text":"<p>mxlpy is a Python package designed to enable mechanistic learning, bridging the gap between mechanistic modeling and machine learning. The package enables you to integrate ordinary differential equation (ODE) models with data-driven techniques. This combination allows for more accurate and interpretable predictions in systems where both physical laws and data-driven insights are valuable. mxlpy thus facilitates the development of models that are not only data-efficient but also robust and capable of capturing complex system dynamics. Choose one of the notebooks below to start your journey!</p>"},{"location":"index.html#building-and-simulating-models","title":"Building and simulating models","text":"<p>In this first notebook you will learn how to build ODE models and do basic simulations with them. This will allow you to create time courses and do steady-state analysis as shown below.</p> <p>Start learning</p>"},{"location":"index.html#parameter-scans","title":"Parameter scans","text":"<p>Parameter scans allow you to systematically assess the behaviour of your model dependent on the value of one or more parameters. mxlpy has rountines to scan over, and easily visualise time courses, protocol time courses, and steady states for one or more parameters.</p> <p>Start learning</p>"},{"location":"index.html#metabolic-control-analysis","title":"Metabolic control analysis","text":"<p>Metabolic control analysis answers the question: what happens to the concentrations and fluxes if I slightly perturb the system? It is thus a local measurement about which reactions hold the most control. If you ever read about rate-limiting steps, then this is for you!</p> <p>Start learning</p>"},{"location":"index.html#fitting","title":"Fitting","text":"<p>Almost every model at some point needs to be fitted to experimental data to be validated. mxlpy offers highly customisable routines for fitting either time series or steady-states.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#monte-carlo-methods","title":"Monte Carlo methods","text":"<p>Almost every parameter in biology is better described with a distribution than a single value. Monte-carlo methods allow you to capture the range of possible behaviour your model can exhibit. This is especially useful when you want to understand the uncertainty in your model's predictions. mxlpy offers these Monte Carlo methods for all scans  ...</p> + = <p>and even for metabolic control analysis</p> + = <p>Start learning</p>"},{"location":"index.html#label-models","title":"Label models","text":"<p>Labelled models allow explicitly mapping the transitions between isotopomers variables.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#mechanistic-learning","title":"Mechanistic Learning","text":"<p>Mechanistic learning is the intersection of mechanistic modelling and machine learning. mxlpy currently supports two such approaches: surrogates and neural posterior estimation. Surrogate models replace whole parts of a mechanistic model (or even the entire model) with machine learning models.</p> <p></p> <p>This allows combining together multiple models of arbitrary size, without having to worry about the internal state of each model. They are especially useful for improving the description of boundary effects, e.g. a dynamic description of downstream consumption. Neural posterior estimation answers the question: what parameters could have generated the data I measured? Here you use an ODE model and prior knowledge about the parameters of interest to create synthetic data. You then use the generated synthetic data as the features and the input parameters as the targets to train an inverse problem. Once that training is successful, the neural network can now predict the input parameters for real world data.</p> <p></p> <p>Start learning</p>"},{"location":"index.html#parameterisation","title":"Parameterisation","text":"<p>Obtaining experimentally measured parameters can be challenging. Using the Brenda enzymes database we can obtain  distributions of enzymatic parameters for a wide range of organisms. These distributions can in turn be used with our Monte-Carlo methods to capture the range of possible behaviour your model can exhibit.</p> + = <p>Start learning</p>"},{"location":"index.html#experimental-features","title":"Experimental features","text":"<p>A collection of experimental features for you to explore. Warning: all APIs shown should be considered unstable and may change without notice.</p> <p>Start learning</p>"},{"location":"index.html#how-to-cite","title":"How to cite","text":"<p>If you use this software in your scientific work, please cite this article:</p> <ul> <li>doi</li> <li>bibtex file</li> </ul>"},{"location":"basics.html","title":"Basics","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Any\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy.types import unwrap\n\n\ndef print_annotated(description: str, value: Any) -&gt; None:\n    print(\n        description,\n        value,\n        sep=\"\\n\",\n        end=\"\\n\\n\",\n    )\n</pre> from __future__ import annotations  from pathlib import Path from typing import Any  import matplotlib.pyplot as plt  from example_models import get_linear_chain_2v from mxlpy.types import unwrap   def print_annotated(description: str, value: Any) -&gt; None:     print(         description,         value,         sep=\"\\n\",         end=\"\\n\\n\",     ) In\u00a0[2]: Copied! <pre>def constant(k: float) -&gt; float:\n    return k\n\n\ndef proportional(k: float, s: float) -&gt; float:\n    return k * s\n</pre> def constant(k: float) -&gt; float:     return k   def proportional(k: float, s: float) -&gt; float:     return k * s <p>Next, we create our model.</p> <p>For this, we first import the <code>Model</code> class from the <code>mxlpy</code> package.</p> In\u00a0[3]: Copied! <pre>from mxlpy import Model\n\nmodel = Model()\n</pre> from mxlpy import Model  model = Model() <p>We first add parameters to the model using <code>.add_parameters({name: value})</code>.</p> <p>Note that the function returns our <code>Model</code> object again. This will be useful later, as we can chain multiple calls together.</p> In\u00a0[4]: Copied! <pre>model = model.add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})\n</pre> model = model.add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1}) <p>Next we add the dynamic variables <code>S</code> and <code>P</code> with their respective initial condition.</p> In\u00a0[5]: Copied! <pre>model = model.add_variables({\"S\": 0, \"P\": 0})\n</pre> model = model.add_variables({\"S\": 0, \"P\": 0}) <p>Finally, we add the three reactions by using</p> <pre>.add_reaction(\n    name,              # the internal name for the reaction\n    fn=...,            # a python function to be evaluated\n    args=[name, ...]   # the arguments passed to the python function\n    stoichiometry={    # a mapping encoding how much the variable `name`\n        name: value    # is changed by the reaction\n    },\n)\n</pre> <p>Attention There are a couple of points to note here. First, the function passed to <code>fn</code> here (and elsewhere) needs to be pickle-able Thus, lambda functions are not supported!</p> <p>Second, the arguments defined with <code>args</code> are passed to <code>fn</code> by position, not by name. Thus, the order of arguments in <code>args</code> needs to match the order of arguments in <code>fn</code></p> In\u00a0[6]: Copied! <pre>model.add_reaction(\n    \"v0\",\n    fn=constant,\n    args=[\"k_in\"],\n    stoichiometry={\"S\": 1},  # produces one S\n)\nmodel.add_reaction(\n    \"v1\",\n    fn=proportional,\n    args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`\n    stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P\n)\nmodel.add_reaction(\n    \"v2\",\n    fn=proportional,\n    args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`\n    stoichiometry={\"P\": -1},  # exports one P\n)\n\nprint(model.get_reaction_names())\n</pre> model.add_reaction(     \"v0\",     fn=constant,     args=[\"k_in\"],     stoichiometry={\"S\": 1},  # produces one S ) model.add_reaction(     \"v1\",     fn=proportional,     args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`     stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P ) model.add_reaction(     \"v2\",     fn=proportional,     args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`     stoichiometry={\"P\": -1},  # exports one P )  print(model.get_reaction_names()) <pre>['v0', 'v1', 'v2']\n</pre> <p>Note, that we in general recommend to use a single function that returns the model instead of defining it globally. This allows us to quickly re-create the model whenever we need a fresh version of it. Below, we define the same model again, but inside a single function.</p> <p>Note that we made use of operator chaining to avoid having to write <code>model</code> for every call.</p> <p>So we can write <code>Model.method1().method2()...</code>  instead of having to write</p> <pre>model.method1()\nmodel.method2()\n</pre> <p>etc</p> In\u00a0[7]: Copied! <pre>def create_linear_chain_model() -&gt; Model:\n    return (\n        Model()\n        .add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})\n        .add_variables({\"S\": 0, \"P\": 0})\n        .add_reaction(\n            \"v0\",\n            fn=constant,\n            args=[\"k_in\"],\n            stoichiometry={\"S\": 1},  # produces one S\n        )\n        .add_reaction(\n            \"v1\",\n            fn=proportional,\n            args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`\n            stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P\n        )\n        .add_reaction(\n            \"v2\",\n            fn=proportional,\n            args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`\n            stoichiometry={\"P\": -1},  # exports one P\n        )\n    )\n</pre> def create_linear_chain_model() -&gt; Model:     return (         Model()         .add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})         .add_variables({\"S\": 0, \"P\": 0})         .add_reaction(             \"v0\",             fn=constant,             args=[\"k_in\"],             stoichiometry={\"S\": 1},  # produces one S         )         .add_reaction(             \"v1\",             fn=proportional,             args=[\"k_1\", \"S\"],  # note that the order needs to match `proportional`             stoichiometry={\"S\": -1, \"P\": 1},  # consumes one S and produces one P         )         .add_reaction(             \"v2\",             fn=proportional,             args=[\"k_out\", \"P\"],  # note that the order needs to match `proportional`             stoichiometry={\"P\": -1},  # exports one P         )     ) <p>We can then simulate the model by passing it to a <code>Simulator</code> and simulate a time series using <code>.simulate(t_end)</code>. Finally, we can obtain the concentrations and fluxes using <code>get_result</code>.</p> <p>While you can directly plot the <code>pd.DataFrame</code>s, mxlpy supplies a variety of plots in the <code>plot</code> namespace that are worth checking out.</p> In\u00a0[8]: Copied! <pre>from mxlpy import Simulator, plot\n\nres = (\n    Simulator(create_linear_chain_model())  # initialise the simulator\n    .simulate(5)  # simulate until t_end = 5 a.u.\n    .get_result()  # return pd.DataFrames for concentrations and fluxes\n)\n\nif res is not None:\n    variables, fluxes = res\n\n    fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5))\n    _ = plot.lines(variables, ax=ax1)\n    _ = plot.lines(fluxes, ax=ax2)\n\n    # Never forget to labelr you axes :)\n    ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\n    ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\n    plt.show()\n</pre> from mxlpy import Simulator, plot  res = (     Simulator(create_linear_chain_model())  # initialise the simulator     .simulate(5)  # simulate until t_end = 5 a.u.     .get_result()  # return pd.DataFrames for concentrations and fluxes )  if res is not None:     variables, fluxes = res      fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5))     _ = plot.lines(variables, ax=ax1)     _ = plot.lines(fluxes, ax=ax2)      # Never forget to labelr you axes :)     ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")     ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")     plt.show() <p>Note, that we checked whether the results were <code>None</code> in case the simulation failed. Explicitly checking using an <code>if</code> clause is the prefered error handling mechanism.</p> <p>If you are sure the simulation won't fail, and still want your code to be type-safe, you can use <code>unwrap</code>.</p> <pre>variables, fluxes = unwrap(Simulator(model).simulate(10).get_result())\n</pre> <p>Note that these functions will throw an error if the values are <code>None</code>, which potentially might crash your programs.</p> In\u00a0[9]: Copied! <pre>def moiety_1(x1: float, total: float) -&gt; float:\n    return total - x1\n\n\ndef model_derived() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"ATP\": 1.0})\n        .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})\n        .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])\n        .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])\n        .add_reaction(\n            \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}\n        )\n    )\n\n\nvariables, fluxes = unwrap(Simulator(model_derived()).simulate(10).get_result())\nfig, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> def moiety_1(x1: float, total: float) -&gt; float:     return total - x1   def model_derived() -&gt; Model:     return (         Model()         .add_variables({\"ATP\": 1.0})         .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})         .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])         .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])         .add_reaction(             \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}         )     )   variables, fluxes = unwrap(Simulator(model_derived()).simulate(10).get_result()) fig, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[10]: Copied! <pre>m = create_linear_chain_model()\n\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_args(),\n)\n\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_args({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  print_annotated(     \"Using initial conditions as default:\",     m.get_args(), )  print_annotated(     \"Using custom concentrations:\",     m.get_args({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nS    0.0\nP    0.0\ndtype: float64\n\nUsing custom concentrations:\nS    1.0\nP    0.5\ndtype: float64\n\n</pre> <p>If the <code>args</code> look fine, the next step is usually to check whether the rate equations are looking as expected</p> In\u00a0[11]: Copied! <pre>m = create_linear_chain_model()\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_fluxes(),\n)\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model() print_annotated(     \"Using initial conditions as default:\",     m.get_fluxes(), ) print_annotated(     \"Using custom concentrations:\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nv0    1.0\nv1    0.0\nv2    0.0\ndtype: float64\n\nUsing custom concentrations:\nv0    1.0\nv1    1.0\nv2    0.5\ndtype: float64\n\n</pre> <p>and whether the stoichiometries are assigned correctly</p> In\u00a0[12]: Copied! <pre>m = create_linear_chain_model()\nm.get_stoichiometries()\n</pre> m = create_linear_chain_model() m.get_stoichiometries() Out[12]: v0 v1 v2 S 1.0 -1.0 0.0 P 0.0 1.0 -1.0 <p>Lastly, you can check the generated right hand side</p> In\u00a0[13]: Copied! <pre>m = create_linear_chain_model()\n\nprint_annotated(\n    \"Using initial conditions as default:\",\n    m.get_right_hand_side(),\n)\n\nprint_annotated(\n    \"Using custom concentrations:\",\n    m.get_right_hand_side({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  print_annotated(     \"Using initial conditions as default:\",     m.get_right_hand_side(), )  print_annotated(     \"Using custom concentrations:\",     m.get_right_hand_side({\"S\": 1.0, \"P\": 0.5}), ) <pre>Using initial conditions as default:\nS    1.0\nP    0.0\ndtype: float64\n\nUsing custom concentrations:\nS    0.0\nP    0.5\ndtype: float64\n\n</pre> <p>If any of the quantities above were unexpected, you can check the model interactively by accessing the various collections.</p> <p>Note: the returned quantities are copies of the internal data, modifying these won't have any effect on the model</p> In\u00a0[14]: Copied! <pre>print_annotated(\"Parameters\", m.parameters)\nprint_annotated(\"Variables\", m.variables)\nprint_annotated(\"Reactions\", m.reactions)\n</pre> print_annotated(\"Parameters\", m.parameters) print_annotated(\"Variables\", m.variables) print_annotated(\"Reactions\", m.reactions) <pre>Parameters\n{'k_in': 1, 'k_1': 1, 'k_out': 1}\n\nVariables\n{'S': 0, 'P': 0}\n\nReactions\n{'v0': Reaction(fn=&lt;function constant at 0x7ff664063f60&gt;, stoichiometry={'S': 1}, args=['k_in']), 'v1': Reaction(fn=&lt;function proportional at 0x7ff664068040&gt;, stoichiometry={'S': -1, 'P': 1}, args=['k_1', 'S']), 'v2': Reaction(fn=&lt;function proportional at 0x7ff664068040&gt;, stoichiometry={'P': -1}, args=['k_out', 'P'])}\n\n</pre> <p>In case you model contains derived quantitites you can access the derived quantities using <code>.derived</code>. Note that this returns a copy of the derived quantities, so editing it won't have any effect on the model.</p> In\u00a0[15]: Copied! <pre>model_derived().derived\n</pre> model_derived().derived Out[15]: <pre>{'k_atp': Derived(fn=&lt;function proportional at 0x7ff664068040&gt;, args=['k_base', 'e0_atpase']),\n 'ADP': Derived(fn=&lt;function moiety_1 at 0x7ff66422aca0&gt;, args=['ATP', 'ATP_total'])}</pre> In\u00a0[16]: Copied! <pre>m = create_linear_chain_model()\n\n# Calculate fluxes\nprint_annotated(\n    \"Before update\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n\n# Update parameters\nm.update_parameters({\"k_in\": 2.0})\n\n# Calculate fluxes again\nprint_annotated(\n    \"After update\",\n    m.get_fluxes({\"S\": 1.0, \"P\": 0.5}),\n)\n</pre> m = create_linear_chain_model()  # Calculate fluxes print_annotated(     \"Before update\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), )  # Update parameters m.update_parameters({\"k_in\": 2.0})  # Calculate fluxes again print_annotated(     \"After update\",     m.get_fluxes({\"S\": 1.0, \"P\": 0.5}), ) <pre>Before update\nv0    1.0\nv1    1.0\nv2    0.5\ndtype: float64\n\nAfter update\nv0    2.0\nv1    1.0\nv2    0.5\ndtype: float64\n\n</pre> In\u00a0[17]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(\n        Model()\n        .add_parameters({\"stoich\": -1.0, \"k\": 1.0})\n        .add_variables({\"x\": 1.0})\n        .add_reaction(\n            \"name\",\n            proportional,\n            args=[\"x\", \"k\"],\n            # Define derived stoichiometry here\n            stoichiometry={\"x\": \"stoich\"},\n        )\n    )\n    .simulate(1)\n    # Update parameter the derived stoichiometry depends on\n    .update_parameter(\"stoich\", -4.0)\n    # Continue simulation\n    .simulate(5)\n    .get_result()\n)\n\n_, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(         Model()         .add_parameters({\"stoich\": -1.0, \"k\": 1.0})         .add_variables({\"x\": 1.0})         .add_reaction(             \"name\",             proportional,             args=[\"x\", \"k\"],             # Define derived stoichiometry here             stoichiometry={\"x\": \"stoich\"},         )     )     .simulate(1)     # Update parameter the derived stoichiometry depends on     .update_parameter(\"stoich\", -4.0)     # Continue simulation     .simulate(5)     .get_result() )  _, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[18]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v())\n    .simulate(t_end=10)  # simulate until t_end = 10 a.u.\n    .get_result()\n)\n\nfig, ax = plot.lines(variables)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v())     .simulate(t_end=10)  # simulate until t_end = 10 a.u.     .get_result() )  fig, ax = plot.lines(variables) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() <p>By default, the <code>Simulator</code> is initialised with the initial concentrations set in the <code>Model</code>. Optionally, you can overwrite the initial conditions using the <code>y0</code> argument.</p> <pre>Simulator(model, y0={name: value, ...})\n</pre> In\u00a0[19]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(create_linear_chain_model(), y0={\"S\": 2.0, \"P\": 0.0})\n    .simulate(10)\n    .get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3))\n_ = plot.lines(variables, ax=ax1)\n_ = plot.lines(fluxes, ax=ax2)\n\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(create_linear_chain_model(), y0={\"S\": 2.0, \"P\": 0.0})     .simulate(10)     .get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3)) _ = plot.lines(variables, ax=ax1) _ = plot.lines(fluxes, ax=ax2)  ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() In\u00a0[20]: Copied! <pre>from mxlpy import make_protocol\n\nprotocol = make_protocol(\n    [\n        (1, {\"k1\": 1}),  # for one second value of 1\n        (2, {\"k1\": 2}),  # for two seconds value of 2\n        (3, {\"k1\": 1}),  # for three seconds value of 1\n    ]\n)\nprotocol\n</pre> from mxlpy import make_protocol  protocol = make_protocol(     [         (1, {\"k1\": 1}),  # for one second value of 1         (2, {\"k1\": 2}),  # for two seconds value of 2         (3, {\"k1\": 1}),  # for three seconds value of 1     ] ) protocol Out[20]: k1 Timedelta 0 days 00:00:01 1 0 days 00:00:03 2 0 days 00:00:06 1 <p>Now instead of running <code>simulate</code> or <code>simulate_time_course</code> we use <code>simulate_over_protocol</code></p> In\u00a0[21]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v()).simulate_over_protocol(protocol).get_result()\n)\n\nfig, ax = plt.subplots()\nplot.lines(variables, ax=ax)\nplot.shade_protocol(protocol[\"k1\"], ax=ax, alpha=0.1)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v()).simulate_over_protocol(protocol).get_result() )  fig, ax = plt.subplots() plot.lines(variables, ax=ax) plot.shade_protocol(protocol[\"k1\"], ax=ax, alpha=0.1) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[22]: Copied! <pre>variables, fluxes = unwrap(\n    Simulator(get_linear_chain_2v())  # optionally supply initial conditions\n    .simulate_to_steady_state()\n    .get_result()\n)\n\nfig, ax = plot.bars(variables)\nax.set(xlabel=\"Variable / a.u.\", ylabel=\"Concentration / a.u.\")\nplt.show()\n</pre> variables, fluxes = unwrap(     Simulator(get_linear_chain_2v())  # optionally supply initial conditions     .simulate_to_steady_state()     .get_result() )  fig, ax = plot.bars(variables) ax.set(xlabel=\"Variable / a.u.\", ylabel=\"Concentration / a.u.\") plt.show() In\u00a0[23]: Copied! <pre>from mxlpy import sbml\n\nmodel = sbml.read(Path(\"assets\") / \"00001-sbml-l3v2.xml\")\nvariables, fluxes = unwrap(Simulator(model).simulate(10).get_result())\n_ = plot.lines(variables)\n</pre> from mxlpy import sbml  model = sbml.read(Path(\"assets\") / \"00001-sbml-l3v2.xml\") variables, fluxes = unwrap(Simulator(model).simulate(10).get_result()) _ = plot.lines(variables) <p>When exporting a model, you can supply additional meta-information like units and compartmentalisation. See the official sbml documentation for more information of legal values.</p> In\u00a0[24]: Copied! <pre>sbml.write(\n    model,\n    file=Path(\".cache\") / \"model.xml\",\n    extent_units=\"mole\",\n    substance_units=\"mole\",\n    time_units=\"second\",\n)\n</pre> sbml.write(     model,     file=Path(\".cache\") / \"model.xml\",     extent_units=\"mole\",     substance_units=\"mole\",     time_units=\"second\", ) Out[24]: <pre>PosixPath('.cache/model.xml')</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about model building and simulation in mxlpy.           Congratulations!  In\u00a0[25]: Copied! <pre>def time_dependency() -&gt; Model:\n    return (\n        Model()\n        .add_variable(\"x\", 1.0)\n        .add_reaction(\n            \"v1\",\n            proportional,\n            args=[\"time\", \"x\"],\n            stoichiometry={\"x\": -1},\n        )\n    )\n\n\nmodel = time_dependency()\n\n# Watch our for explicit time dependency here!\nprint_annotated(\n    \"Fluxes at time = 1.0\",\n    model.get_fluxes(time=1.0),\n)\nprint_annotated(\n    \"Fluxes at time = 2.0\",\n    model.get_fluxes(time=2.0),\n)\n\n# During simulations the time is automatically taken care of\n_ = unwrap(Simulator(model).simulate(t_end=10).get_result()).variables.plot(\n    xlabel=\"time / a.u.\",\n    ylabel=\"amount / a.u.\",\n    title=\"Time-dependent reaction\",\n)\n</pre> def time_dependency() -&gt; Model:     return (         Model()         .add_variable(\"x\", 1.0)         .add_reaction(             \"v1\",             proportional,             args=[\"time\", \"x\"],             stoichiometry={\"x\": -1},         )     )   model = time_dependency()  # Watch our for explicit time dependency here! print_annotated(     \"Fluxes at time = 1.0\",     model.get_fluxes(time=1.0), ) print_annotated(     \"Fluxes at time = 2.0\",     model.get_fluxes(time=2.0), )  # During simulations the time is automatically taken care of _ = unwrap(Simulator(model).simulate(t_end=10).get_result()).variables.plot(     xlabel=\"time / a.u.\",     ylabel=\"amount / a.u.\",     title=\"Time-dependent reaction\", ) <pre>Fluxes at time = 1.0\nv1    1.0\ndtype: float64\n\nFluxes at time = 2.0\nv1    2.0\ndtype: float64\n\n</pre> In\u00a0[26]: Copied! <pre>def model_derived() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"ATP\": 1.0})\n        .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})\n        .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])\n        .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])\n        .add_reaction(\n            \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}\n        )\n    )\n\n\nm = Model().add_parameters({\"x1\": 1.0}).add_derived(\"x1d\", constant, args=[\"x1\"])\nprint(\"Derived Parameters:\", m.derived_parameters)\nprint(\"Derived Variables:\", m.derived_variables)\n\nprint(\"\\nMaking x1 dynamic\")\nm.make_parameter_dynamic(\"x1\")\nprint(\"Derived Parameters:\", m.derived_parameters)\nprint(\"Derived Variables:\", m.derived_variables)\n</pre> def model_derived() -&gt; Model:     return (         Model()         .add_variables({\"ATP\": 1.0})         .add_parameters({\"ATP_total\": 1.0, \"k_base\": 1.0, \"e0_atpase\": 1.0})         .add_derived(\"k_atp\", proportional, args=[\"k_base\", \"e0_atpase\"])         .add_derived(\"ADP\", moiety_1, args=[\"ATP\", \"ATP_total\"])         .add_reaction(             \"ATPase\", proportional, args=[\"k_atp\", \"ATP\"], stoichiometry={\"ATP\": -1}         )     )   m = Model().add_parameters({\"x1\": 1.0}).add_derived(\"x1d\", constant, args=[\"x1\"]) print(\"Derived Parameters:\", m.derived_parameters) print(\"Derived Variables:\", m.derived_variables)  print(\"\\nMaking x1 dynamic\") m.make_parameter_dynamic(\"x1\") print(\"Derived Parameters:\", m.derived_parameters) print(\"Derived Variables:\", m.derived_variables) <pre>Derived Parameters: {'x1d': Derived(fn=&lt;function constant at 0x7ff664063f60&gt;, args=['x1'])}\nDerived Variables: {}\n\nMaking x1 dynamic\nDerived Parameters: {}\nDerived Variables: {'x1d': Derived(fn=&lt;function constant at 0x7ff664063f60&gt;, args=['x1'])}\n</pre>"},{"location":"basics.html#model-building-basics","title":"Model building basics\u00b6","text":"<p>In the following you will learn how to build and simulate your first model using <code>mxlpy</code>.</p> <p>This will allow you to create time courses and do steady-state analysis as shown below.</p>"},{"location":"basics.html#defining-your-first-model","title":"Defining your first model\u00b6","text":"<p>Let's say you want to model the following chemical network of a linear chain of reactions</p> <p>$$ \\Large \\varnothing \\xrightarrow{v_0} S \\xrightarrow{v_1} P \\xrightarrow{v_2} \\varnothing $$</p> <p>We can translate this into a system of ordinary differential equations (ODEs)</p> <p>$$\\begin{align*} \\frac{dS}{dt} &amp;= v_0 - v_1     \\\\ \\frac{dP}{dt} &amp;= v_1 - v_2 \\\\ \\end{align*} $$</p> <p>Note that the rates $v$ effect the variables by certain factors, known as stoichiometries. We can explicity write out these factors like this:</p> <p>$$\\begin{align*} \\frac{dS}{dt} &amp;= 1 \\cdot v_0 -1 \\cdot v_1     \\\\ \\frac{dP}{dt} &amp;= 1\\cdot v_1 -1 \\cdot v_2 \\\\ \\end{align*} $$</p> <p>In the example the stoichiometries are all $1$ or $-1$, however, they can have any real value. We can write out the stoichiometries using a stoichiometric matrix:</p> Variable $v_0$ $v_1$ $v_2$ S 1 -1 0 P 0 1 -1 <p>Which we can read as (ignoring the 0 entries):</p> <ul> <li><code>S</code> is produced by $v_0$ and consumed by $v_1$</li> <li><code>P</code> is produced by $v_1$ and consumed by $v_2$</li> </ul> <p>Lastly we choose rate equations for each rate to get the flux vector $v$</p> <p>$$\\begin{align*}     v_0 &amp;= k_{in} \\\\     v_1 &amp;= k_1 * S \\\\     v_2 &amp;= k_{out} * P \\\\ \\end{align*}$$</p>"},{"location":"basics.html#implementing-your-first-model","title":"Implementing your first model\u00b6","text":"<p>Now let's implement this first model in mxlpy. We start by creating the rate functions $\\textbf{v}$. Note that these should be general and re-usable whenever possible, to make your model clear to people reading it. Try to give these functions names that are meaningful to your audience, e.g. a rate function <code>k * s</code> could be named proportional or mass-action.</p>"},{"location":"basics.html#derived-quantities","title":"Derived quantities\u00b6","text":"<p>Frequently it makes sense to derive one quantity in a model from other quantities. This can be done for</p> <ul> <li>parameters derived from other parameters</li> <li>variables derived from parameters or other variables</li> <li>stoichiometries derived from parameters or variables (more on this later)</li> </ul> <p>mxlpy offers a unified interface for derived parameters and variables usign <code>Model.add_derived()</code>.</p>"},{"location":"basics.html#introspection","title":"Introspection\u00b6","text":"<p>If the simulation didn't show the expected results, it is usually a good idea to try to pinpoint the error. <code>mxlpy</code> offers a variety of methods to access intermediate results.</p> <p>The first is to check whether all derived quantities were calculate correctly. For this, you can use the <code>get_args</code> method, which is named consistently with the <code>args</code> argument in all methods like <code>add_reaction</code>.</p>"},{"location":"basics.html#crud","title":"CRUD\u00b6","text":"<p>The model has a complete create, read, update, delete API for all it's elements. The methods and attributes are named consistenly, with <code>add</code> instead of <code>create</code> and <code>get</code> instead of <code>read</code>. Note that the elements itself are accessible as <code>properties</code>, e.g. <code>.parameters</code> which will return copies of the data. Only use the supplied methods to change the internal state of the model.</p> <p>Here are some example methods and attributes for parameters</p> Functionality Parameters Create <code>.add_parameter()</code>, <code>.add_parameters()</code> Read <code>.parameters</code>, <code>.get_parameter_names()</code> Update <code>.update_parameter()</code>, <code>.update_parameters()</code>, <code>.scale_parameter()</code>, <code>scale.parameters()</code> Delete <code>.remove_parameter()</code>, <code>.remove_parameters()</code> <p>and variables</p> Functionality Variables Create <code>.add_variable()</code>, <code>.add_variables()</code> Read <code>.variables</code>, <code>.get_variable_names()</code>, <code>get_initial_conditions()</code> Update <code>.update_variable()</code>, <code>.update_variables()</code> Delete <code>.remove_parameter()</code>, <code>.remove_parameters()</code>"},{"location":"basics.html#derived-stoichiometries","title":"Derived stoichiometries\u00b6","text":"<p>To define derived stoichiometries can make them dependent on parameters in the model or use the <code>Derived</code> class as a value in the stoichiometries.</p> <p>So instead of defining them like this</p> <p><code>stoichiometry={\"x\": 1.0}</code></p> <p>you can use</p> <p><code>stoichiometry={\"x\": \"stoich\"}</code></p> <p>or for more advanced uses you use the <code>Derived</code> class as the value</p> <p><code>stoichiometry={\"x\": Derived(fn=constant, args=[\"stoich\"])}</code></p>"},{"location":"basics.html#simulations-time-courses","title":"Simulations: time courses\u00b6","text":"<p>Time courses are simulations over time</p> <p></p> <p>You can obtain the time course of integration using the <code>simulate</code> method. There are two ways how you can define the time points this function returns.</p> <ol> <li>supply the end time <code>t_end</code></li> <li>supply both end time and number of steps with <code>t_end</code> and <code>steps</code></li> </ol> <p>If you want to set the exact time points to be returned use <code>simulate_time_course</code></p> <pre>simulate(t_end=10)\nsimulate(t_end=10, steps=10)\nsimulate_time_course(np.linspace(0, 10, 11))\n</pre>"},{"location":"basics.html#simulations-protocol-time-course","title":"Simulations: protocol time course\u00b6","text":"<p>Protocols are used to make parameter changes discrete in time, such as turning a light on and off. This is useful reproducing experimental time courses where a parameter was changed at fixed time points.</p> <p></p> <p>The protocol is defined as a <code>pandas.DataFrame</code> using <code>pd.Timedelta</code> values as in index, and the parameter values at the respective time interval as values.</p> pd.Timedelta p1 p2 0 days 00:00:01 1 0 0 days 00:00:03 2 1 0 days 00:00:06 1 2 <p>You can use as many parameters as you want.</p> <p>Note mxlpy assigns one second of the <code>Timedelta</code> to one time unit of the integration. mxlpy does not take into account whether your integration might use a different time unit.</p> <p>For convenience, we supply the <code>make_protocol</code> function, which takes in a pair of the duration of the time-step on the respective parameter values.</p>"},{"location":"basics.html#simulations-steady-state","title":"Simulations: steady-state\u00b6","text":"<p>A steady-state describes a state at which the concentrations of the system don't change anymore (also called fixed points).</p> <p></p> <p>You can simulate until the model reaches a steady-state using the <code>simulate_to_steady_state</code> method.</p>"},{"location":"basics.html#sbml","title":"SBML\u00b6","text":"<p>The systems biology markup language (SBML) is a widely used file format for sharing models between different software packages and programming languages.</p> <p><code>mxlpy</code> supports reading and writing sbml models using the <code>sbml.read</code> and <code>sbml.write</code> functions.</p>"},{"location":"basics.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"basics.html#time-dependent-reactions","title":"Time-dependent reactions\u00b6","text":"<p>You can use the special name <code>time</code> to refer to the actual integration time in the rare case a reaction or module depends on it explicitly. This is why the methods <code>get_args</code>, <code>get_fluxes</code> etc. also take an additional <code>time</code> argument.</p>"},{"location":"basics.html#derived-parameters-and-variables","title":"Derived parameters and variables\u00b6","text":"<p>Internally mxlpy differentiates between derived parameters and derived variables. This differentiation is just-in-time before any calculation and thus might change if you change the nature of a parameter / variable.</p> <p>If you are interested in which category mxlpy has placed the derived quantities, you can access <code>.derived_parameters</code> and <code>.derived_variables</code> as well.</p>"},{"location":"citing.html","title":"Citing","text":"<p>If you use this software in your scientific work, please cite this article:</p> <ul> <li>doi</li> <li>bibtex file</li> </ul>"},{"location":"examples.html","title":"Examples","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\nfrom mxlpy import Model, Simulator, fns, plot\nfrom mxlpy.types import unwrap\n</pre> import matplotlib.pyplot as plt  from mxlpy import Model, Simulator, fns, plot from mxlpy.types import unwrap In\u00a0[2]: Copied! <pre>def sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\nres = unwrap(Simulator(sir()).simulate(100).get_result())\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5))\n_ = plot.lines(res.variables, ax=ax1)\n_ = plot.lines(res.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\nax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\")\nplt.show()\n</pre> def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   res = unwrap(Simulator(sir()).simulate(100).get_result())  fig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5)) _ = plot.lines(res.variables, ax=ax1) _ = plot.lines(res.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\") ax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\") plt.show() <p>We can now easily extend the original model by adding an additional compartment and transition.</p> <p>The SIRD model for example differentiates between recovered and deceased individuals.</p> <p>So there exists an additional compartment for deceased individuals and a transition for infected to deceased individuals, proportional to the amount of infected individuals and the mortality $\\mu$ of the infection: $\\mu I$</p> In\u00a0[3]: Copied! <pre>def sird() -&gt; Model:\n    return (\n        sir()\n        .add_variable(\"d\", 0.0)\n        .add_parameter(\"mu\", 0.01)\n        .add_reaction(\n            \"death\",\n            fns.mass_action_1s,\n            args=[\"i\", \"mu\"],\n            stoichiometry={\"i\": -1, \"d\": 1},\n        )\n    )\n\n\nres = unwrap(Simulator(sird()).simulate(100).get_result())\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5))\n_ = plot.lines(res.variables, ax=ax1)\n_ = plot.lines(res.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\nax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\")\nplt.show()\n</pre> def sird() -&gt; Model:     return (         sir()         .add_variable(\"d\", 0.0)         .add_parameter(\"mu\", 0.01)         .add_reaction(             \"death\",             fns.mass_action_1s,             args=[\"i\", \"mu\"],             stoichiometry={\"i\": -1, \"d\": 1},         )     )   res = unwrap(Simulator(sird()).simulate(100).get_result())  fig, (ax1, ax2) = plot.two_axes(figsize=(7.5, 3.5)) _ = plot.lines(res.variables, ax=ax1) _ = plot.lines(res.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\") ax2.set(xlabel=\"Time / a.u.\", ylabel=\"Rate of change\") plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples.html#sir-and-sird-models","title":"SIR and SIRD models\u00b6","text":"<p>In epidemiology, compartmental models are often applied to model infectious diseases.</p> <p>Common compartments include ones for Susceptible, Infectious and Recovered individuals, which are included in the SIR model.</p> <p>In this model there are two transitions (<code>reactions</code> in mxlpy) between those compartments.</p> <ul> <li>susceptible individuals can become infected by contact with an infected person: $\\beta S  I$</li> <li>infected people can recover with a rate proportional: $\\gamma I$</li> </ul> <p>These transitions are scaled by the average number of contacts per person per time ($\\beta$) and the inverse of the average infection time $\\gamma$.</p>"},{"location":"fitting.html","title":"Fitting","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import minimize\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy import Simulator, fit, plot\nfrom mxlpy.types import unwrap\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize  from example_models import get_linear_chain_2v from mxlpy import Simulator, fit, plot from mxlpy.types import unwrap In\u00a0[2]: Copied! <pre># As a small trick, let's define a variable for the model function\n# That way, we can re-use it all over the file and easily replace\n# it with another model\nmodel_fn = get_linear_chain_2v\n\nres = unwrap(\n    Simulator(model_fn())\n    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n    .simulate_time_course(np.linspace(0, 10, 101))\n    .get_result()\n).get_combined()\n\nfig, ax = plot.lines(res)\nax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\")\nplt.show()\n</pre> # As a small trick, let's define a variable for the model function # That way, we can re-use it all over the file and easily replace # it with another model model_fn = get_linear_chain_2v  res = unwrap(     Simulator(model_fn())     .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})     .simulate_time_course(np.linspace(0, 10, 101))     .get_result() ).get_combined()  fig, ax = plot.lines(res) ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. &amp; Flux / a.u.\") plt.show() In\u00a0[3]: Copied! <pre>data = res.iloc[-1]\ndata.head()\n</pre> data = res.iloc[-1] data.head() Out[3]: <pre>x     0.500000\ny     1.000045\nv1    1.000000\nv2    1.000000\nv3    1.000045\nName: 10.0, dtype: float64</pre> In\u00a0[4]: Copied! <pre>fit.steady_state(\n    model_fn(),\n    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n    data=res.iloc[-1],\n)\n</pre> fit.steady_state(     model_fn(),     p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},     data=res.iloc[-1], ) Out[4]: <pre>{'k1': np.float64(1.000015202475239),\n 'k2': np.float64(2.0000309249184327),\n 'k3': np.float64(0.9999697802169417)}</pre> <p>If only some of the data is required, you can use a subset of it. The fitting routine will only try to fit concentrations and fluxes contained in that series.</p> In\u00a0[5]: Copied! <pre>fit.steady_state(\n    model_fn(),\n    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n    data=data.loc[[\"x\", \"y\"]],\n)\n</pre> fit.steady_state(     model_fn(),     p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},     data=data.loc[[\"x\", \"y\"]], ) Out[5]: <pre>{'k1': np.float64(0.9829433889293213),\n 'k2': np.float64(1.9658867533095319),\n 'k3': np.float64(0.9828987681888647)}</pre> In\u00a0[6]: Copied! <pre>fit.time_course(\n    model_fn(),\n    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n    data=res,\n)\n</pre> fit.time_course(     model_fn(),     p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},     data=res, ) Out[6]: <pre>{'k1': np.float64(0.9999999948101959),\n 'k2': np.float64(1.9999999615864308),\n 'k3': np.float64(0.9999999922253802)}</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about fitting in mxlpy.           Congratulations!  In\u00a0[7]: Copied! <pre>from typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from mxlpy.fit import ResidualFn\n\n\ndef nelder_mead(\n    residual_fn: ResidualFn,\n    p0: dict[str, float],\n) -&gt; dict[str, float]:\n    res = minimize(\n        residual_fn,\n        x0=list(p0.values()),\n        method=\"Nelder-Mead\",\n    )\n    if res.success:\n        return dict(\n            zip(\n                p0,\n                res.x,\n                strict=True,\n            )\n        )\n    return dict(zip(p0, np.full(len(p0), np.nan, dtype=float), strict=True))\n\n\nfit.time_course(\n    model_fn(),\n    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n    data=res,\n    minimize_fn=nelder_mead,\n)\n</pre> from typing import TYPE_CHECKING  if TYPE_CHECKING:     from mxlpy.fit import ResidualFn   def nelder_mead(     residual_fn: ResidualFn,     p0: dict[str, float], ) -&gt; dict[str, float]:     res = minimize(         residual_fn,         x0=list(p0.values()),         method=\"Nelder-Mead\",     )     if res.success:         return dict(             zip(                 p0,                 res.x,                 strict=True,             )         )     return dict(zip(p0, np.full(len(p0), np.nan, dtype=float), strict=True))   fit.time_course(     model_fn(),     p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},     data=res,     minimize_fn=nelder_mead, ) Out[7]: <pre>{'k1': np.float64(1.0000044128393781),\n 'k2': np.float64(1.9999586259064912),\n 'k3': np.float64(1.000005095705572)}</pre>"},{"location":"fitting.html#fitting","title":"Fitting\u00b6","text":"<p>Almost every model at some point needs to be fitted to experimental data to be validated.</p> <p>mxlpy offers highly customisable routines for fitting either time series or steady-states.</p> <p></p> <p>For this tutorial we are going to use the <code>fit</code> module to optimise our parameter values and the <code>plot</code> module to plot some results.</p> <p>Let's get started!</p>"},{"location":"fitting.html#creating-synthetic-data","title":"Creating synthetic data\u00b6","text":"<p>Normally, you would fit your model to experimental data. Here, for the sake of simplicity, we will generate some synthetic data.</p> <p>Checkout the basics tutorial if you need a refresher on building and simulating models.</p>"},{"location":"fitting.html#steady-states","title":"Steady-states\u00b6","text":"<p>For the steady-state fit we need two inputs:</p> <ol> <li>the steady state data, which we supply as a <code>pandas.Series</code></li> <li>an initial parameter guess</li> </ol> <p>The fitting routine will compare all data contained in that series to the model output.</p> <p>Note that the data both contains concentrations and fluxes!</p>"},{"location":"fitting.html#time-course","title":"Time course\u00b6","text":"<p>For the time course fit we need again need two inputs</p> <ol> <li>the time course data, which we supply as a <code>pandas.DataFrame</code></li> <li>an initial parameter guess</li> </ol> <p>The fitting routine will create data at every time points specified in the <code>DataFrame</code> and compare all of them.</p> <p>Other than that, the same rules of the steady-state fitting apply.</p>"},{"location":"fitting.html#advanced-topics-customisation","title":"Advanced topics / customisation\u00b6","text":"<p>You can use dependency injection to overwrite the minimisation function as well as the residual function and the integrator. Here we create a custom minimization function.</p>"},{"location":"integrators.html","title":"Integrator configuration","text":"In\u00a0[1]: Copied! <pre>from functools import partial\n\nfrom example_models import get_linear_chain_2v\nfrom mxlpy import Simulator, unwrap\nfrom mxlpy.integrators import Scipy\n\nmodel = get_linear_chain_2v()\n\n# You can explicitly set an integrator for the simulation\ns = Simulator(model, integrator=Scipy)\n\n# You can also change the default settings of each integrator\ns = Simulator(model, integrator=partial(Scipy, atol=1e-6, rtol=1e-6))\ns.simulate(5)\n\n# You can also change integration settings mid simulation\n# As not all integrators have the same settings, we recommend explicitly checking\n# which integrator is currently set\nif isinstance(s.integrator, Scipy):\n    s.integrator.atol = 1e-6\n    s.integrator.rtol = 1e-6\n\nunwrap(s.simulate(10).get_result()).variables.plot()\n</pre> from functools import partial  from example_models import get_linear_chain_2v from mxlpy import Simulator, unwrap from mxlpy.integrators import Scipy  model = get_linear_chain_2v()  # You can explicitly set an integrator for the simulation s = Simulator(model, integrator=Scipy)  # You can also change the default settings of each integrator s = Simulator(model, integrator=partial(Scipy, atol=1e-6, rtol=1e-6)) s.simulate(5)  # You can also change integration settings mid simulation # As not all integrators have the same settings, we recommend explicitly checking # which integrator is currently set if isinstance(s.integrator, Scipy):     s.integrator.atol = 1e-6     s.integrator.rtol = 1e-6  unwrap(s.simulate(10).get_result()).variables.plot() Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"integrators.html#integrator-configuration","title":"Integrator configuration\u00b6","text":"<p>You can explicitly control which integrator is used for the simulations. As all integrators have different settings, changing them is done on the integrator object itself, which can be found at <code>Simulator().integrator</code>.</p> <p>By default, the <code>Assimulo</code> integrator is used. However, that package currenlty requires installation via <code>conda-forge</code>. If <code>mxlpy</code> was installed from <code>pypi</code>, this package is not available and <code>mxlpy</code> will fall back to the <code>Scipy</code> package. Thus, when setting integrator settings you should always check which integrator you are actually working with, as this otherwise might lead bugs on other systems.</p>"},{"location":"label-models.html","title":"Label models","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom typing import Any\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_linear_chain_2v, get_tpi_ald_model\nfrom mxlpy import (\n    LabelMapper,\n    LinearLabelMapper,\n    Simulator,\n    plot,\n)\nfrom mxlpy.types import unwrap\n\n\ndef print_annotated(description: str, value: Any) -&gt; None:\n    print(\n        description,\n        value,\n        sep=\"\\n\",\n        end=\"\\n\\n\",\n    )\n</pre> from __future__ import annotations  from typing import Any  import matplotlib.pyplot as plt  from example_models import get_linear_chain_2v, get_tpi_ald_model from mxlpy import (     LabelMapper,     LinearLabelMapper,     Simulator,     plot, ) from mxlpy.types import unwrap   def print_annotated(description: str, value: Any) -&gt; None:     print(         description,         value,         sep=\"\\n\",         end=\"\\n\\n\",     ) In\u00a0[2]: Copied! <pre>mapper = LabelMapper(\n    get_tpi_ald_model(),\n    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n    label_maps={\n        \"TPIf\": [2, 1, 0],\n        \"TPIr\": [2, 1, 0],\n        \"ALDf\": [0, 1, 2, 3, 4, 5],\n        \"ALDr\": [0, 1, 2, 3, 4, 5],\n    },\n)\n\n\nlabels = unwrap(\n    Simulator(mapper.build_model(initial_labels={\"GAP\": 0})).simulate(20).get_result()\n).variables\n\nfig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3)\nplt.show()\n</pre> mapper = LabelMapper(     get_tpi_ald_model(),     label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},     label_maps={         \"TPIf\": [2, 1, 0],         \"TPIr\": [2, 1, 0],         \"ALDf\": [0, 1, 2, 3, 4, 5],         \"ALDr\": [0, 1, 2, 3, 4, 5],     }, )   labels = unwrap(     Simulator(mapper.build_model(initial_labels={\"GAP\": 0})).simulate(20).get_result() ).variables  fig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3) plt.show() <pre>/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n/home/runner/work/MxlPy/MxlPy/src/mxlpy/types.py:292: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  dependent[name] = self.fn(*dependent.loc[:, self.args].to_numpy().T)\n</pre> In\u00a0[3]: Copied! <pre>model_fn = get_tpi_ald_model()\n\nconcs, fluxes = unwrap(Simulator(model_fn).simulate(20).get_result())\n\n\nmapper = LinearLabelMapper(\n    model=model_fn,\n    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n    label_maps={\n        \"TPIf\": [2, 1, 0],\n        \"TPIr\": [2, 1, 0],\n        \"ALDf\": [0, 1, 2, 3, 4, 5],\n        \"ALDr\": [0, 1, 2, 3, 4, 5],\n    },\n)\n\n\nlabels = unwrap(\n    Simulator(\n        mapper.build_model(\n            concs=concs.iloc[-1],\n            fluxes=fluxes.iloc[-1],\n            initial_labels={\"GAP\": 0},\n        )\n    )\n    .simulate(20)\n    .get_result()\n).variables\nfig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3)\nplt.show()\n</pre> model_fn = get_tpi_ald_model()  concs, fluxes = unwrap(Simulator(model_fn).simulate(20).get_result())   mapper = LinearLabelMapper(     model=model_fn,     label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},     label_maps={         \"TPIf\": [2, 1, 0],         \"TPIr\": [2, 1, 0],         \"ALDf\": [0, 1, 2, 3, 4, 5],         \"ALDr\": [0, 1, 2, 3, 4, 5],     }, )   labels = unwrap(     Simulator(         mapper.build_model(             concs=concs.iloc[-1],             fluxes=fluxes.iloc[-1],             initial_labels={\"GAP\": 0},         )     )     .simulate(20)     .get_result() ).variables fig, ax = plot.relative_label_distribution(mapper, labels, n_cols=3) plt.show() First finish line     With that you now know most of what you will need from a day-to-day basis about labelled models in mxlpy.           Congratulations!  In\u00a0[4]: Copied! <pre>model = get_linear_chain_2v()\nconcs, fluxes = unwrap(Simulator(model).simulate(100).get_result())\nmapper = LinearLabelMapper(\n    model,\n    label_variables={\"x\": 2, \"y\": 2},\n    label_maps={\n        \"v1\": [0, 1],\n        \"v2\": [0, 1],\n        \"v3\": [0, 1],\n    },\n)\n\nlabel_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n)\n\n# Access the external label pool\nprint(label_model.parameters[\"EXT\"])\n\n# A reaction that consumes the external label pool\nprint(label_model.reactions[\"v1__0\"].args)\n\n# A reaction that doesn't require the external label pool\nprint(label_model.reactions[\"v2__0\"].args)\n</pre> model = get_linear_chain_2v() concs, fluxes = unwrap(Simulator(model).simulate(100).get_result()) mapper = LinearLabelMapper(     model,     label_variables={\"x\": 2, \"y\": 2},     label_maps={         \"v1\": [0, 1],         \"v2\": [0, 1],         \"v3\": [0, 1],     }, )  label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1], )  # Access the external label pool print(label_model.parameters[\"EXT\"])  # A reaction that consumes the external label pool print(label_model.reactions[\"v1__0\"].args)  # A reaction that doesn't require the external label pool print(label_model.reactions[\"v2__0\"].args) <pre>1.0\n['EXT', 'v1']\n['x__0', 'v2']\n</pre> <p>You can modify the external concentration to your liking by simply updating the parameter value.</p> In\u00a0[5]: Copied! <pre>fig, ax = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model)\n        .update_parameter(\"EXT\", 1.0)  # update exeternal label to fully labelled\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"Fully labelled external pool\")\nplt.show()\n</pre> fig, ax = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model)         .update_parameter(\"EXT\", 1.0)  # update exeternal label to fully labelled         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"Fully labelled external pool\") plt.show() In\u00a0[6]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model)\n        .update_parameter(\"EXT\", 0.5)  # update external label to half labelled\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"Half labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model)         .update_parameter(\"EXT\", 0.5)  # update external label to half labelled         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"Half labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>Somewhat trivially, if you have no external label, there is no influx of labels</p> In\u00a0[7]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model).update_parameter(\"EXT\", 0.0).simulate(20).get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model).update_parameter(\"EXT\", 0.0).simulate(20).get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"No labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>However, we can imagine a scenario where some initial labels are given, even though there is no external labeling. You can achieve that by updating the initial conditions like so.</p> In\u00a0[8]: Copied! <pre>fig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(label_model, y0=label_model.get_initial_conditions() | {\"x__0\": 1.0})\n        .update_parameter(\"EXT\", 0.0)\n        .simulate(20)\n        .get_result()\n    ).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No labelled external pool\")\nfor ax in axs:\n    ax.set_ylim(0, 1)\nplt.show()\n</pre> fig, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(label_model, y0=label_model.get_initial_conditions() | {\"x__0\": 1.0})         .update_parameter(\"EXT\", 0.0)         .simulate(20)         .get_result()     ).variables,     n_cols=3, ) fig.suptitle(\"No labelled external pool\") for ax in axs:     ax.set_ylim(0, 1) plt.show() <p>For convenience, the <code>build_model</code> function also allows you to set the external labels and the initial labels. Here, <code>initial_labels</code> specifies the position at which the initial label is given.</p> In\u00a0[9]: Copied! <pre>label_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n    external_label=0.0,\n    initial_labels={\"x\": 0},\n)\n\nfig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(Simulator(label_model).simulate(20).get_result()).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No external label, but initial label in C1 of x\")\nplt.show()\n</pre> label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1],     external_label=0.0,     initial_labels={\"x\": 0}, )  fig, axs = plot.relative_label_distribution(     mapper,     unwrap(Simulator(label_model).simulate(20).get_result()).variables,     n_cols=3, ) fig.suptitle(\"No external label, but initial label in C1 of x\") plt.show() <p>You can also distribute that initial label across multiple label positions of the variable.</p> In\u00a0[10]: Copied! <pre>label_model = mapper.build_model(\n    concs=concs.iloc[-1],\n    fluxes=fluxes.iloc[-1],\n    external_label=0.0,\n    initial_labels={\"x\": [0, 1]},\n)\n\nfig, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(Simulator(label_model).simulate(20).get_result()).variables,\n    n_cols=3,\n)\nfig.suptitle(\"No external label, but initial label in C1 &amp; C2 of x\")\nplt.show()\n</pre> label_model = mapper.build_model(     concs=concs.iloc[-1],     fluxes=fluxes.iloc[-1],     external_label=0.0,     initial_labels={\"x\": [0, 1]}, )  fig, axs = plot.relative_label_distribution(     mapper,     unwrap(Simulator(label_model).simulate(20).get_result()).variables,     n_cols=3, ) fig.suptitle(\"No external label, but initial label in C1 &amp; C2 of x\") plt.show()"},{"location":"label-models.html#labeled-models","title":"Labeled models\u00b6","text":"<p>Labelled models allow explicitly mapping the transitions between isotopomers variables. This, for example, allows building models of the Calvin-Benson-Bassham cycle, in which each carbon atom can be labelled individually:</p> <p>mxlpy includes a <code>LabelMapper</code> that takes</p> <ul> <li>a model</li> <li>a dictionary mapping the variables to the amount of label positions they have</li> <li>a transition map</li> </ul> <p>to auto-generate all possible <code>2^n</code> variants of the variables and reaction transitions between them.</p> <p>As an example let's take triose phosphate isomerase, which catalyzes the interconversion of glyceraldehyde 3-phosphate (GAP) and dihydroxyacetone phosphate (DHAP). As illustrated below, in the case of the forward reaction the first and last carbon atoms are swapped</p> <p>So DHAP(1) is build from GAP(3), DHAP(2) from GAP(2) and DHAP(3) from GAP(1). We notate this using normal 0-based indexing as follows</p> <pre>label_maps = {\"TPIf\": [2, 1, 0]}\n</pre>"},{"location":"label-models.html#linear-label-mapper","title":"Linear label mapper\u00b6","text":"<p>The <code>LabelMapper</code> makes no assumptions about the state of the model, which causes a lot of complexity. In steady-state however, the space of possible solutions is reduced and the labelling dynamics can be represented by a set of linear differential equations. See Sokol and Portais 2015 for the theory of dynamic label propagation under the stationary assumption.</p>"},{"location":"label-models.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"label-models.html#external-initial-labels","title":"External &amp; initial labels\u00b6","text":"<p>In the case of open models, we make the assumption that there is a static pool of external labels. For example, this could be the labelled portion of ambient carbon dioxide. We denote that external label pool with <code>EXT</code> and by default set the value <code>1.0</code> to it, which means that it is fully labelled.</p>"},{"location":"mca.html","title":"MCA","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\n\nfrom example_models import get_upper_glycolysis\nfrom mxlpy import plot\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt  from example_models import get_upper_glycolysis from mxlpy import plot In\u00a0[2]: Copied! <pre>from mxlpy import mca\n</pre> from mxlpy import mca In\u00a0[3]: Copied! <pre>elas = mca.variable_elasticities(\n    get_upper_glycolysis(),\n    to_scan=[\"GLC\", \"F6P\"],\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n)\n\n_ = plot.heatmap(elas)\nplt.show()\n</pre> elas = mca.variable_elasticities(     get_upper_glycolysis(),     to_scan=[\"GLC\", \"F6P\"],     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     }, )  _ = plot.heatmap(elas) plt.show() In\u00a0[4]: Copied! <pre>elas = mca.parameter_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"k1\", \"k2\"],\n)\n\n_ = plot.heatmap(elas)\nplt.show()\n</pre> elas = mca.parameter_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"k1\", \"k2\"], )  _ = plot.heatmap(elas) plt.show() In\u00a0[5]: Copied! <pre>crcs, frcs = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n_ = plot.heatmap(crcs, ax=ax1)\n_ = plot.heatmap(frcs, ax=ax2)\nplt.show()\n</pre> crcs, frcs = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"], )  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4)) _ = plot.heatmap(crcs, ax=ax1) _ = plot.heatmap(frcs, ax=ax2) plt.show() <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:03,  1.65it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:01&lt;00:00,  5.07it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:01&lt;00:00,  6.05it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about metabolic control analysis in mxlpy.           Congratulations!  In\u00a0[6]: Copied! <pre>_ = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n    normalized=False,\n)\n</pre> _ = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],     normalized=False, ) <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:02,  2.38it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:00&lt;00:00,  8.61it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 10.78it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00,  8.26it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>_ = mca.response_coefficients(\n    get_upper_glycolysis(),\n    to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n    displacement=1e-2,\n)\n</pre> _ = mca.response_coefficients(     get_upper_glycolysis(),     to_scan=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],     displacement=1e-2, ) <pre>\r  0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258d        | 1/7 [00:00&lt;00:03,  1.61it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:00&lt;00:00,  6.19it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:01&lt;00:00,  6.19it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:01&lt;00:00,  6.10it/s]</pre> <pre>\n</pre>"},{"location":"mca.html#metabolic-control-analysis","title":"Metabolic control analysis\u00b6","text":"<p>Metabolic control analysis answers the question: what happens to the concentrations and fluxes if I slightly perturb the system? It is thus a local measurement about which reactions hold the most control.</p> <p>The most common measurements are elasticities and response coefficients. The main difference between them is that response coefficients are calculated at steady-state, while elasticities can be calculated at every arbitrary state.</p> <p>All the required functionality can be found in the <code>mxlpy.mca</code> module.</p> <p>As an example, we will use the upper glycolysis model from the Systems Biology textbook by Klipp et al. (2005).</p>"},{"location":"mca.html#variable-elasticities","title":"Variable elasticities\u00b6","text":"<p>Variable elasticities are the sensitivity of reactions to a small change in the concentration of a variable. They are not a steady-state measurement and can be calculated for any arbitrary state.</p> <p></p> <p>Both the <code>concs</code> and <code>variables</code> arguments are optional. If <code>concs</code> is not supplied, the routine will use the initial conditions from the model. If <code>variables</code> is not supplied, the elasticities will be calculated for all variables.</p>"},{"location":"mca.html#parameter-elasticities","title":"Parameter elasticities\u00b6","text":"<p>Similarly, parameter elasticities are the sensitivity of reactions to a small change in the concentration of a variable. They are not a steady-state measurement and can be calculated for any arbitrary state.</p> <p></p> <p>Both the <code>concs</code> and <code>parameters</code> arguments are optional. If <code>concs</code> is not supplied, the routine will use the initial conditions from the model. If <code>parameters</code> is not supplied, the elasticities will be calculated for all parameters.</p>"},{"location":"mca.html#response-coefficients","title":"Response coefficients\u00b6","text":"<p>Response coefficients show the sensitivity of variables and reactions at steady-state to a small change in a parameter.</p> <p></p> <p>If the parameter is proportional to the rate, they are also called control coefficients.</p> <p>Calculation of these is run in parallel by default.</p>"},{"location":"mca.html#advanced-concepts-customisation","title":"Advanced concepts / customisation\u00b6","text":""},{"location":"mca.html#normalisation","title":"Normalisation\u00b6","text":"<p>By default the elasticities and response coefficients are normalised, so e.g. for the response coefficients the following is calculated:</p> <p>$$C^J_{v_i} = \\left( \\frac{dJ}{dp} \\frac{p}{J} \\right) \\bigg/ \\left( \\frac{\\partial v_i}{\\partial  p}\\frac{p}{v_i} \\right)$$</p> <p>You can also obtain the non-normalised coefficients, by setting <code>normalized=False</code>, which amounts to the following calculation:</p> <p>$$C^J_{v_i} = \\left( \\frac{dJ}{dp} \\frac{p}{J} \\right)$$</p>"},{"location":"mca.html#displacement","title":"Displacement\u00b6","text":"<p>We wrote above that we slightly change the value, but by how much exactly? By default the relative change is set to <code>1e-4</code>. <code>mxlpy</code> uses a central finite difference approximation, which means that in this case change the value to $$\\textrm{value} \\cdot \\left(1 \\pm 10^{-4} \\right)$$</p> <p>which amounts to a change of <code>0.01 %</code>.</p> <p>You can set that using the <code>displacement</code> argument.</p>"},{"location":"metaprogramming.html","title":"Metaprogramming","text":"In\u00a0[1]: Copied! <pre>from example_models import get_linear_chain_1v, get_linear_chain_2v\nfrom mxlpy.meta import (\n    generate_latex_code,\n    generate_model_code_py,\n    generate_mxlpy_code,\n)\n</pre> from example_models import get_linear_chain_1v, get_linear_chain_2v from mxlpy.meta import (     generate_latex_code,     generate_model_code_py,     generate_mxlpy_code, ) In\u00a0[2]: Copied! <pre>print(generate_mxlpy_code(get_linear_chain_1v()))\n</pre> print(generate_mxlpy_code(get_linear_chain_1v())) <pre>from mxlpy import Model\n\ndef constant(k_in: float) -&gt; float:\n    return k_in\n    \n\ndef mass_action_1s(k_out: float, x: float) -&gt; float:\n    return k_out*x\n    \ndef create_model() -&gt; Model:\n    return (\n        Model()\n        .add_parameters({'k_in': 1.0, 'k_out': 1.0})\n        .add_variables({'x': 1.0})\n        .add_reaction(\n                \"v_in\",\n                fn=constant,\n                args=['k_in'],\n                stoichiometry={\"x\": 1},\n            )\n        .add_reaction(\n                \"v_out\",\n                fn=mass_action_1s,\n                args=['k_out', 'x'],\n                stoichiometry={\"x\": -1},\n            )\n    )\n</pre> <p><code>mxlpy</code> can also generate a generic python function from the source code. The plan here is to generalise this to be able to export models into other programming languages as well.</p> In\u00a0[3]: Copied! <pre>print(generate_model_code_py(get_linear_chain_2v()))\n</pre> print(generate_model_code_py(get_linear_chain_2v())) <pre>from collections.abc import Iterable\n\nfrom mxlpy.types import Float\n\ndef model(t: Float, variables: Float) -&gt; Iterable[Float]:\n    x, y = variables\n    k1 = 1.0\n    k2 = 2.0\n    k3 = 1.0\n    v1 = k1\n    v2 = k2*x\n    v3 = k3*y\n    dxdt = v1 -v2\n    dydt = v2 -v3\n    return dxdt, dydt\n</pre> In\u00a0[4]: Copied! <pre>print(generate_latex_code(get_linear_chain_1v()))\n</pre> print(generate_latex_code(get_linear_chain_1v())) <pre>\\documentclass{article}\n\\usepackage[english]{babel}\n\\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}\n\\usepackage{amsmath, amssymb, array, booktabs,\n            breqn, caption, longtable, mathtools, placeins,\n            ragged2e, tabularx, titlesec, titling}\n\\newcommand{\\sectionbreak}{\\clearpage}\n\\setlength{\\parindent}{0pt}\n\n\\title{Model construction}\n\\date{} % clear date\n\\author{mxlpy}\n\\begin{document}\n\\maketitle\n\\FloatBarrier\\subsubsection*{Variables}\n\\begin{longtable}{c|c}\n    Model name &amp; Initial concentration \\\\\n    \\hline\n    \\endhead\n    x &amp; 1.00e+00 \\\\\n    \\caption[Model variables]{Model variables}\n    \\label{table:model-vars}\n\\end{longtable}\n\n\\FloatBarrier\\subsubsection*{Parameters}\n\\begin{longtable}{c|c}\n    Parameter name &amp; Parameter value \\\\\n    \\hline\n    \\endhead\n    $\\mathrm{k\\_in}$ &amp; 1.00e+00 \\\\\n    $\\mathrm{k\\_out}$ &amp; 1.00e+00 \\\\\n    \\caption[Model parameters]{Model parameters}\n    \\label{table:model-pars}\n\\end{longtable}\n\n\\FloatBarrier\\subsubsection*{Reactions}\n\\begin{dmath*}\n    v_in = k_{in}\n\\end{dmath*}\n\n\\begin{dmath*}\n    v_out = k_{out} x\n\\end{dmath*}\n\n\\FloatBarrier\\subsubsection*{Stoichiometries}\n\\begin{longtable}{c|c}\n    Rate name &amp; Stoichiometry \\\\\n    \\hline\n    \\endhead\n    v\\_in &amp; $\\mathrm{x}$ \\\\\n    v\\_out &amp; $-\\mathrm{x}$ \\\\\n    \\caption[Model stoichiometries.]{Model stoichiometries.}\n    \\label{table:model-stoichs}\n\\end{longtable}\n\\end{document}\n\n</pre>"},{"location":"metaprogramming.html#metaprogramming","title":"Metaprogramming\u00b6","text":""},{"location":"metaprogramming.html#code-generation","title":"code generation\u00b6","text":"<p>Currently, the limitation here is that functions used for reactions etc. cannot call other functions.</p> <p><code>mxlpy</code> can generate own source code from a model.</p>"},{"location":"metaprogramming.html#latex-export","title":"LaTeX export\u00b6","text":"<p>Currently, the limitation here is that functions used for reactions etc. cannot call other functions.</p> <p><code>mxlpy</code> supports writing out your model as <code>LaTeX</code>.</p>"},{"location":"monte-carlo.html","title":"Monte Carlo methods","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport mxlpy as mb2\nfrom example_models import (\n    get_lin_chain_two_circles,\n    get_linear_chain_2v,\n    get_upper_glycolysis,\n)\nfrom mxlpy import make_protocol, mc, mca, plot\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np import pandas as pd  import mxlpy as mb2 from example_models import (     get_lin_chain_two_circles,     get_linear_chain_2v,     get_upper_glycolysis, ) from mxlpy import make_protocol, mc, mca, plot In\u00a0[2]: Copied! <pre>from mxlpy.distributions import LogNormal, Uniform, sample\n\nsample(\n    {\n        \"k2\": Uniform(1.0, 2.0),\n        \"k3\": LogNormal(mean=1.0, sigma=1.0),\n    },\n    n=5,\n)\n</pre> from mxlpy.distributions import LogNormal, Uniform, sample  sample(     {         \"k2\": Uniform(1.0, 2.0),         \"k3\": LogNormal(mean=1.0, sigma=1.0),     },     n=5, ) Out[2]: k2 k3 0 1.773956 0.739205 1 1.438878 3.088978 2 1.858598 1.981308 3 1.697368 2.672993 4 1.094177 1.158303 In\u00a0[3]: Copied! <pre>ss = mc.steady_state(\n    get_linear_chain_2v(),\n    mc_to_scan=sample(\n        {\n            \"k1\": Uniform(0.9, 1.1),\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5), sharex=False)\nplot.violins(ss.variables, ax=ax1)\nplot.violins(ss.fluxes, ax=ax2)\nax1.set(xlabel=\"Variables\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Reactions\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> ss = mc.steady_state(     get_linear_chain_2v(),     mc_to_scan=sample(         {             \"k1\": Uniform(0.9, 1.1),             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2.5), sharex=False) plot.violins(ss.variables, ax=ax1) plot.violins(ss.fluxes, ax=ax2) ax1.set(xlabel=\"Variables\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Reactions\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00&lt;00:00, 49.58it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 65.91it/s]</pre> <pre>\n</pre> In\u00a0[4]: Copied! <pre>tc = mc.time_course(\n    get_linear_chain_2v(),\n    time_points=np.linspace(0, 1, 11),\n    mc_to_scan=sample(\n        {\n            \"k1\": Uniform(0.9, 1.1),\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2)\nax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tc = mc.time_course(     get_linear_chain_2v(),     time_points=np.linspace(0, 1, 11),     mc_to_scan=sample(         {             \"k1\": Uniform(0.9, 1.1),             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2) ax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 68.49it/s]</pre> <pre>\n</pre> In\u00a0[5]: Copied! <pre>tc = mc.time_course_over_protocol(\n    get_linear_chain_2v(),\n    time_points_per_step=10,\n    protocol=make_protocol(\n        [\n            (1, {\"k1\": 1}),\n            (2, {\"k1\": 2}),\n            (3, {\"k1\": 1}),\n        ]\n    ),\n    mc_to_scan=sample(\n        {\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2)\nfor ax in (ax1, ax2):\n    plot.shade_protocol(tc.protocol[\"k1\"], ax=ax, alpha=0.1)\n\nax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tc = mc.time_course_over_protocol(     get_linear_chain_2v(),     time_points_per_step=10,     protocol=make_protocol(         [             (1, {\"k1\": 1}),             (2, {\"k1\": 2}),             (3, {\"k1\": 1}),         ]     ),     mc_to_scan=sample(         {             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tc.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tc.fluxes, ax=ax2) for ax in (ax1, ax2):     plot.shade_protocol(tc.protocol[\"k1\"], ax=ax, alpha=0.1)  ax1.set(xlabel=\"Time / a.u\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"Time / a.u\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 10%|\u2588         | 1/10 [00:00&lt;00:00,  9.45it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 36.40it/s]</pre> <pre>\n</pre> In\u00a0[6]: Copied! <pre>mc_elas = mc.variable_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"GLC\", \"F6P\"],\n    mc_to_scan=sample(\n        {\n            # \"k1\": LogNormal(mean=np.log(0.25), sigma=1.0),\n            # \"k2\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            \"k3\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k4\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k5\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k6\": LogNormal(mean=np.log(1.0), sigma=1.0),\n            # \"k7\": LogNormal(mean=np.log(2.5), sigma=1.0),\n        },\n        n=5,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(mc_elas)\nplt.show()\n</pre> mc_elas = mc.variable_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"GLC\", \"F6P\"],     mc_to_scan=sample(         {             # \"k1\": LogNormal(mean=np.log(0.25), sigma=1.0),             # \"k2\": LogNormal(mean=np.log(1.0), sigma=1.0),             \"k3\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k4\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k5\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k6\": LogNormal(mean=np.log(1.0), sigma=1.0),             # \"k7\": LogNormal(mean=np.log(2.5), sigma=1.0),         },         n=5,     ), )  _ = plot.violins_from_2d_idx(mc_elas) plt.show() <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 33.51it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>elas = mc.parameter_elasticities(\n    get_upper_glycolysis(),\n    variables={\n        \"GLC\": 0.3,\n        \"G6P\": 0.4,\n        \"F6P\": 0.5,\n        \"FBP\": 0.6,\n        \"ATP\": 0.4,\n        \"ADP\": 0.6,\n    },\n    to_scan=[\"k1\", \"k2\", \"k3\"],\n    mc_to_scan=sample(\n        {\n            \"k3\": LogNormal(mean=np.log(0.25), sigma=1.0),\n        },\n        n=5,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(elas)\nplt.show()\n</pre> elas = mc.parameter_elasticities(     get_upper_glycolysis(),     variables={         \"GLC\": 0.3,         \"G6P\": 0.4,         \"F6P\": 0.5,         \"FBP\": 0.6,         \"ATP\": 0.4,         \"ADP\": 0.6,     },     to_scan=[\"k1\", \"k2\", \"k3\"],     mc_to_scan=sample(         {             \"k3\": LogNormal(mean=np.log(0.25), sigma=1.0),         },         n=5,     ), )  _ = plot.violins_from_2d_idx(elas) plt.show() <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 29.27it/s]</pre> <pre>\n</pre> In\u00a0[8]: Copied! <pre># Compare with \"normal\" control coefficients\nrc = mca.response_coefficients(\n    get_lin_chain_two_circles(),\n    to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],\n)\n_ = plot.heatmap(rc.variables)\n\nmrc = mc.response_coefficients(\n    get_lin_chain_two_circles(),\n    to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],\n    mc_to_scan=sample(\n        {\n            \"k0\": LogNormal(np.log(1.0), 1.0),\n            \"k4\": LogNormal(np.log(0.5), 1.0),\n        },\n        n=10,\n    ),\n)\n\n_ = plot.violins_from_2d_idx(mrc.variables, n_cols=len(mrc.variables.columns))\n</pre> # Compare with \"normal\" control coefficients rc = mca.response_coefficients(     get_lin_chain_two_circles(),     to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"], ) _ = plot.heatmap(rc.variables)  mrc = mc.response_coefficients(     get_lin_chain_two_circles(),     to_scan=[\"vmax_1\", \"vmax_2\", \"vmax_3\", \"vmax_5\", \"vmax_6\"],     mc_to_scan=sample(         {             \"k0\": LogNormal(np.log(1.0), 1.0),             \"k4\": LogNormal(np.log(0.5), 1.0),         },         n=10,     ), )  _ = plot.violins_from_2d_idx(mrc.variables, n_cols=len(mrc.variables.columns)) <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.67it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 10.55it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00,  7.66it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  3.27it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.38it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.12it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.06it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:00,  3.12it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.35it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:00&lt;00:00,  3.17it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.12it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.05it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.20it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.33it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.11it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.03it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.19it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.17it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r 10%|\u2588         | 1/10 [00:01&lt;00:14,  1.63s/it]</pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.36it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.10it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.01it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.45it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.36it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.35it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.09it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.09it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.40it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.04it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.03it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r 20%|\u2588\u2588        | 2/10 [00:02&lt;00:09,  1.20s/it]</pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:02,  1.55it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.31it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.47it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.04it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.36it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.47it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.00it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:01&lt;00:02,  1.42it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.47it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.29it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.32it/s]</pre> <pre>\n</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&lt;00:03,  1.55it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:01,  1.98it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.44it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:02&lt;00:01,  1.48it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.10it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:02&lt;00:00,  1.98it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.45it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  2.45it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.11it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:02&lt;00:00,  1.50it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  1.96it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:02&lt;00:00,  1.97it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r 20%|\u2588\u2588        | 1/5 [00:00&lt;00:01,  2.36it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.34it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  2.75it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 2/5 [00:00&lt;00:01,  2.33it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:03&lt;00:00,  1.53it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:03&lt;00:00,  1.50it/s]</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&lt;00:03,  1.09it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.02it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  2.68it/s]</pre> <pre>\n</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&lt;00:00,  2.14it/s]</pre> <pre>\n</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 3/5 [00:01&lt;00:00,  2.72it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 4/5 [00:01&lt;00:00,  3.14it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.44it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:01&lt;00:00,  3.05it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&lt;00:00,  2.07it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&lt;00:00,  1.60it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about monte carlo methods in mxlpy.           Congratulations!  In\u00a0[9]: Copied! <pre>mcss = mc.scan_steady_state(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),\n    mc_to_scan=sample(\n        {\n            \"k2\": Uniform(1.0, 1.3),\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nplot.violins_from_2d_idx(mcss.variables)\nplt.show()\n</pre> mcss = mc.scan_steady_state(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),     mc_to_scan=sample(         {             \"k2\": Uniform(1.0, 1.3),             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  plot.violins_from_2d_idx(mcss.variables) plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 30.76it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 29.31it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 26.97it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 29.71it/s]</pre> <pre></pre> <pre>\r 10%|\u2588         | 1/10 [00:00&lt;00:01,  6.28it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 27.85it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 27.36it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 24.47it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 31.65it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 28.47it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 27.58it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00&lt;00:00, 20.18it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 25.46it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 30.64it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 43.22it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 43.46it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 22.06it/s]</pre> <pre>\n</pre> In\u00a0[10]: Copied! <pre># FIXME: no idea how to plot this yet. Ridge plots?\n# Maybe it's just a bit much :D\n\nmcss = mc.scan_steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(0, 1, 3),\n            \"k2\": np.linspace(0, 1, 3),\n        }\n    ),\n    mc_to_scan=sample(\n        {\n            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n        },\n        n=10,\n    ),\n)\n\nmcss.variables.head()\n</pre> # FIXME: no idea how to plot this yet. Ridge plots? # Maybe it's just a bit much :D  mcss = mc.scan_steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(0, 1, 3),             \"k2\": np.linspace(0, 1, 3),         }     ),     mc_to_scan=sample(         {             \"k3\": LogNormal(mean=1.0, sigma=0.2),         },         n=10,     ), )  mcss.variables.head() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 15.70it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 19.04it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 15.51it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 16.33it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 18.65it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 16.40it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 16.33it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 15.10it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 22.11it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 19.60it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 20.45it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 19.10it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 21.84it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 20.24it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r 10%|\u2588         | 1/10 [00:00&lt;00:04,  2.01it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 20.36it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 19.29it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 17.06it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 19.30it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 18.28it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 22%|\u2588\u2588\u258f       | 2/9 [00:00&lt;00:00, 12.74it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 17.87it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 16.72it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 18.10it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 4/9 [00:00&lt;00:00, 14.92it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 21.70it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 20.79it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 20.77it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 22.53it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 19.31it/s]</pre> <pre></pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00&lt;00:00,  6.18it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 21.37it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r  0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 21.70it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 19.41it/s]</pre> <pre>\n</pre> <pre>\n</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 3/9 [00:00&lt;00:00, 28.03it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 3/9 [00:00&lt;00:00, 28.67it/s]</pre> <pre></pre> <pre>\n</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 7/9 [00:00&lt;00:00, 34.83it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 36.91it/s]</pre> <pre>\n</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01&lt;00:00,  9.21it/s]</pre> <pre>\n</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 8/9 [00:00&lt;00:00, 36.62it/s]</pre> <pre></pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 37.31it/s]</pre> <pre>\n</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01&lt;00:00,  7.83it/s]</pre> <pre>\n</pre> Out[10]: x y k1 k2 0 0.0 0.0 1.000000e+00 -3.825562e-23 0.5 -1.832836e-17 -2.579102e-18 1.0 -7.161368e-17 -2.105052e-17 0.5 0.0 NaN NaN 0.5 1.000000e+00 1.233791e-01 In\u00a0[11]: Copied! <pre>from dataclasses import dataclass\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from mxlpy.types import Array\n\n\n@dataclass\nclass MyOwnDistribution:\n    loc: float = 0.0\n    scale: float = 1.0\n\n    def sample(\n        self,\n        num: int,\n        rng: np.random.Generator | None = None,\n    ) -&gt; Array:\n        if rng is None:\n            rng = np.random.default_rng()\n        return rng.normal(loc=self.loc, scale=self.scale, size=num)\n\n\nsample({\"p1\": MyOwnDistribution()}, n=5)\n</pre> from dataclasses import dataclass from typing import TYPE_CHECKING  if TYPE_CHECKING:     from mxlpy.types import Array   @dataclass class MyOwnDistribution:     loc: float = 0.0     scale: float = 1.0      def sample(         self,         num: int,         rng: np.random.Generator | None = None,     ) -&gt; Array:         if rng is None:             rng = np.random.default_rng()         return rng.normal(loc=self.loc, scale=self.scale, size=num)   sample({\"p1\": MyOwnDistribution()}, n=5) Out[11]: p1 0 0.537181 1 0.700570 2 0.718040 3 -0.829239 4 -1.760548 In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"monte-carlo.html#monte-carlo-methods","title":"Monte Carlo methods\u00b6","text":"<p>Almost every parameter in biology is better described with a distribution than a single value. Monte-carlo methods allow you to capture the range of possible behaviour your model can exhibit. This is especially useful when you want to understand the uncertainty in your model's predictions.</p> <p>mxlpy offers these Monte Carlo methods for all scans  ...</p> + = <p>and even for metabolic control analysis</p> + = <p>In this tutorial we will mostly use the <code>mxlpy.distributions</code> and <code>mxlpy.mca</code> modules, which contain the functionality to sample from distributions and run distributed analyses.</p>"},{"location":"monte-carlo.html#sample-values","title":"Sample values\u00b6","text":"<p>To do any Monte-Carlo analysis, we first need to be able to sample values.</p> <p>For that, you can use the <code>sample</code> function and distributions supplied by mxlpy. These are mostly thin wrappers around the <code>numpy</code> and <code>scipy</code> sampling methods.</p>"},{"location":"monte-carlo.html#steady-state","title":"Steady-state\u00b6","text":"<p>Using <code>mc.steady_state</code> you can calculate the steady-state distribution given the monte-carlo parameters.</p> <p>This works analogously to the <code>scan.steady_state</code> function, except the index of the dataframes is always just an integer.</p> <p>The parameters used can be obtained by <code>result.parameters</code>.</p> <p>We will use a linear chain of reactions with two circles as an example model for this notebook.</p> <p>$$ \\begin{array}{c|c}     \\mathrm{Reaction} &amp; \\mathrm{Stoichiometry} \\\\     \\hline     v_0 &amp; \\varnothing \\rightarrow{} \\mathrm{x_1} \\\\     v_1 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_2} \\\\     v_2 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_3} \\\\     v_3 &amp; -\\mathrm{x_1} \\rightarrow{} \\mathrm{x_4} \\\\     v_4 &amp; -\\mathrm{x_4} \\rightarrow{} \\varnothing\\\\     v_5 &amp; -\\mathrm{x_2} \\rightarrow{} \\mathrm{x_1} \\\\     v_6 &amp; -\\mathrm{x_3} \\rightarrow{} \\mathrm{x_1} \\\\ \\end{array} $$</p>"},{"location":"monte-carlo.html#time-course","title":"Time course\u00b6","text":"<p>Using <code>mc.time_course</code> you can calculate time courses for sampled parameters.</p> + = <p>This function works analogously to <code>scan.time_course</code>.</p> <p>The <code>pandas.DataFrame</code>s for concentrations and fluxes have a <code>n x time</code> <code>pandas.MultiIndex</code>.</p> <p>The corresponding parameters can be found in <code>result.parameters</code></p>"},{"location":"monte-carlo.html#protocol-time-course","title":"Protocol time course\u00b6","text":"<p>Using <code>mc.time_course_over_protocol</code> you can calculate time courses for sampled parameters given a discrete protocol.</p> + = <p>The <code>pandas.DataFrame</code>s for concentrations and fluxes have a <code>n x time</code> <code>pandas.MultiIndex</code>. The corresponding parameters can be found in <code>scan.parameters</code></p>"},{"location":"monte-carlo.html#metabolic-control-analysis","title":"Metabolic control analysis\u00b6","text":"<p>mxlpy further has routines for monte-carlo distributed metabolic control analysis. This allows quantifying, whether the coefficients obtained from the MCA analysis are robust against parameter changes or whether they are just an artifact of a particular choice of parameters.</p>"},{"location":"monte-carlo.html#variable-elasticities","title":"Variable elasticities\u00b6","text":"+ = <p>The returned <code>pandas.DataFrame</code> has a <code>pd.MultiIndex</code> of shape <code>n x reaction</code>.</p>"},{"location":"monte-carlo.html#parameter-elasticities","title":"Parameter elasticities\u00b6","text":"+ ="},{"location":"monte-carlo.html#response-coefficients","title":"Response coefficients\u00b6","text":"+ ="},{"location":"monte-carlo.html#advanced-topics","title":"Advanced topics\u00b6","text":""},{"location":"monte-carlo.html#parameter-scans","title":"Parameter scans\u00b6","text":"<p>Vary both monte carlo parameters as well as systematically scan for other parameters</p>"},{"location":"monte-carlo.html#custom-distributions","title":"Custom distributions\u00b6","text":"<p>If you want to create custom distributions, all you need to do is to create a class that follows the <code>Distribution</code> protocol, e.g. implements a sample function.</p> <p>For API consistency, the <code>sample</code> method has to take <code>rng</code> argument, which can be ignored if not applicable.</p>"},{"location":"mxl.html","title":"Mechanistic learning","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nfrom functools import partial\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nfrom numpy.polynomial.polynomial import Polynomial\n\nfrom example_models.linear_chain import get_linear_chain_2v\nfrom mxlpy import Model, Simulator, fns, npe, plot, scan, surrogates\nfrom mxlpy.distributions import LogNormal, Normal, sample\nfrom mxlpy.types import AbstractSurrogate, unwrap\n</pre> from __future__ import annotations  from functools import partial  import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns import torch from numpy.polynomial.polynomial import Polynomial  from example_models.linear_chain import get_linear_chain_2v from mxlpy import Model, Simulator, fns, npe, plot, scan, surrogates from mxlpy.distributions import LogNormal, Normal, sample from mxlpy.types import AbstractSurrogate, unwrap In\u00a0[2]: Copied! <pre>m = Model()\nm.add_variable(\"x\", 1.0)\nm.add_surrogate(\n    \"surrogate\",\n    surrogates.Polynomial(\n        model=Polynomial(coef=[2]),\n        args=[\"x\"],\n        outputs=[\"y\"],\n    ),\n)\nm.add_derived(\"z\", fns.add, args=[\"x\", \"y\"])\n\n# Check output\nm.get_dependent()\n</pre> m = Model() m.add_variable(\"x\", 1.0) m.add_surrogate(     \"surrogate\",     surrogates.Polynomial(         model=Polynomial(coef=[2]),         args=[\"x\"],         outputs=[\"y\"],     ), ) m.add_derived(\"z\", fns.add, args=[\"x\", \"y\"])  # Check output m.get_dependent() Out[2]: <pre>x       1.0\ntime    0.0\ny       2.0\nz       3.0\ndtype: float64</pre> <p>Next we extend that idea to create a reaction. The only thing we need to change here is to also add the <code>stoichiometries</code> of the respective output variable.</p> <p>I've renamed the output to <code>v1</code> here to fit convention, but that is not technically necessary. <code>mxlpy</code> will always infer structurally into what kind of value your surrogate will be translated.</p> In\u00a0[3]: Copied! <pre>m = Model()\nm.add_variable(\"x\", 1.0)\nm.add_surrogate(\n    \"surrogate\",\n    surrogates.Polynomial(\n        model=Polynomial(coef=[2]),\n        args=[\"x\"],\n        outputs=[\"v1\"],\n        stoichiometries={\"v1\": {\"x\": -1}},\n    ),\n)\nm.add_derived(\"z\", fns.add, args=[\"x\", \"v1\"])\n\n# Check output\nm.get_right_hand_side()\n</pre> m = Model() m.add_variable(\"x\", 1.0) m.add_surrogate(     \"surrogate\",     surrogates.Polynomial(         model=Polynomial(coef=[2]),         args=[\"x\"],         outputs=[\"v1\"],         stoichiometries={\"v1\": {\"x\": -1}},     ), ) m.add_derived(\"z\", fns.add, args=[\"x\", \"v1\"])  # Check output m.get_right_hand_side() Out[3]: <pre>x   -2.0\ndtype: float64</pre> <p>Note that if you have multiple outputs, it is perfectly fine for them to mix between derived values and reactions.</p> <pre>Surrogate(\n    model=...,\n    args=[\"x\", \"y\"],\n    outputs=[\"d1\", \"v1\"],               # outputs derived value d1 and rate v1\n    stoichiometries={\"v1\": {\"x\": -1}},  # only rate v1 is given stoichiometries\n)\n</pre> <p>We will start with a simple linear chain model</p> <p>$$ \\Large \\varnothing \\xrightarrow{v_1} x \\xrightarrow{v_2} y \\xrightarrow{v_3} \\varnothing $$</p> <p>where we want to read out the steady-state rate of $v_3$ dependent on the fixed concentration of $x$, while ignoring the inner state of the model.</p> <p>$$ \\Large  x \\xrightarrow{} ... \\xrightarrow{v_3}$$</p> <p>Since we need to fix a <code>variable</code> as an <code>parameter</code>, we can use the <code>make_variable_static</code> method to do that.</p> In\u00a0[4]: Copied! <pre># Now \"x\" is a parameter\nget_linear_chain_2v().make_variable_static(\"x\").parameters\n</pre> # Now \"x\" is a parameter get_linear_chain_2v().make_variable_static(\"x\").parameters Out[4]: <pre>{'k1': 1.0, 'k2': 2.0, 'k3': 1.0, 'x': 1.0}</pre> <p>And we can already create a function to create a model, which will take our surrogate as an input.</p> In\u00a0[5]: Copied! <pre>def get_model_with_surrogate(surrogate: AbstractSurrogate) -&gt; Model:\n    model = Model()\n    model.add_variables({\"x\": 1.0, \"z\": 0.0})\n\n    # Adding the surrogate\n    model.add_surrogate(\n        \"surrogate\",\n        surrogate,\n        args=[\"x\"],\n        outputs=[\"v2\"],\n        stoichiometries={\n            \"v2\": {\"x\": -1, \"z\": 1},\n        },\n    )\n\n    # Note that besides the surrogate we haven't defined any other reaction!\n    # We could have though\n    return model\n</pre> def get_model_with_surrogate(surrogate: AbstractSurrogate) -&gt; Model:     model = Model()     model.add_variables({\"x\": 1.0, \"z\": 0.0})      # Adding the surrogate     model.add_surrogate(         \"surrogate\",         surrogate,         args=[\"x\"],         outputs=[\"v2\"],         stoichiometries={             \"v2\": {\"x\": -1, \"z\": 1},         },     )      # Note that besides the surrogate we haven't defined any other reaction!     # We could have though     return model In\u00a0[6]: Copied! <pre>surrogate_features = pd.DataFrame({\"x\": np.geomspace(1e-12, 2.0, 21)})\n\nsurrogate_targets = scan.steady_state(\n    get_linear_chain_2v().make_variable_static(\"x\"),\n    to_scan=surrogate_features,\n).fluxes.loc[:, [\"v3\"]]\n\n# It's always a good idea to check the inputs and outputs\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False)\n_ = plot.violins(surrogate_features, ax=ax1)[1].set(\n    title=\"Features\", ylabel=\"Flux / a.u.\"\n)\n_ = plot.violins(surrogate_targets, ax=ax2)[1].set(\n    title=\"Targets\", ylabel=\"Flux / a.u.\"\n)\nplt.show()\n</pre> surrogate_features = pd.DataFrame({\"x\": np.geomspace(1e-12, 2.0, 21)})  surrogate_targets = scan.steady_state(     get_linear_chain_2v().make_variable_static(\"x\"),     to_scan=surrogate_features, ).fluxes.loc[:, [\"v3\"]]  # It's always a good idea to check the inputs and outputs fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False) _ = plot.violins(surrogate_features, ax=ax1)[1].set(     title=\"Features\", ylabel=\"Flux / a.u.\" ) _ = plot.violins(surrogate_targets, ax=ax2)[1].set(     title=\"Targets\", ylabel=\"Flux / a.u.\" ) plt.show() <pre>\r  0%|          | 0/21 [00:00&lt;?, ?it/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 5/21 [00:00&lt;00:00, 44.88it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:00&lt;00:00, 76.35it/s]</pre> <pre>\n</pre> In\u00a0[7]: Copied! <pre>surrogate, info = surrogates.train_polynomial(\n    surrogate_features[\"x\"],\n    surrogate_targets[\"v3\"],\n)\n\nprint(\"Model\", surrogate.model, end=\"\\n\\n\")\nprint(info[\"score\"])\n</pre> surrogate, info = surrogates.train_polynomial(     surrogate_features[\"x\"],     surrogate_targets[\"v3\"], )  print(\"Model\", surrogate.model, end=\"\\n\\n\") print(info[\"score\"]) <pre>Model 2.0 + 2.0\u00b7(-1.0 + 1.0x)\n\ndegree\n1     2.0\n2     4.0\n3     6.0\n4     8.0\n5    10.0\n6    12.0\n7    14.0\nName: score, dtype: float64\n</pre> <p>You can then insert the surrogate into the model using the function we defined earlier</p> In\u00a0[8]: Copied! <pre>concs, fluxes = unwrap(\n    Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(8, 3))\nplot.lines(concs, ax=ax1)\nplot.lines(fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> concs, fluxes = unwrap(     Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(8, 3)) plot.lines(concs, ax=ax1) plot.lines(fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() <p>While polynomial regression can model nonlinear relationships between variables, it often struggles when the underlying relationship is more complex than a polynomial function. You will learn about using neural networks in the next section.</p> In\u00a0[9]: Copied! <pre>surrogate, loss = surrogates.train_torch(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    epochs=250,\n)\n\nax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1])\nax.set_ylim(0, None)\nplt.show()\n</pre> surrogate, loss = surrogates.train_torch(     features=surrogate_features,     targets=surrogate_targets,     epochs=250, )  ax = loss.plot(ax=plt.subplots(figsize=(4, 2.5))[1]) ax.set_ylim(0, None) plt.show() <pre>\r  0%|          | 0/250 [00:00&lt;?, ?it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 150/250 [00:00&lt;00:00, 1493.20it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [00:00&lt;00:00, 1515.31it/s]</pre> <pre>\n</pre> <p>As before, you can then insert the surrogate into the model using the function we defined earlier</p> In\u00a0[10]: Copied! <pre>concs, fluxes = unwrap(\n    Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result()\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(8, 3))\nplot.lines(concs, ax=ax1)\nplot.lines(fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\")\nplt.show()\n</pre> concs, fluxes = unwrap(     Simulator(get_model_with_surrogate(surrogate)).simulate(10).get_result() )  fig, (ax1, ax2) = plot.two_axes(figsize=(8, 3)) plot.lines(concs, ax=ax1) plot.lines(fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"flux / a.u.\") plt.show() In\u00a0[11]: Copied! <pre>trainer = surrogates.TorchTrainer(\n    features=surrogate_features,\n    targets=surrogate_targets,\n)\n\n# First training epochs\ntrainer.train(epochs=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Decide to continue training\ntrainer.train(epochs=150)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\nsurrogate = trainer.get_surrogate(surrogate_outputs=[\"x\"])\n</pre> trainer = surrogates.TorchTrainer(     features=surrogate_features,     targets=surrogate_targets, )  # First training epochs trainer.train(epochs=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Decide to continue training trainer.train(epochs=150) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  surrogate = trainer.get_surrogate(surrogate_outputs=[\"x\"]) <pre>\r  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1498.17it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/150 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 150/150 [00:00&lt;00:00, 1562.54it/s]</pre> <pre>\n</pre> In\u00a0[12]: Copied! <pre>print(surrogate.predict(np.array([-0.1])))\nprint(surrogate.predict(np.array([0.0])))\nprint(surrogate.predict(np.array([0.1])))\n</pre> print(surrogate.predict(np.array([-0.1]))) print(surrogate.predict(np.array([0.0]))) print(surrogate.predict(np.array([0.1]))) <pre>{'x': np.float32(-0.020074744)}\n{'x': np.float32(-1.4226651e-05)}\n{'x': np.float32(0.20353743)}\n</pre> In\u00a0[13]: Copied! <pre># Note that now the parameters are the targets\nnpe_targets = sample(\n    {\n        \"k1\": LogNormal(mean=1.0, sigma=0.3),\n    },\n    n=1_000,\n)\n\n# And the generated data are the features\nnpe_features = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=npe_targets,\n).results.loc[:, [\"y\", \"v2\", \"v3\"]]\n\n# It's always a good idea to check the inputs and outputs\nfig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False)\n_ = plot.violins(npe_features, ax=ax1)[1].set(title=\"Features\", ylabel=\"Flux / a.u.\")\n_ = plot.violins(npe_targets, ax=ax2)[1].set(title=\"Targets\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> # Note that now the parameters are the targets npe_targets = sample(     {         \"k1\": LogNormal(mean=1.0, sigma=0.3),     },     n=1_000, )  # And the generated data are the features npe_features = scan.steady_state(     get_linear_chain_2v(),     to_scan=npe_targets, ).results.loc[:, [\"y\", \"v2\", \"v3\"]]  # It's always a good idea to check the inputs and outputs fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3), sharex=False) _ = plot.violins(npe_features, ax=ax1)[1].set(title=\"Features\", ylabel=\"Flux / a.u.\") _ = plot.violins(npe_targets, ax=ax2)[1].set(title=\"Targets\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  1%|          | 6/1000 [00:00&lt;00:16, 59.79it/s]</pre> <pre>\r  2%|\u258f         | 22/1000 [00:00&lt;00:08, 113.92it/s]</pre> <pre>\r  4%|\u258d         | 38/1000 [00:00&lt;00:07, 129.46it/s]</pre> <pre>\r  5%|\u258c         | 54/1000 [00:00&lt;00:06, 139.94it/s]</pre> <pre>\r  7%|\u258b         | 70/1000 [00:00&lt;00:06, 144.33it/s]</pre> <pre>\r  9%|\u258a         | 86/1000 [00:00&lt;00:06, 146.78it/s]</pre> <pre>\r 10%|\u2588         | 102/1000 [00:00&lt;00:05, 150.46it/s]</pre> <pre>\r 12%|\u2588\u258f        | 120/1000 [00:00&lt;00:05, 158.54it/s]</pre> <pre>\r 14%|\u2588\u258e        | 137/1000 [00:00&lt;00:05, 160.40it/s]</pre> <pre>\r 15%|\u2588\u258c        | 154/1000 [00:01&lt;00:05, 157.70it/s]</pre> <pre>\r 17%|\u2588\u258b        | 171/1000 [00:01&lt;00:05, 160.01it/s]</pre> <pre>\r 19%|\u2588\u2589        | 188/1000 [00:01&lt;00:05, 159.11it/s]</pre> <pre>\r 20%|\u2588\u2588        | 204/1000 [00:01&lt;00:05, 158.68it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 220/1000 [00:01&lt;00:04, 156.37it/s]</pre> <pre>\r 24%|\u2588\u2588\u258e       | 236/1000 [00:01&lt;00:05, 131.88it/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 257/1000 [00:01&lt;00:04, 150.10it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 273/1000 [00:01&lt;00:04, 152.16it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 290/1000 [00:01&lt;00:04, 156.39it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 307/1000 [00:02&lt;00:04, 156.07it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 323/1000 [00:02&lt;00:04, 154.59it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 339/1000 [00:02&lt;00:04, 153.49it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 355/1000 [00:02&lt;00:04, 154.49it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 371/1000 [00:02&lt;00:04, 155.64it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u258a      | 387/1000 [00:02&lt;00:03, 155.69it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 403/1000 [00:02&lt;00:03, 155.33it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 420/1000 [00:02&lt;00:03, 156.99it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 436/1000 [00:02&lt;00:03, 157.56it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 452/1000 [00:02&lt;00:03, 156.09it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 468/1000 [00:03&lt;00:03, 156.79it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 484/1000 [00:03&lt;00:03, 156.82it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 501/1000 [00:03&lt;00:03, 157.51it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 517/1000 [00:03&lt;00:03, 156.61it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 534/1000 [00:03&lt;00:02, 157.83it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 551/1000 [00:03&lt;00:02, 158.78it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 568/1000 [00:03&lt;00:02, 161.67it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 585/1000 [00:03&lt;00:02, 158.28it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 601/1000 [00:03&lt;00:02, 157.25it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 618/1000 [00:04&lt;00:02, 158.59it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 634/1000 [00:04&lt;00:02, 158.92it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 651/1000 [00:04&lt;00:02, 157.33it/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 668/1000 [00:04&lt;00:02, 155.94it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 684/1000 [00:04&lt;00:02, 156.48it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 701/1000 [00:04&lt;00:01, 154.21it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 719/1000 [00:04&lt;00:01, 161.49it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 736/1000 [00:04&lt;00:01, 158.37it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 753/1000 [00:04&lt;00:01, 161.35it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 770/1000 [00:04&lt;00:01, 156.27it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 786/1000 [00:05&lt;00:01, 155.07it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 803/1000 [00:05&lt;00:01, 158.90it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 820/1000 [00:05&lt;00:01, 160.41it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 837/1000 [00:05&lt;00:01, 156.92it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 853/1000 [00:05&lt;00:00, 156.24it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 870/1000 [00:05&lt;00:00, 156.12it/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 886/1000 [00:05&lt;00:00, 157.10it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 903/1000 [00:05&lt;00:00, 158.93it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 919/1000 [00:05&lt;00:00, 157.11it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 935/1000 [00:06&lt;00:00, 157.94it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 951/1000 [00:06&lt;00:00, 157.30it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 968/1000 [00:06&lt;00:00, 156.00it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 984/1000 [00:06&lt;00:00, 155.50it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:06&lt;00:00, 154.33it/s]</pre> <pre>\n</pre> In\u00a0[14]: Copied! <pre>estimator, losses = npe.train_torch_steady_state(\n    features=npe_features,\n    targets=npe_targets,\n    epochs=1000,\n)\n\nax = losses.plot(figsize=(4, 2.5))\nax.set(xlabel=\"epoch\", ylabel=\"loss\")\nax.set_ylim(0, None)\nplt.show()\n</pre> estimator, losses = npe.train_torch_steady_state(     features=npe_features,     targets=npe_targets,     epochs=1000, )  ax = losses.plot(figsize=(4, 2.5)) ax.set(xlabel=\"epoch\", ylabel=\"loss\") ax.set_ylim(0, None) plt.show() <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r 14%|\u2588\u258e        | 137/1000 [00:00&lt;00:00, 1361.11it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 275/1000 [00:00&lt;00:00, 1366.41it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588\u258f     | 413/1000 [00:00&lt;00:00, 1370.25it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 551/1000 [00:00&lt;00:00, 1357.17it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 688/1000 [00:00&lt;00:00, 1361.48it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 825/1000 [00:00&lt;00:00, 1340.21it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 962/1000 [00:00&lt;00:00, 1349.36it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00&lt;00:00, 1352.79it/s]</pre> <pre>\n</pre> In\u00a0[15]: Copied! <pre>fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2))\n\nax = sns.kdeplot(npe_targets, fill=True, ax=ax1)\nax.set_title(\"Prior\")\n\nposterior = estimator.predict(npe_features)\nax = sns.kdeplot(posterior, fill=True, ax=ax2)\nax.set_title(\"Posterior\")\nplt.show()\n</pre> fig, (ax1, ax2) = plot.two_axes(figsize=(6, 2))  ax = sns.kdeplot(npe_targets, fill=True, ax=ax1) ax.set_title(\"Prior\")  posterior = estimator.predict(npe_features) ax = sns.kdeplot(posterior, fill=True, ax=ax2) ax.set_title(\"Posterior\") plt.show() In\u00a0[16]: Copied! <pre>trainer = npe.TorchSteadyStateTrainer(\n    features=npe_features,\n    targets=npe_targets,\n)\n\n# Initial training\ntrainer.train(epochs=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Continue training\ntrainer.train(epochs=100)\ntrainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None)\nplt.show()\n\n# Get trainer if loss is deemed suitable\nestimator = trainer.get_estimator()\n</pre> trainer = npe.TorchSteadyStateTrainer(     features=npe_features,     targets=npe_targets, )  # Initial training trainer.train(epochs=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Continue training trainer.train(epochs=100) trainer.get_loss().plot(figsize=(4, 2.5)).set_ylim(0, None) plt.show()  # Get trainer if loss is deemed suitable estimator = trainer.get_estimator() <pre>\r  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1287.62it/s]</pre> <pre>\n</pre> <pre>\r  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1372.28it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about labelled models in mxlpy.           Congratulations!  In\u00a0[17]: Copied! <pre>def mean_abs(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n    return torch.mean(torch.abs(x - y))\n\n\ntrainer = surrogates.TorchTrainer(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    loss_fn=mean_abs,\n)\n\ntrainer = npe.TorchSteadyStateTrainer(\n    features=npe_features,\n    targets=npe_targets,\n    loss_fn=mean_abs,\n)\n\ntrainer = npe.TorchTimeCourseTrainer(\n    features=npe_features,\n    targets=npe_targets,\n    loss_fn=mean_abs,\n)\n</pre> def mean_abs(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:     return torch.mean(torch.abs(x - y))   trainer = surrogates.TorchTrainer(     features=surrogate_features,     targets=surrogate_targets,     loss_fn=mean_abs, )  trainer = npe.TorchSteadyStateTrainer(     features=npe_features,     targets=npe_targets,     loss_fn=mean_abs, )  trainer = npe.TorchTimeCourseTrainer(     features=npe_features,     targets=npe_targets,     loss_fn=mean_abs, ) In\u00a0[18]: Copied! <pre>from typing import TYPE_CHECKING\n\nfrom mxlpy import LinearLabelMapper, Simulator\nfrom mxlpy.distributions import sample\nfrom mxlpy.fns import michaelis_menten_1s\nfrom mxlpy.parallel import parallelise\n\nif TYPE_CHECKING:\n    from mxlpy.types import AbstractEstimator\n\n# FIXME: todo\n# Show how to change Adam settings or user other optimizers\n# Show how to change the surrogate network\n</pre> from typing import TYPE_CHECKING  from mxlpy import LinearLabelMapper, Simulator from mxlpy.distributions import sample from mxlpy.fns import michaelis_menten_1s from mxlpy.parallel import parallelise  if TYPE_CHECKING:     from mxlpy.types import AbstractEstimator  # FIXME: todo # Show how to change Adam settings or user other optimizers # Show how to change the surrogate network In\u00a0[19]: Copied! <pre>def get_closed_cycle() -&gt; tuple[Model, dict[str, int], dict[str, list[int]]]:\n    \"\"\"\n\n    | Reaction       | Labelmap |\n    | -------------- | -------- |\n    | x1 -&gt;[v1] x2   | [0, 1]   |\n    | x2 -&gt;[v2a] x3  | [0, 1]   |\n    | x2 -&gt;[v2b] x3  | [1, 0]   |\n    | x3 -&gt;[v3] x1   | [0, 1]   |\n\n    \"\"\"\n    model = (\n        Model()\n        .add_parameters(\n            {\n                \"vmax_1\": 1.0,\n                \"km_1\": 0.5,\n                \"vmax_2a\": 1.0,\n                \"vmax_2b\": 1.0,\n                \"km_2\": 0.5,\n                \"vmax_3\": 1.0,\n                \"km_3\": 0.5,\n            }\n        )\n        .add_variables({\"x1\": 1.0, \"x2\": 0.0, \"x3\": 0.0})\n        .add_reaction(\n            \"v1\",\n            michaelis_menten_1s,\n            stoichiometry={\"x1\": -1, \"x2\": 1},\n            args=[\"x1\", \"vmax_1\", \"km_1\"],\n        )\n        .add_reaction(\n            \"v2a\",\n            michaelis_menten_1s,\n            stoichiometry={\"x2\": -1, \"x3\": 1},\n            args=[\"x2\", \"vmax_2a\", \"km_2\"],\n        )\n        .add_reaction(\n            \"v2b\",\n            michaelis_menten_1s,\n            stoichiometry={\"x2\": -1, \"x3\": 1},\n            args=[\"x2\", \"vmax_2b\", \"km_2\"],\n        )\n        .add_reaction(\n            \"v3\",\n            michaelis_menten_1s,\n            stoichiometry={\"x3\": -1, \"x1\": 1},\n            args=[\"x3\", \"vmax_3\", \"km_3\"],\n        )\n    )\n    label_variables: dict[str, int] = {\"x1\": 2, \"x2\": 2, \"x3\": 2}\n    label_maps: dict[str, list[int]] = {\n        \"v1\": [0, 1],\n        \"v2a\": [0, 1],\n        \"v2b\": [1, 0],\n        \"v3\": [0, 1],\n    }\n    return model, label_variables, label_maps\n</pre> def get_closed_cycle() -&gt; tuple[Model, dict[str, int], dict[str, list[int]]]:     \"\"\"      | Reaction       | Labelmap |     | -------------- | -------- |     | x1 -&gt;[v1] x2   | [0, 1]   |     | x2 -&gt;[v2a] x3  | [0, 1]   |     | x2 -&gt;[v2b] x3  | [1, 0]   |     | x3 -&gt;[v3] x1   | [0, 1]   |      \"\"\"     model = (         Model()         .add_parameters(             {                 \"vmax_1\": 1.0,                 \"km_1\": 0.5,                 \"vmax_2a\": 1.0,                 \"vmax_2b\": 1.0,                 \"km_2\": 0.5,                 \"vmax_3\": 1.0,                 \"km_3\": 0.5,             }         )         .add_variables({\"x1\": 1.0, \"x2\": 0.0, \"x3\": 0.0})         .add_reaction(             \"v1\",             michaelis_menten_1s,             stoichiometry={\"x1\": -1, \"x2\": 1},             args=[\"x1\", \"vmax_1\", \"km_1\"],         )         .add_reaction(             \"v2a\",             michaelis_menten_1s,             stoichiometry={\"x2\": -1, \"x3\": 1},             args=[\"x2\", \"vmax_2a\", \"km_2\"],         )         .add_reaction(             \"v2b\",             michaelis_menten_1s,             stoichiometry={\"x2\": -1, \"x3\": 1},             args=[\"x2\", \"vmax_2b\", \"km_2\"],         )         .add_reaction(             \"v3\",             michaelis_menten_1s,             stoichiometry={\"x3\": -1, \"x1\": 1},             args=[\"x3\", \"vmax_3\", \"km_3\"],         )     )     label_variables: dict[str, int] = {\"x1\": 2, \"x2\": 2, \"x3\": 2}     label_maps: dict[str, list[int]] = {         \"v1\": [0, 1],         \"v2a\": [0, 1],         \"v2b\": [1, 0],         \"v3\": [0, 1],     }     return model, label_variables, label_maps In\u00a0[20]: Copied! <pre>def _worker(\n    x: tuple[tuple[int, pd.Series], tuple[int, pd.Series]],\n    mapper: LinearLabelMapper,\n    time: float,\n    initial_labels: dict[str, int | list[int]],\n) -&gt; pd.Series:\n    (_, y_ss), (_, v_ss) = x\n    return unwrap(\n        Simulator(mapper.build_model(y_ss, v_ss, initial_labels=initial_labels))\n        .simulate(time)\n        .get_result()\n    ).variables.iloc[-1]\n\n\ndef get_label_distribution_at_time(\n    model: Model,\n    label_variables: dict[str, int],\n    label_maps: dict[str, list[int]],\n    time: float,\n    initial_labels: dict[str, int | list[int]],\n    ss_concs: pd.DataFrame,\n    ss_fluxes: pd.DataFrame,\n) -&gt; pd.DataFrame:\n    mapper = LinearLabelMapper(\n        model,\n        label_variables=label_variables,\n        label_maps=label_maps,\n    )\n\n    return pd.DataFrame(\n        parallelise(\n            partial(_worker, mapper=mapper, time=time, initial_labels=initial_labels),\n            inputs=list(\n                enumerate(zip(ss_concs.iterrows(), ss_fluxes.iterrows(), strict=True))\n            ),\n            cache=None,\n        )\n    ).T\n\n\ndef inverse_parameter_elasticity(\n    estimator: AbstractEstimator,\n    datum: pd.Series,\n    *,\n    normalized: bool = True,\n    displacement: float = 1e-4,\n) -&gt; pd.DataFrame:\n    ref = estimator.predict(datum).iloc[0, :]\n\n    coefs = {}\n    for name, value in datum.items():\n        up = coefs[name] = estimator.predict(\n            pd.Series(datum.to_dict() | {name: value * 1 + displacement})\n        ).iloc[0, :]\n        down = coefs[name] = estimator.predict(\n            pd.Series(datum.to_dict() | {name: value * 1 - displacement})\n        ).iloc[0, :]\n        coefs[name] = (up - down) / (2 * displacement * value)\n\n    coefs = pd.DataFrame(coefs)\n    if normalized:\n        coefs *= datum / ref.to_numpy()\n\n    return coefs\n</pre> def _worker(     x: tuple[tuple[int, pd.Series], tuple[int, pd.Series]],     mapper: LinearLabelMapper,     time: float,     initial_labels: dict[str, int | list[int]], ) -&gt; pd.Series:     (_, y_ss), (_, v_ss) = x     return unwrap(         Simulator(mapper.build_model(y_ss, v_ss, initial_labels=initial_labels))         .simulate(time)         .get_result()     ).variables.iloc[-1]   def get_label_distribution_at_time(     model: Model,     label_variables: dict[str, int],     label_maps: dict[str, list[int]],     time: float,     initial_labels: dict[str, int | list[int]],     ss_concs: pd.DataFrame,     ss_fluxes: pd.DataFrame, ) -&gt; pd.DataFrame:     mapper = LinearLabelMapper(         model,         label_variables=label_variables,         label_maps=label_maps,     )      return pd.DataFrame(         parallelise(             partial(_worker, mapper=mapper, time=time, initial_labels=initial_labels),             inputs=list(                 enumerate(zip(ss_concs.iterrows(), ss_fluxes.iterrows(), strict=True))             ),             cache=None,         )     ).T   def inverse_parameter_elasticity(     estimator: AbstractEstimator,     datum: pd.Series,     *,     normalized: bool = True,     displacement: float = 1e-4, ) -&gt; pd.DataFrame:     ref = estimator.predict(datum).iloc[0, :]      coefs = {}     for name, value in datum.items():         up = coefs[name] = estimator.predict(             pd.Series(datum.to_dict() | {name: value * 1 + displacement})         ).iloc[0, :]         down = coefs[name] = estimator.predict(             pd.Series(datum.to_dict() | {name: value * 1 - displacement})         ).iloc[0, :]         coefs[name] = (up - down) / (2 * displacement * value)      coefs = pd.DataFrame(coefs)     if normalized:         coefs *= datum / ref.to_numpy()      return coefs In\u00a0[21]: Copied! <pre>model, label_variables, label_maps = get_closed_cycle()\n\nss_concs, ss_fluxes = unwrap(\n    Simulator(model)\n    .update_parameters({\"vmax_2a\": 1.0, \"vmax_2b\": 0.5})\n    .simulate_to_steady_state()\n    .get_result()\n)\nmapper = LinearLabelMapper(\n    model,\n    label_variables=label_variables,\n    label_maps=label_maps,\n)\n\n_, axs = plot.relative_label_distribution(\n    mapper,\n    unwrap(\n        Simulator(\n            mapper.build_model(\n                ss_concs.iloc[-1], ss_fluxes.iloc[-1], initial_labels={\"x1\": 0}\n            )\n        )\n        .simulate(5)\n        .get_result()\n    ).variables,\n    sharey=True,\n    n_cols=3,\n)\n\naxs[0].set_ylabel(\"Relative label distribution\")\naxs[1].set_xlabel(\"Time / s\")\nplt.show()\n</pre> model, label_variables, label_maps = get_closed_cycle()  ss_concs, ss_fluxes = unwrap(     Simulator(model)     .update_parameters({\"vmax_2a\": 1.0, \"vmax_2b\": 0.5})     .simulate_to_steady_state()     .get_result() ) mapper = LinearLabelMapper(     model,     label_variables=label_variables,     label_maps=label_maps, )  _, axs = plot.relative_label_distribution(     mapper,     unwrap(         Simulator(             mapper.build_model(                 ss_concs.iloc[-1], ss_fluxes.iloc[-1], initial_labels={\"x1\": 0}             )         )         .simulate(5)         .get_result()     ).variables,     sharey=True,     n_cols=3, )  axs[0].set_ylabel(\"Relative label distribution\") axs[1].set_xlabel(\"Time / s\") plt.show() In\u00a0[22]: Copied! <pre>surrogate_targets = sample(\n    {\n        \"vmax_2b\": Normal(0.5, 0.1),\n    },\n    n=1000,\n).clip(lower=0)\n\nax = sns.kdeplot(surrogate_targets, fill=True)\nax.set_title(\"Prior\")\n</pre> surrogate_targets = sample(     {         \"vmax_2b\": Normal(0.5, 0.1),     },     n=1000, ).clip(lower=0)  ax = sns.kdeplot(surrogate_targets, fill=True) ax.set_title(\"Prior\") Out[22]: <pre>Text(0.5, 1.0, 'Prior')</pre> In\u00a0[23]: Copied! <pre>ss_concs, ss_fluxes = scan.steady_state(\n    model,\n    to_scan=surrogate_targets,\n)\n</pre> ss_concs, ss_fluxes = scan.steady_state(     model,     to_scan=surrogate_targets, ) <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 5/1000 [00:00&lt;00:27, 35.56it/s]</pre> <pre>\r  2%|\u258f         | 15/1000 [00:00&lt;00:14, 67.96it/s]</pre> <pre>\r  2%|\u258e         | 25/1000 [00:00&lt;00:13, 70.76it/s]</pre> <pre>\r  4%|\u258e         | 36/1000 [00:00&lt;00:11, 82.96it/s]</pre> <pre>\r  4%|\u258d         | 45/1000 [00:00&lt;00:12, 78.51it/s]</pre> <pre>\r  6%|\u258c         | 55/1000 [00:00&lt;00:11, 83.78it/s]</pre> <pre>\r  6%|\u258b         | 64/1000 [00:00&lt;00:11, 79.77it/s]</pre> <pre>\r  8%|\u258a         | 75/1000 [00:00&lt;00:10, 86.27it/s]</pre> <pre>\r  8%|\u258a         | 84/1000 [00:01&lt;00:11, 81.31it/s]</pre> <pre>\r  9%|\u2589         | 94/1000 [00:01&lt;00:10, 85.56it/s]</pre> <pre>\r 10%|\u2588         | 104/1000 [00:01&lt;00:10, 83.00it/s]</pre> <pre>\r 11%|\u2588\u258f        | 114/1000 [00:01&lt;00:10, 85.55it/s]</pre> <pre>\r 12%|\u2588\u258f        | 124/1000 [00:01&lt;00:10, 83.97it/s]</pre> <pre>\r 13%|\u2588\u258e        | 134/1000 [00:01&lt;00:10, 85.99it/s]</pre> <pre>\r 14%|\u2588\u258d        | 143/1000 [00:01&lt;00:09, 86.30it/s]</pre> <pre>\r 15%|\u2588\u258c        | 152/1000 [00:01&lt;00:10, 81.08it/s]</pre> <pre>\r 16%|\u2588\u258c        | 161/1000 [00:01&lt;00:10, 82.28it/s]</pre> <pre>\r 17%|\u2588\u258b        | 170/1000 [00:02&lt;00:09, 84.22it/s]</pre> <pre>\r 18%|\u2588\u258a        | 179/1000 [00:02&lt;00:10, 80.53it/s]</pre> <pre>\r 19%|\u2588\u2589        | 188/1000 [00:02&lt;00:09, 82.88it/s]</pre> <pre>\r 20%|\u2588\u2589        | 197/1000 [00:02&lt;00:09, 84.15it/s]</pre> <pre>\r 21%|\u2588\u2588        | 207/1000 [00:02&lt;00:09, 82.22it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 216/1000 [00:02&lt;00:09, 83.91it/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 226/1000 [00:02&lt;00:08, 86.45it/s]</pre> <pre>\r 24%|\u2588\u2588\u258e       | 235/1000 [00:02&lt;00:09, 82.64it/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 244/1000 [00:02&lt;00:09, 80.34it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 254/1000 [00:03&lt;00:08, 83.55it/s]</pre> <pre>\r 26%|\u2588\u2588\u258b       | 263/1000 [00:03&lt;00:08, 83.50it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 272/1000 [00:03&lt;00:08, 82.92it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 282/1000 [00:03&lt;00:08, 84.95it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 291/1000 [00:03&lt;00:08, 84.22it/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 300/1000 [00:03&lt;00:08, 84.05it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 309/1000 [00:03&lt;00:08, 84.11it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 318/1000 [00:03&lt;00:07, 85.49it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 327/1000 [00:03&lt;00:07, 84.86it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 336/1000 [00:04&lt;00:08, 80.04it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 345/1000 [00:04&lt;00:08, 80.07it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 355/1000 [00:04&lt;00:07, 84.32it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258b      | 364/1000 [00:04&lt;00:07, 82.85it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 373/1000 [00:04&lt;00:07, 81.25it/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 382/1000 [00:04&lt;00:07, 83.32it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 392/1000 [00:04&lt;00:07, 84.75it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 401/1000 [00:04&lt;00:07, 83.33it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 410/1000 [00:04&lt;00:06, 84.66it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 419/1000 [00:05&lt;00:07, 77.42it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 430/1000 [00:05&lt;00:06, 82.44it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 439/1000 [00:05&lt;00:06, 84.31it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258d     | 448/1000 [00:05&lt;00:06, 82.61it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 457/1000 [00:05&lt;00:06, 82.72it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 466/1000 [00:05&lt;00:06, 83.91it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 475/1000 [00:05&lt;00:06, 85.09it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 484/1000 [00:05&lt;00:06, 83.80it/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 493/1000 [00:05&lt;00:06, 81.29it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 503/1000 [00:06&lt;00:05, 85.82it/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 512/1000 [00:06&lt;00:05, 84.06it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 521/1000 [00:06&lt;00:06, 79.81it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 530/1000 [00:06&lt;00:05, 80.44it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 540/1000 [00:06&lt;00:05, 85.71it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 549/1000 [00:06&lt;00:05, 81.40it/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 558/1000 [00:06&lt;00:05, 82.47it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 567/1000 [00:06&lt;00:05, 84.17it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 576/1000 [00:06&lt;00:05, 84.29it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 585/1000 [00:07&lt;00:05, 82.13it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 595/1000 [00:07&lt;00:04, 85.63it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 604/1000 [00:07&lt;00:05, 75.25it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 615/1000 [00:07&lt;00:04, 82.95it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 624/1000 [00:07&lt;00:04, 83.86it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 634/1000 [00:07&lt;00:04, 82.19it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 643/1000 [00:07&lt;00:04, 82.89it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 654/1000 [00:07&lt;00:04, 83.56it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 663/1000 [00:08&lt;00:04, 84.21it/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 672/1000 [00:08&lt;00:03, 84.71it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 681/1000 [00:08&lt;00:03, 85.92it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 690/1000 [00:08&lt;00:03, 83.32it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 699/1000 [00:08&lt;00:03, 80.26it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 708/1000 [00:08&lt;00:03, 81.81it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 717/1000 [00:08&lt;00:03, 78.36it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 726/1000 [00:08&lt;00:03, 79.22it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 734/1000 [00:08&lt;00:03, 78.97it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 744/1000 [00:09&lt;00:03, 83.30it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 753/1000 [00:09&lt;00:03, 81.30it/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 762/1000 [00:09&lt;00:02, 81.42it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 771/1000 [00:09&lt;00:02, 82.89it/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 780/1000 [00:09&lt;00:02, 84.88it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 789/1000 [00:09&lt;00:02, 77.71it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 799/1000 [00:09&lt;00:02, 80.07it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 808/1000 [00:09&lt;00:02, 79.93it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 818/1000 [00:09&lt;00:02, 85.36it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 827/1000 [00:10&lt;00:02, 78.37it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 838/1000 [00:10&lt;00:01, 85.12it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 847/1000 [00:10&lt;00:01, 80.84it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 856/1000 [00:10&lt;00:01, 82.46it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 865/1000 [00:10&lt;00:01, 83.48it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 874/1000 [00:10&lt;00:01, 84.85it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 883/1000 [00:10&lt;00:01, 80.16it/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 892/1000 [00:10&lt;00:01, 81.32it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 901/1000 [00:10&lt;00:01, 78.49it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 910/1000 [00:11&lt;00:01, 81.58it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 919/1000 [00:11&lt;00:00, 81.30it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 928/1000 [00:11&lt;00:00, 82.76it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 937/1000 [00:11&lt;00:00, 81.72it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 946/1000 [00:11&lt;00:00, 80.52it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 956/1000 [00:11&lt;00:00, 83.02it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 965/1000 [00:11&lt;00:00, 82.12it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 974/1000 [00:11&lt;00:00, 80.34it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 983/1000 [00:11&lt;00:00, 77.43it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 993/1000 [00:12&lt;00:00, 79.62it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:12&lt;00:00, 82.07it/s]</pre> <pre>\n</pre> In\u00a0[24]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n_, ax = plot.violins(ss_concs, ax=ax1)\nax.set_ylabel(\"Concentration / a.u.\")\n_, ax = plot.violins(ss_fluxes, ax=ax2)\nax.set_ylabel(\"Flux / a.u.\")\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4)) _, ax = plot.violins(ss_concs, ax=ax1) ax.set_ylabel(\"Concentration / a.u.\") _, ax = plot.violins(ss_fluxes, ax=ax2) ax.set_ylabel(\"Flux / a.u.\") Out[24]: <pre>Text(0, 0.5, 'Flux / a.u.')</pre> In\u00a0[25]: Copied! <pre>surrogate_features = get_label_distribution_at_time(\n    model=model,\n    label_variables=label_variables,\n    label_maps=label_maps,\n    time=5,\n    ss_concs=ss_concs,\n    ss_fluxes=ss_fluxes,\n    initial_labels={\"x1\": 0},\n)\n_, ax = plot.violins(surrogate_features)\nax.set_ylabel(\"Relative label distribution\")\n</pre> surrogate_features = get_label_distribution_at_time(     model=model,     label_variables=label_variables,     label_maps=label_maps,     time=5,     ss_concs=ss_concs,     ss_fluxes=ss_fluxes,     initial_labels={\"x1\": 0}, ) _, ax = plot.violins(surrogate_features) ax.set_ylabel(\"Relative label distribution\") <pre>\r  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> <pre>\r  0%|          | 1/1000 [00:00&lt;06:57,  2.40it/s]</pre> <pre>\r  1%|          | 6/1000 [00:00&lt;01:14, 13.41it/s]</pre> <pre>\r  1%|\u258f         | 14/1000 [00:00&lt;00:34, 28.19it/s]</pre> <pre>\r  2%|\u258f         | 22/1000 [00:00&lt;00:25, 38.33it/s]</pre> <pre>\r  3%|\u258e         | 30/1000 [00:00&lt;00:21, 45.22it/s]</pre> <pre>\r  4%|\u258d         | 38/1000 [00:01&lt;00:19, 50.01it/s]</pre> <pre>\r  5%|\u258d         | 46/1000 [00:01&lt;00:17, 53.40it/s]</pre> <pre>\r  5%|\u258c         | 54/1000 [00:01&lt;00:18, 51.90it/s]</pre> <pre>\r  6%|\u258c         | 62/1000 [00:01&lt;00:16, 57.68it/s]</pre> <pre>\r  7%|\u258b         | 69/1000 [00:01&lt;00:15, 59.32it/s]</pre> <pre>\r  8%|\u258a         | 76/1000 [00:01&lt;00:15, 60.81it/s]</pre> <pre>\r  8%|\u258a         | 83/1000 [00:01&lt;00:15, 59.55it/s]</pre> <pre>\r  9%|\u2589         | 90/1000 [00:01&lt;00:15, 59.64it/s]</pre> <pre>\r 10%|\u2589         | 97/1000 [00:02&lt;00:15, 57.19it/s]</pre> <pre>\r 10%|\u2588         | 105/1000 [00:02&lt;00:15, 57.45it/s]</pre> <pre>\r 11%|\u2588\u258f        | 113/1000 [00:02&lt;00:14, 59.47it/s]</pre> <pre>\r 12%|\u2588\u258f        | 121/1000 [00:02&lt;00:15, 57.65it/s]</pre> <pre>\r 13%|\u2588\u258e        | 129/1000 [00:02&lt;00:14, 59.30it/s]</pre> <pre>\r 14%|\u2588\u258e        | 137/1000 [00:02&lt;00:14, 60.18it/s]</pre> <pre>\r 14%|\u2588\u258d        | 145/1000 [00:02&lt;00:13, 61.20it/s]</pre> <pre>\r 15%|\u2588\u258c        | 153/1000 [00:02&lt;00:13, 61.08it/s]</pre> <pre>\r 16%|\u2588\u258c        | 161/1000 [00:03&lt;00:13, 61.65it/s]</pre> <pre>\r 17%|\u2588\u258b        | 169/1000 [00:03&lt;00:13, 61.83it/s]</pre> <pre>\r 18%|\u2588\u258a        | 177/1000 [00:03&lt;00:13, 61.90it/s]</pre> <pre>\r 18%|\u2588\u258a        | 184/1000 [00:03&lt;00:27, 29.64it/s]</pre> <pre>\r 19%|\u2588\u2589        | 190/1000 [00:04&lt;00:24, 33.07it/s]</pre> <pre>\r 20%|\u2588\u2589        | 198/1000 [00:04&lt;00:20, 38.72it/s]</pre> <pre>\r 20%|\u2588\u2588        | 204/1000 [00:04&lt;00:19, 41.21it/s]</pre> <pre>\r 21%|\u2588\u2588        | 210/1000 [00:04&lt;00:17, 44.87it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 217/1000 [00:04&lt;00:16, 48.35it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 224/1000 [00:04&lt;00:14, 52.86it/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 230/1000 [00:04&lt;00:14, 52.20it/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 238/1000 [00:04&lt;00:14, 54.37it/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 246/1000 [00:05&lt;00:13, 56.84it/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 254/1000 [00:05&lt;00:12, 57.81it/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 262/1000 [00:05&lt;00:12, 58.78it/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 270/1000 [00:05&lt;00:12, 59.13it/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 278/1000 [00:05&lt;00:13, 55.46it/s]</pre> <pre>\r 29%|\u2588\u2588\u258a       | 286/1000 [00:05&lt;00:11, 60.49it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 293/1000 [00:05&lt;00:11, 61.82it/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 300/1000 [00:05&lt;00:11, 61.34it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 307/1000 [00:06&lt;00:11, 62.44it/s]</pre> <pre>\r 31%|\u2588\u2588\u2588\u258f      | 314/1000 [00:06&lt;00:11, 61.21it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 321/1000 [00:06&lt;00:11, 59.32it/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 328/1000 [00:06&lt;00:10, 61.12it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 335/1000 [00:06&lt;00:10, 62.45it/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 342/1000 [00:06&lt;00:10, 60.21it/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258d      | 349/1000 [00:06&lt;00:11, 58.06it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 356/1000 [00:06&lt;00:11, 58.46it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258b      | 364/1000 [00:06&lt;00:10, 59.47it/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 372/1000 [00:07&lt;00:10, 59.59it/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 380/1000 [00:07&lt;00:10, 59.76it/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 388/1000 [00:07&lt;00:10, 60.51it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 396/1000 [00:07&lt;00:10, 59.71it/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 404/1000 [00:07&lt;00:10, 57.82it/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 412/1000 [00:07&lt;00:09, 60.10it/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 420/1000 [00:07&lt;00:09, 60.57it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 427/1000 [00:08&lt;00:09, 62.50it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 434/1000 [00:08&lt;00:09, 62.85it/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 441/1000 [00:08&lt;00:09, 61.06it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258d     | 448/1000 [00:08&lt;00:09, 58.66it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 455/1000 [00:08&lt;00:09, 60.41it/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258b     | 463/1000 [00:08&lt;00:09, 59.49it/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 469/1000 [00:08&lt;00:08, 59.17it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 476/1000 [00:08&lt;00:09, 57.84it/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 484/1000 [00:08&lt;00:08, 58.57it/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 492/1000 [00:09&lt;00:08, 59.59it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 500/1000 [00:09&lt;00:08, 60.79it/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 508/1000 [00:09&lt;00:08, 61.28it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 516/1000 [00:09&lt;00:07, 61.49it/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 524/1000 [00:09&lt;00:07, 61.95it/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 532/1000 [00:09&lt;00:07, 61.48it/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 539/1000 [00:09&lt;00:07, 62.31it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 546/1000 [00:09&lt;00:07, 60.00it/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 553/1000 [00:10&lt;00:07, 61.43it/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 560/1000 [00:10&lt;00:07, 60.03it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 567/1000 [00:10&lt;00:07, 61.42it/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 574/1000 [00:10&lt;00:06, 62.63it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 581/1000 [00:10&lt;00:06, 61.96it/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 588/1000 [00:10&lt;00:06, 59.91it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 595/1000 [00:10&lt;00:06, 60.72it/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 602/1000 [00:10&lt;00:06, 62.48it/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 609/1000 [00:11&lt;00:06, 59.14it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 615/1000 [00:11&lt;00:06, 57.30it/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 622/1000 [00:11&lt;00:06, 57.46it/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 629/1000 [00:11&lt;00:06, 60.49it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 636/1000 [00:11&lt;00:06, 60.57it/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 643/1000 [00:11&lt;00:05, 59.97it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 650/1000 [00:11&lt;00:05, 58.59it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 658/1000 [00:11&lt;00:05, 60.15it/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 665/1000 [00:11&lt;00:05, 62.52it/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 672/1000 [00:12&lt;00:05, 62.21it/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 679/1000 [00:12&lt;00:05, 60.11it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 686/1000 [00:12&lt;00:05, 58.97it/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 693/1000 [00:12&lt;00:05, 58.12it/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 700/1000 [00:12&lt;00:04, 60.19it/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 708/1000 [00:12&lt;00:04, 60.78it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 716/1000 [00:12&lt;00:04, 58.98it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 724/1000 [00:12&lt;00:04, 60.17it/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 732/1000 [00:13&lt;00:04, 61.07it/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 740/1000 [00:13&lt;00:04, 61.18it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 747/1000 [00:13&lt;00:04, 62.24it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 754/1000 [00:13&lt;00:04, 59.52it/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 762/1000 [00:13&lt;00:03, 59.55it/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 770/1000 [00:13&lt;00:03, 59.58it/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 778/1000 [00:13&lt;00:03, 60.10it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 786/1000 [00:13&lt;00:03, 60.67it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 794/1000 [00:14&lt;00:03, 60.94it/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 802/1000 [00:14&lt;00:03, 60.68it/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 810/1000 [00:14&lt;00:03, 61.64it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 817/1000 [00:14&lt;00:02, 61.88it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 824/1000 [00:14&lt;00:02, 60.98it/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 831/1000 [00:14&lt;00:02, 59.18it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 838/1000 [00:14&lt;00:02, 61.47it/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 845/1000 [00:14&lt;00:02, 62.81it/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 852/1000 [00:15&lt;00:02, 62.78it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 859/1000 [00:15&lt;00:02, 60.52it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 866/1000 [00:15&lt;00:02, 61.03it/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 873/1000 [00:15&lt;00:02, 61.42it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 881/1000 [00:15&lt;00:01, 61.95it/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 888/1000 [00:15&lt;00:01, 63.03it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 895/1000 [00:15&lt;00:01, 60.21it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 902/1000 [00:15&lt;00:01, 58.71it/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 909/1000 [00:15&lt;00:01, 59.93it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 917/1000 [00:16&lt;00:01, 60.55it/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 925/1000 [00:16&lt;00:01, 61.09it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 933/1000 [00:16&lt;00:01, 60.85it/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 941/1000 [00:16&lt;00:00, 61.39it/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 949/1000 [00:16&lt;00:00, 61.83it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 956/1000 [00:16&lt;00:00, 57.63it/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 964/1000 [00:16&lt;00:00, 60.09it/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 972/1000 [00:17&lt;00:00, 60.67it/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 980/1000 [00:17&lt;00:00, 60.47it/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 988/1000 [00:17&lt;00:00, 60.93it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 996/1000 [00:17&lt;00:00, 60.77it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:17&lt;00:00, 56.71it/s]</pre> <pre>\n</pre> Out[25]: <pre>Text(0, 0.5, 'Relative label distribution')</pre> In\u00a0[26]: Copied! <pre>estimator, losses = npe.train_torch_steady_state(\n    features=surrogate_features,\n    targets=surrogate_targets,\n    epochs=2_000,\n)\n\nax = losses.plot()\nax.set_ylim(0, None)\n</pre> estimator, losses = npe.train_torch_steady_state(     features=surrogate_features,     targets=surrogate_targets,     epochs=2_000, )  ax = losses.plot() ax.set_ylim(0, None) <pre>\r  0%|          | 0/2000 [00:00&lt;?, ?it/s]</pre> <pre>\r  7%|\u258b         | 143/2000 [00:00&lt;00:01, 1420.88it/s]</pre> <pre>\r 14%|\u2588\u258d        | 287/2000 [00:00&lt;00:01, 1429.27it/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 431/2000 [00:00&lt;00:01, 1432.04it/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 575/2000 [00:00&lt;00:00, 1429.12it/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 719/2000 [00:00&lt;00:00, 1431.87it/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 864/2000 [00:00&lt;00:00, 1435.01it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 1008/2000 [00:00&lt;00:00, 1431.95it/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1152/2000 [00:00&lt;00:00, 1433.93it/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1296/2000 [00:00&lt;00:00, 1429.20it/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1439/2000 [00:01&lt;00:00, 1428.61it/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1582/2000 [00:01&lt;00:00, 1418.26it/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1725/2000 [00:01&lt;00:00, 1419.06it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1869/2000 [00:01&lt;00:00, 1423.24it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [00:01&lt;00:00, 1427.49it/s]</pre> <pre>\n</pre> Out[26]: <pre>(0.0, 0.518943495163694)</pre> In\u00a0[27]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(\n    1,\n    2,\n    figsize=(8, 3),\n    layout=\"constrained\",\n    sharex=True,\n    sharey=False,\n)\n\nax = sns.kdeplot(surrogate_targets, fill=True, ax=ax1)\nax.set_title(\"Prior\")\n\nposterior = estimator.predict(surrogate_features)\n\nax = sns.kdeplot(posterior, fill=True, ax=ax2)\nax.set_title(\"Posterior\")\nax2.set_ylim(*ax1.get_ylim())\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(     1,     2,     figsize=(8, 3),     layout=\"constrained\",     sharex=True,     sharey=False, )  ax = sns.kdeplot(surrogate_targets, fill=True, ax=ax1) ax.set_title(\"Prior\")  posterior = estimator.predict(surrogate_features)  ax = sns.kdeplot(posterior, fill=True, ax=ax2) ax.set_title(\"Posterior\") ax2.set_ylim(*ax1.get_ylim()) plt.show() In\u00a0[28]: Copied! <pre>_ = plot.heatmap(inverse_parameter_elasticity(estimator, surrogate_features.iloc[0]))\n</pre> _ = plot.heatmap(inverse_parameter_elasticity(estimator, surrogate_features.iloc[0])) In\u00a0[29]: Copied! <pre>elasticities = pd.DataFrame(\n    {\n        k: inverse_parameter_elasticity(estimator, i).loc[\"vmax_2b\"]\n        for k, i in surrogate_features.iterrows()\n    }\n).T\n\n_ = plot.violins(elasticities)\n</pre> elasticities = pd.DataFrame(     {         k: inverse_parameter_elasticity(estimator, i).loc[\"vmax_2b\"]         for k, i in surrogate_features.iterrows()     } ).T  _ = plot.violins(elasticities) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"mxl.html#mechanistic-learning","title":"Mechanistic Learning\u00b6","text":"<p>Mechanistic learning is the intersection of mechanistic modelling and machine learning. mxlpy currently supports two such approaches: surrogates and neural posterior estimation.</p> <p>In the following we will mostly use the <code>mxlpy.surrogates</code> and <code>mxlpy.npe</code> modules to learn about both approaches.</p>"},{"location":"mxl.html#surrogate-models","title":"Surrogate models\u00b6","text":"<p>Surrogate models replace whole parts of a mechanistic model (or even the entire model) with machine learning models.</p> <p>This allows combining together multiple models of arbitrary size, without having to worry about the internal state of each model. They are especially useful for improving the description of boundary effects, e.g. a dynamic description of downstream consumption.</p>"},{"location":"mxl.html#manual-construction","title":"Manual construction\u00b6","text":"<p>Surrogates can have return two kind of values in <code>mxply</code>: <code>derived quantities</code> and <code>reactions</code>.</p> <p>We will start by defining a polynomial surrogate that will get the value of a variable <code>x</code> and output the derived quantity <code>y</code>. Note that due to their nature surrogates can take multiple inputs and return multiple outputs, so we will always use iterables when defining them.</p> <p>We then also add a derived value <code>z</code> that uses the output of our surrogate to see that we are getting the correct output.</p>"},{"location":"mxl.html#training-a-surrogate-from-data-and-using-it","title":"Training a surrogate from data and using it\u00b6","text":""},{"location":"mxl.html#create-data","title":"Create data\u00b6","text":"<p>The surrogates used in the following will all use the steady-state fluxes depending on the inputs.</p> <p>We can thus create the necessary training data usign <code>scan.steady_state</code>. Since this is usually a large amount of data, we recommend caching the results using <code>Cache</code>.</p>"},{"location":"mxl.html#polynomial-surrogate","title":"Polynomial surrogate\u00b6","text":"<p>We can train our polynomial surrogate using <code>train_polynomial_surrogate</code>. By default this will train polynomials for the degrees <code>(1, 2, 3, 4, 5, 6, 7)</code>, but you can change that by using the <code>degrees</code> argument. The function returns the trained surrogate and the training information for the different polynomial degrees.</p> <p>Currently the polynomial surrogates are limited to a single feature and a single target</p>"},{"location":"mxl.html#neural-network-surrogate-using-pytorch","title":"Neural network surrogate using PyTorch\u00b6","text":"<p>Neural networks are designed to capture highly complex and nonlinear relationships. Through layers of neurons and activation functions, neural networks can learn intricate patterns that are not easily represented by e.g. a polynomial. They have the flexibility to approximate any continuous function, given sufficient depth and appropriate training.</p> <p>You can train a neural network surrogate based on the popular PyTorch library using <code>train_torch_surrogate</code>. That function takes the <code>features</code>, <code>targets</code> and the number of <code>epochs</code> as inputs for it's training.</p> <p><code>train_torch_surrogate</code> returns the trained surrogate, as well as the training <code>loss</code>. It is always a good idea to check whether that training loss approaches 0.</p>"},{"location":"mxl.html#re-entrant-training","title":"Re-entrant training\u00b6","text":"<p>Quite often you don't know the amount of epochs you are going to need in order to reach the required loss. In this case, you can directly use the <code>TorchSurrogateTrainer</code> class to continue training.</p>"},{"location":"mxl.html#troubleshooting","title":"Troubleshooting\u00b6","text":"<p>It often can make sense to check specific predictions of the surrogate. For example, what does it predict when the inputs are all 0?</p>"},{"location":"mxl.html#neural-posterior-estimation","title":"Neural posterior estimation\u00b6","text":"<p>Neural posterior estimation answers the question: what parameters could have generated the data I measured? Here you use an ODE model and prior knowledge about the parameters of interest to create synthetic data. You then use the generated synthetic data as the features and the input parameters as the targets to train an inverse problem. Once that training is successful, the neural network can now predict the input parameters for real world data.</p> <p>You can use this technique for both steady-state as well as time course data. The only difference is in using <code>scan.time_course</code>.</p> <p>Take care here to save the targets as well in case you use cached data :)</p>"},{"location":"mxl.html#train-npe","title":"Train NPE\u00b6","text":"<p>You can then train your neural posterior estimator using <code>npe.train_torch_ss_estimator</code> (or <code>npe.train_torch_time_course_estimator</code> if you have time course data).</p>"},{"location":"mxl.html#sanity-check-do-prior-and-posterior-match","title":"Sanity check: do prior and posterior match?\u00b6","text":""},{"location":"mxl.html#re-entrant-training","title":"Re-entrant training\u00b6","text":"<p>As with the surrogates you often you don't know the amount of epochs you are going to need in order to reach the required loss. For the neural posterior estimation you can use the <code>npe.TorchSteadyStateTrainer</code> and <code>npe.TorchTimeCourseTrainer</code> respectively to continue training.</p>"},{"location":"mxl.html#custom-loss-function","title":"Custom loss function\u00b6","text":"<p>You can use a custom loss function by simply injecting a function that takes the predicted tensor <code>x</code> and the data <code>y</code> and produces another tensor.</p>"},{"location":"mxl.html#label-npe","title":"Label NPE\u00b6","text":""},{"location":"mxl.html#inverse-parameter-sensitivity","title":"Inverse parameter sensitivity\u00b6","text":""},{"location":"parameter_identifiability.html","title":"Identifiability","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom mxlpy import Model, Simulator, fns, plot\nfrom mxlpy.identify import profile_likelihood\nfrom mxlpy.types import unwrap\n</pre> import numpy as np  from mxlpy import Model, Simulator, fns, plot from mxlpy.identify import profile_likelihood from mxlpy.types import unwrap <p>We start with an SIR model, which we use to generate some data (this would usually be experimentally measured data)</p> In\u00a0[2]: Copied! <pre>def sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\ndata = unwrap(Simulator(sir()).simulate(100).get_result()).variables\n_ = plot.lines(data)\n</pre> def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   data = unwrap(Simulator(sir()).simulate(100).get_result()).variables _ = plot.lines(data) <p>We then, for <code>n</code> different values of each parameter we are interested in, we</p> <ul> <li>draw random samples for the remaining model parameters</li> <li>fit the model to the data (excluding the parameter we are interested in) and note the final error</li> <li>visualise the error for each parameter value</li> </ul> <p>The error for a parameter should show a clear minimum around the different values used, otherwise it is not identifiable</p> In\u00a0[3]: Copied! <pre>errors_beta = profile_likelihood(\n    sir(),\n    data=data,\n    parameter_name=\"beta\",\n    parameter_values=np.linspace(0.2 * 0.5, 0.2 * 1.5, 10),\n    n_random=10,\n)\n\nfig, ax = plot.lines(errors_beta, legend=False)\nax.set(title=\"beta\", xlabel=\"parameter value\", ylabel=\"abs(error)\")\nplot.show()\n</pre> errors_beta = profile_likelihood(     sir(),     data=data,     parameter_name=\"beta\",     parameter_values=np.linspace(0.2 * 0.5, 0.2 * 1.5, 10),     n_random=10, )  fig, ax = plot.lines(errors_beta, legend=False) ax.set(title=\"beta\", xlabel=\"parameter value\", ylabel=\"abs(error)\") plot.show() <pre>\rbeta:   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\rbeta:  10%|\u2588         | 1/10 [00:01&lt;00:14,  1.66s/it]</pre> <pre>\rbeta:  20%|\u2588\u2588        | 2/10 [00:03&lt;00:13,  1.72s/it]</pre> <pre>\rbeta:  30%|\u2588\u2588\u2588       | 3/10 [00:05&lt;00:12,  1.78s/it]</pre> <pre>\rbeta:  40%|\u2588\u2588\u2588\u2588      | 4/10 [00:07&lt;00:11,  1.98s/it]</pre> <pre>\rbeta:  50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:09&lt;00:10,  2.04s/it]</pre> <pre>\rbeta:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:11&lt;00:08,  2.11s/it]</pre> <pre>\rbeta:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:14&lt;00:06,  2.13s/it]</pre> <pre>\rbeta:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:16&lt;00:04,  2.14s/it]</pre> <pre>\rbeta:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:18&lt;00:02,  2.11s/it]</pre> <pre>\rbeta: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20&lt;00:00,  2.20s/it]</pre> <pre>\rbeta: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20&lt;00:00,  2.07s/it]</pre> <pre>\n</pre>"},{"location":"parameter_identifiability.html#numerical-parameter-identifiability","title":"Numerical parameter identifiability\u00b6","text":"<p>See the course by Marisa Eisenberg for an excellent introduction into the topic</p>"},{"location":"parameterise.html","title":"Model parameterisation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom mxlpy import Model, fns, mc, plot\nfrom mxlpy.distributions import GaussianKde, sample\nfrom mxlpy.parameterise import get_km_and_kcat_from_brenda\n</pre> from pathlib import Path  import matplotlib.pyplot as plt  from mxlpy import Model, fns, mc, plot from mxlpy.distributions import GaussianKde, sample from mxlpy.parameterise import get_km_and_kcat_from_brenda In\u00a0[2]: Copied! <pre>kms, kcats = get_km_and_kcat_from_brenda(\n    ec=\"4.1.1.39\",\n    brenda_path=Path(\"assets\") / \"brenda_rubisco_only.json\",\n)\n\nprint(f\"Found: {len(kms)} michaelis constants\")\nkms.head()\n</pre> kms, kcats = get_km_and_kcat_from_brenda(     ec=\"4.1.1.39\",     brenda_path=Path(\"assets\") / \"brenda_rubisco_only.json\", )  print(f\"Found: {len(kms)} michaelis constants\") kms.head() <pre>Found: 668 michaelis constants\n</pre> Out[2]: value substrate organism uniprot sequence 0 0.0290 CO2 Amphicarpaea bracteata A0A1C3HPM0 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... 5 0.0510 CO2 Archaeoglobus fulgidus O28635 MAEFEIYREYVDKSYEPQKDDIVAVFRITPAEGFTIEDAAGAVAAE... 7 0.0279 CO2 Hordeum murinum A0A1C3HPQ4 MSPQTETKAGVGFKAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 8 0.0279 CO2 Hordeum brachyantherum A0A1C3HPQ0 MSPQTETKAGVGFQAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 9 0.0195 CO2 Glycine canescens A0A1C3HPP9 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... <p>As you can see above, this provides you with parameter values for different organisms and substrates. Thus, we first filter by the specific substrate we are interested in.</p> In\u00a0[3]: Copied! <pre># Filter out a specific substrate\nkms = kms[kms[\"substrate\"] == \"CO2\"]\nkcats = kcats[kcats[\"substrate\"] == \"CO2\"]\n\nprint(f\"Filtered to {len(kms)} michaelis constants\")\nkms.head()\n</pre> # Filter out a specific substrate kms = kms[kms[\"substrate\"] == \"CO2\"] kcats = kcats[kcats[\"substrate\"] == \"CO2\"]  print(f\"Filtered to {len(kms)} michaelis constants\") kms.head() <pre>Filtered to 443 michaelis constants\n</pre> Out[3]: value substrate organism uniprot sequence 0 0.0290 CO2 Amphicarpaea bracteata A0A1C3HPM0 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... 5 0.0510 CO2 Archaeoglobus fulgidus O28635 MAEFEIYREYVDKSYEPQKDDIVAVFRITPAEGFTIEDAAGAVAAE... 7 0.0279 CO2 Hordeum murinum A0A1C3HPQ4 MSPQTETKAGVGFKAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 8 0.0279 CO2 Hordeum brachyantherum A0A1C3HPQ0 MSPQTETKAGVGFQAGVKDYKLTYYTPEYETKDTDILAAFRVSPQP... 9 0.0195 CO2 Glycine canescens A0A1C3HPP9 MSPQTETKASVGFKAGVKDYKLTYYTPDYETKDTDILAAFRVTPQP... <p>Since these are sufficiently many values, we can create a Gaussian Kernel Density estimate of them.</p> In\u00a0[4]: Copied! <pre>km_dist = GaussianKde.from_data(kms[\"value\"])\nfig, ax = km_dist.plot(\n    xmin=kms[\"value\"].min() * 0.8,\n    xmax=kms[\"value\"].max() * 1.2,\n)\nax.set(title=f\"rubisco km for CO2, n={len(kms)}\")\nplt.show()\n</pre> km_dist = GaussianKde.from_data(kms[\"value\"]) fig, ax = km_dist.plot(     xmin=kms[\"value\"].min() * 0.8,     xmax=kms[\"value\"].max() * 1.2, ) ax.set(title=f\"rubisco km for CO2, n={len(kms)}\") plt.show() <p>This kernel density estimate we can now use exactly like other distribution in our <code>Monte-Carlo</code> routines (see the Monte Carlo notebook for more information).</p> <p>Here, we create a small toy model and then use the distribution obtained from the experimental data to calculate the steady-state distribution of the model concentration.</p> In\u00a0[5]: Copied! <pre>model = (\n    Model()\n    .add_parameters({\"k_out\": 1.0, \"km\": 1.0})\n    .add_variable(\"PGA\", 0)\n    .add_reaction(\n        \"rubisco\",\n        fns.constant,\n        args=[\"km\"],\n        stoichiometry={\"PGA\": 2},\n    )\n    .add_reaction(\n        \"outflux\",\n        fns.mass_action_1s,\n        args=[\"PGA\", \"k_out\"],\n        stoichiometry={\"PGA\": -1},\n    )\n)\n\nss = mc.steady_state(model, mc_to_scan=sample({\"km\": km_dist}, n=10))\n\nfig, ax = plt.subplots(figsize=(4, 3))\nax.set(ylabel=\"Steady-state concentration\")\nplot.violins(ss.variables, ax=ax)\nplt.show()\n</pre> model = (     Model()     .add_parameters({\"k_out\": 1.0, \"km\": 1.0})     .add_variable(\"PGA\", 0)     .add_reaction(         \"rubisco\",         fns.constant,         args=[\"km\"],         stoichiometry={\"PGA\": 2},     )     .add_reaction(         \"outflux\",         fns.mass_action_1s,         args=[\"PGA\", \"k_out\"],         stoichiometry={\"PGA\": -1},     ) )  ss = mc.steady_state(model, mc_to_scan=sample({\"km\": km_dist}, n=10))  fig, ax = plt.subplots(figsize=(4, 3)) ax.set(ylabel=\"Steady-state concentration\") plot.violins(ss.variables, ax=ax) plt.show() <pre>\r  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:00&lt;00:00, 87.43it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 62.70it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about parameter scans in mxlpy.           Congratulations!"},{"location":"parameterise.html#model-parameterisation","title":"Model parameterisation\u00b6","text":"<p>Obtaining experimentally measured parameters can be challenging.</p> <p>Using the Brenda enzymes database we can obtain  distributions of enzymatic parameters for a wide range of organisms.</p> <p>We can do that with the <code>mxlpy.parameterise</code> module.</p> <p>These distributions can then in turn be used with our Monte-Carlo methods to capture the range of possible behaviour your model can exhibit.</p> + = <p>In order to obtain the parameters for a given Enzyme commision number (ec) we will manually download the database. You have to do this manually due to the brenda licensing terms.</p> <p>Note: we have created a small copy of just the rubisco data here to keep the documentation running. Adjust your <code>brenda_path</code> accordingly</p>"},{"location":"report.html","title":"Reporting","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom IPython.display import Markdown\nfrom matplotlib.figure import Figure\n\nfrom example_models import get_sir, get_sird\nfrom mxlpy import Model, Simulator, plot, report\nfrom mxlpy.types import unwrap\n\n\ndef plot_difference(r_old: pd.DataFrame, r_new: pd.DataFrame) -&gt; Figure:\n    rel_diff = (r_new - r_old) / r_old\n    largest_diff = rel_diff.abs().mean().fillna(0).sort_values().tail(n=3)\n\n    fig, ax = plot.one_axes()\n    plot.lines(r_new, ax=ax)\n    lines = dict(zip(r_new.columns, ax.lines, strict=True))\n    for f, i in enumerate(reversed(largest_diff.index), start=2):\n        line = lines[i]\n        line.set_linewidth(line.get_linewidth() * f)\n\n    plot.reset_prop_cycle(ax)\n    plot.lines(r_old, ax=ax, alpha=0.25, legend=False)\n    ax.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")\n    return fig\n</pre> from pathlib import Path  import matplotlib.pyplot as plt import pandas as pd from IPython.display import Markdown from matplotlib.figure import Figure  from example_models import get_sir, get_sird from mxlpy import Model, Simulator, plot, report from mxlpy.types import unwrap   def plot_difference(r_old: pd.DataFrame, r_new: pd.DataFrame) -&gt; Figure:     rel_diff = (r_new - r_old) / r_old     largest_diff = rel_diff.abs().mean().fillna(0).sort_values().tail(n=3)      fig, ax = plot.one_axes()     plot.lines(r_new, ax=ax)     lines = dict(zip(r_new.columns, ax.lines, strict=True))     for f, i in enumerate(reversed(largest_diff.index), start=2):         line = lines[i]         line.set_linewidth(line.get_linewidth() * f)      plot.reset_prop_cycle(ax)     plot.lines(r_old, ax=ax, alpha=0.25, legend=False)     ax.set(xlabel=\"Time / a.u.\", ylabel=\"Relative Population\")     return fig In\u00a0[2]: Copied! <pre>md = report.markdown(\n    get_sir(),\n    get_sird(),\n)\n\n# IPython Display\nMarkdown(md)\n</pre> md = report.markdown(     get_sir(),     get_sird(), )  # IPython Display Markdown(md) Out[2]: <p>You can further expand the report with user-defined analysis functions that are being run for both models. Here for example we perform a normal simulation and then plot the time course, highlighting the variables that changed the most.</p> <p>All user-defined analysis functions have to take two models and the directory where plots are to be stored as an input and output a description in markdown as well as the path of the final image, so that it can be inserted into the report correctly.</p> In\u00a0[3]: Copied! <pre>def analyse_concentrations(m1: Model, m2: Model, img_dir: Path) -&gt; tuple[str, Path]:\n    r_old = unwrap(Simulator(m1).simulate(100).get_result())\n    r_new = unwrap(Simulator(m2).simulate(100).get_result())\n    fig = plot_difference(r_old.variables, r_new.variables)\n    fig.savefig((path := img_dir / \"concentration.png\"), dpi=300)\n    plt.close(fig)\n    return \"## Comparison of largest changing\", path\n\n\nmd = report.markdown(\n    get_sir(),\n    get_sird(),\n    analyses=[analyse_concentrations],\n)\n\n# IPython Display\nMarkdown(md)\n</pre> def analyse_concentrations(m1: Model, m2: Model, img_dir: Path) -&gt; tuple[str, Path]:     r_old = unwrap(Simulator(m1).simulate(100).get_result())     r_new = unwrap(Simulator(m2).simulate(100).get_result())     fig = plot_difference(r_old.variables, r_new.variables)     fig.savefig((path := img_dir / \"concentration.png\"), dpi=300)     plt.close(fig)     return \"## Comparison of largest changing\", path   md = report.markdown(     get_sir(),     get_sird(),     analyses=[analyse_concentrations], )  # IPython Display Markdown(md) Out[3]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"report.html#reports","title":"Reports\u00b6","text":"<p>To make it easy to communicate changes between two models, <code>mxlpy</code> has conveniece functions in the <code>report</code> module. By default, the <code>report.markdown</code> function will take two models as inputs and then compare both the structure of the two models as well as numerical differences in dependent values as well as the right hand side.</p> <p>The report is color-coded consistently, with green referring to new features, orange referring to updates / changes and red referring to deleted quantities.</p>"},{"location":"report.html#report-2025-05-09","title":"Report:  2025-05-09\u00b6","text":""},{"location":"report.html#variables","title":"Variables\u00b6","text":"Name Old Value New Value d - 0.0"},{"location":"report.html#parameters","title":"Parameters\u00b6","text":"Name Old Value New Value mu - 0.01"},{"location":"report.html#reactions","title":"Reactions\u00b6","text":"Name Old Value New Value death - $i \\mu$"},{"location":"report.html#numerical-differences-of-right-hand-side-values","title":"Numerical differences of right hand side values\u00b6","text":"Name Old Value New Value Relative Change i 0.01 0.01 12.5%"},{"location":"report.html#report-2025-05-09","title":"Report:  2025-05-09\u00b6","text":""},{"location":"report.html#variables","title":"Variables\u00b6","text":"Name Old Value New Value d - 0.0"},{"location":"report.html#parameters","title":"Parameters\u00b6","text":"Name Old Value New Value mu - 0.01"},{"location":"report.html#reactions","title":"Reactions\u00b6","text":"Name Old Value New Value death - $i \\mu$"},{"location":"report.html#numerical-differences-of-right-hand-side-values","title":"Numerical differences of right hand side values\u00b6","text":"Name Old Value New Value Relative Change i 0.01 0.01 12.5%"},{"location":"report.html#comparison-of-largest-changing","title":"Comparison of largest changing\u00b6","text":""},{"location":"scans.html","title":"Scans","text":"In\u00a0[1]: Copied! <pre>from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport mxlpy as mb2\nfrom example_models import (\n    get_linear_chain_2v,\n)\nfrom mxlpy import make_protocol, plot, scan\n</pre> from __future__ import annotations  import matplotlib.pyplot as plt import numpy as np import pandas as pd  import mxlpy as mb2 from example_models import (     get_linear_chain_2v, ) from mxlpy import make_protocol, plot, scan In\u00a0[2]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 3, 11)}),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 3))\nplot.lines(res.variables, ax=ax1)  # access concentrations by name\nplot.lines(res.fluxes, ax=ax2)  # access fluxes by name\n\nax1.set(ylabel=\"Concentration / a.u.\")\nax2.set(ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(1, 3, 11)}), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 3)) plot.lines(res.variables, ax=ax1)  # access concentrations by name plot.lines(res.fluxes, ax=ax2)  # access fluxes by name  ax1.set(ylabel=\"Concentration / a.u.\") ax2.set(ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 5/11 [00:00&lt;00:00, 49.15it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 69.99it/s]</pre> <pre>\n</pre> <p>All scans return a result object, which allow multiple access patterns for convenience.</p> <p>Namely, the concentrations and fluxes can be accessed by name, unpacked or combined into a single dataframe.</p> In\u00a0[3]: Copied! <pre># Access by name\n_ = res.variables\n_ = res.fluxes\n\n# scan can be unpacked\nconcs, fluxes = res\n\n# combine concs and fluxes as single dataframe\n_ = res.results\n</pre> # Access by name _ = res.variables _ = res.fluxes  # scan can be unpacked concs, fluxes = res  # combine concs and fluxes as single dataframe _ = res.results In\u00a0[4]: Copied! <pre>mb2.cartesian_product(\n    {\n        \"k1\": [1, 2],\n        \"k2\": [3, 4],\n    }\n)\n</pre> mb2.cartesian_product(     {         \"k1\": [1, 2],         \"k2\": [3, 4],     } ) Out[4]: k1 k2 0 1 3 1 1 4 2 2 3 3 2 4 In\u00a0[5]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 3),\n            \"k2\": np.linspace(1, 2, 4),\n        }\n    ),\n)\n\nres.results.head()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 3),             \"k2\": np.linspace(1, 2, 4),         }     ), )  res.results.head() <pre>\r  0%|          | 0/12 [00:00&lt;?, ?it/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 9/12 [00:00&lt;00:00, 86.97it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:00&lt;00:00, 80.59it/s]</pre> <pre>\n</pre> Out[5]: x y v1 v2 v3 k1 k2 1.0 1.000000 1.00 1.0 1.0 1.0 1.0 1.333333 0.75 1.0 1.0 1.0 1.0 1.666667 0.60 1.0 1.0 1.0 1.0 2.000000 0.50 1.0 1.0 1.0 1.0 1.5 1.000000 1.50 1.5 1.5 1.5 1.5 <p>You can plot the results of a single variable of this scan using a heatmap</p> In\u00a0[6]: Copied! <pre>plot.heatmap_from_2d_idx(res.variables, variable=\"x\")\nplt.show()\n</pre> plot.heatmap_from_2d_idx(res.variables, variable=\"x\") plt.show() <p>Or create heatmaps of all passed variables at once.</p> In\u00a0[7]: Copied! <pre>plot.heatmaps_from_2d_idx(res.variables)\nplt.show()\n</pre> plot.heatmaps_from_2d_idx(res.variables) plt.show() <p>You can also combine more than two parameters, however, visualisation then becomes challenging.</p> In\u00a0[8]: Copied! <pre>res = scan.steady_state(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 3),\n            \"k2\": np.linspace(1, 2, 4),\n            \"k3\": np.linspace(1, 2, 4),\n        }\n    ),\n)\nres.results.head()\n</pre> res = scan.steady_state(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 3),             \"k2\": np.linspace(1, 2, 4),             \"k3\": np.linspace(1, 2, 4),         }     ), ) res.results.head() <pre>\r  0%|          | 0/48 [00:00&lt;?, ?it/s]</pre> <pre>\r 19%|\u2588\u2589        | 9/48 [00:00&lt;00:00, 87.86it/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 24/48 [00:00&lt;00:00, 119.15it/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 42/48 [00:00&lt;00:00, 139.33it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 48/48 [00:00&lt;00:00, 102.14it/s]</pre> <pre>\n</pre> Out[8]: x y v1 v2 v3 k1 k2 k3 1.0 1.000000 1.000000 1.00 1.00 1.0 1.0 1.0 1.333333 1.00 0.75 1.0 1.0 1.0 1.666667 1.00 0.60 1.0 1.0 1.0 2.000000 1.00 0.50 1.0 1.0 1.0 1.333333 1.000000 0.75 1.00 1.0 1.0 1.0 In\u00a0[9]: Copied! <pre>tss = scan.time_course(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),\n    time_points=np.linspace(0, 1, 11),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tss = scan.time_course(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),     time_points=np.linspace(0, 1, 11), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)  ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 9/11 [00:00&lt;00:00, 89.37it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 76.16it/s]</pre> <pre>\n</pre> <p>Again, this works for an arbitray number of parameters.</p> In\u00a0[10]: Copied! <pre>tss = scan.time_course(\n    get_linear_chain_2v(),\n    to_scan=mb2.cartesian_product(\n        {\n            \"k1\": np.linspace(1, 2, 11),\n            \"k2\": np.linspace(1, 2, 4),\n        }\n    ),\n    time_points=np.linspace(0, 1, 11),\n)\n\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\nplt.show()\n</pre> tss = scan.time_course(     get_linear_chain_2v(),     to_scan=mb2.cartesian_product(         {             \"k1\": np.linspace(1, 2, 11),             \"k2\": np.linspace(1, 2, 4),         }     ),     time_points=np.linspace(0, 1, 11), )   fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(tss.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\") plt.show() <pre>\r  0%|          | 0/44 [00:00&lt;?, ?it/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 14/44 [00:00&lt;00:00, 133.25it/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 41/44 [00:00&lt;00:00, 211.34it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44/44 [00:00&lt;00:00, 159.90it/s]</pre> <pre>\n</pre> <p>The scan object returned has a <code>pandas.MultiIndex</code> of <code>n x time</code>, where <code>n</code> is an index that references parameter combinations. You can access the referenced parameters using <code>.parameters</code></p> In\u00a0[11]: Copied! <pre>tss.parameters.head()\n</pre> tss.parameters.head() Out[11]: k1 k2 0 1.0 1.000000 1 1.0 1.333333 2 1.0 1.666667 3 1.0 2.000000 4 1.1 1.000000 <p>You can also easily access common aggregates like <code>mean</code> and <code>standard deviation (std)</code> using <code>get_agg_per_time</code>.</p> In\u00a0[12]: Copied! <pre>tss.get_agg_per_time(\"std\").head()\n</pre> tss.get_agg_per_time(\"std\").head() Out[12]: x y v1 v2 v3 time 0.0 7.758641e-17 1.148299e-16 0.319884 0.376987 1.148299e-16 0.1 4.593190e-02 3.336533e-02 0.319884 0.328164 3.336533e-02 0.2 8.557149e-02 5.943832e-02 0.319884 0.293370 5.943832e-02 0.3 1.198715e-01 7.999096e-02 0.319884 0.270384 7.999096e-02 0.4 1.496277e-01 9.645527e-02 0.319884 0.256845 9.645527e-02 In\u00a0[13]: Copied! <pre>res = scan.time_course_over_protocol(\n    get_linear_chain_2v(),\n    to_scan=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),\n    protocol=make_protocol(\n        [\n            (1, {\"k1\": 1}),\n            (2, {\"k1\": 2}),\n            (3, {\"k1\": 1}),\n        ]\n    ),\n)\n\nfig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\nplot.lines_mean_std_from_2d_idx(res.variables, ax=ax1)\nplot.lines_mean_std_from_2d_idx(res.fluxes, ax=ax2)\nax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\")\nax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")\n\nfor ax in (ax1, ax2):\n    plot.shade_protocol(res.protocol[\"k1\"], ax=ax, alpha=0.2)\nplt.show()\n</pre> res = scan.time_course_over_protocol(     get_linear_chain_2v(),     to_scan=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),     protocol=make_protocol(         [             (1, {\"k1\": 1}),             (2, {\"k1\": 2}),             (3, {\"k1\": 1}),         ]     ), )  fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4)) plot.lines_mean_std_from_2d_idx(res.variables, ax=ax1) plot.lines_mean_std_from_2d_idx(res.fluxes, ax=ax2) ax1.set(xlabel=\"time / a.u.\", ylabel=\"Concentration / a.u.\") ax2.set(xlabel=\"time / a.u.\", ylabel=\"Flux / a.u.\")  for ax in (ax1, ax2):     plot.shade_protocol(res.protocol[\"k1\"], ax=ax, alpha=0.2) plt.show() <pre>\r  0%|          | 0/11 [00:00&lt;?, ?it/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 5/11 [00:00&lt;00:00, 36.42it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00&lt;00:00, 40.08it/s]</pre> <pre>\n</pre> First finish line     With that you now know most of what you will need from a day-to-day basis about parameter scans in mxlpy.           Congratulations!  In\u00a0[14]: Copied! <pre>import pickle\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\n\nfrom mxlpy.parallel import Cache, parallelise\n\nif TYPE_CHECKING:\n    from collections.abc import Hashable\n</pre> import pickle from pathlib import Path from typing import TYPE_CHECKING, Any  from mxlpy.parallel import Cache, parallelise  if TYPE_CHECKING:     from collections.abc import Hashable In\u00a0[15]: Copied! <pre>def square(x: float) -&gt; float:\n    return x**2\n\n\noutput = parallelise(square, [(\"a\", 2), (\"b\", 3), (\"c\", 4)])\noutput\n</pre> def square(x: float) -&gt; float:     return x**2   output = parallelise(square, [(\"a\", 2), (\"b\", 3), (\"c\", 4)]) output <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 20.53it/s]</pre> <pre>\n</pre> Out[15]: <pre>{'a': 4, 'b': 9, 'c': 16}</pre> In\u00a0[16]: Copied! <pre>output = parallelise(\n    square,\n    [(\"a\", 2), (\"b\", 3), (\"c\", 4)],\n    cache=Cache(),\n)\n</pre> output = parallelise(     square,     [(\"a\", 2), (\"b\", 3), (\"c\", 4)],     cache=Cache(), ) <pre>\r  0%|          | 0/3 [00:00&lt;?, ?it/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 21.29it/s]</pre> <pre>\n</pre> <p>To avoid overwriting cache results by different analyses we recommend saving each of them in a respective folder.</p> In\u00a0[17]: Copied! <pre>_ = Cache(tmp_dir=Path(\".cache\") / \"analysis-name\")\n</pre> _ = Cache(tmp_dir=Path(\".cache\") / \"analysis-name\") <p>By default the <code>key</code> of <code>parallelise</code> is used to create a pickle file called <code>{k}.p</code>. You can customise this behaviour by changing the <code>name_fn</code>, <code>load_fn</code> and <code>save_fn</code> arguments respectively.</p> In\u00a0[18]: Copied! <pre>def _pickle_name(k: Hashable) -&gt; str:\n    return f\"{k}.p\"\n\n\ndef _pickle_load(file: Path) -&gt; Any:\n    with file.open(\"rb\") as fp:\n        return pickle.load(fp)\n\n\ndef _pickle_save(file: Path, data: Any) -&gt; None:\n    with file.open(\"wb\") as fp:\n        pickle.dump(data, fp)\n\n\n_ = Cache(\n    name_fn=_pickle_name,\n    load_fn=_pickle_load,\n    save_fn=_pickle_save,\n)\n</pre> def _pickle_name(k: Hashable) -&gt; str:     return f\"{k}.p\"   def _pickle_load(file: Path) -&gt; Any:     with file.open(\"rb\") as fp:         return pickle.load(fp)   def _pickle_save(file: Path, data: Any) -&gt; None:     with file.open(\"wb\") as fp:         pickle.dump(data, fp)   _ = Cache(     name_fn=_pickle_name,     load_fn=_pickle_load,     save_fn=_pickle_save, ) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"scans.html#parameter-scans","title":"Parameter scans\u00b6","text":"<p>Parameter scans allow you to systematically assess the behaviour of your model dependent on the value of one or more parameters. mxlpy has routines to scan over, and easily visualise time courses, protocol time courses, and steady states for one or more parameters.</p> <p>For this, we import the <code>scan</code> and <code>plot</code> modules from which contain the respective routines.</p>"},{"location":"scans.html#steady-state","title":"Steady-state\u00b6","text":"<p>The steady-state scan takes a <code>pandas.DataFrame</code> of parameters to be scanned as an input and returns the steady-states at the respective parameter values.</p> <p>The DataFrame can take an arbitrary number of parameters and should be in the following format</p> n k1 0 1 1 1.2 2 1.4 <p>As an example we will use a linear chain of two reactions like this</p> <p>$$ \\varnothing \\xrightarrow{v_1} S \\xrightarrow{v_2} P \\xrightarrow{v_3} \\varnothing$$</p>"},{"location":"scans.html#combinations","title":"Combinations\u00b6","text":"<p>Often you want to scan over multiple parameters at the same time. The recommended way to do this is to use the <code>cartesian_product</code> function, which takes a <code>parameter_name: values</code> mapping and creates a <code>pandas.DataFrame</code> of their combinations from it (think nested for loop).</p> <p>In the case the parameters <code>DataFrame</code> contains more than one column, the returned <code>pandas.DataFrame</code> will contain a <code>pandas.MultiIndex</code>.</p>"},{"location":"scans.html#time-course","title":"Time course\u00b6","text":"<p>You can perform a time course for each of the parameter values, resulting in a distribution of time courses. The index now also contains the time, so even for one parameter a <code>pandas.MultiIndex</code> is used.</p>"},{"location":"scans.html#protocol","title":"Protocol\u00b6","text":"<p>The same can be done for protocols.</p>"},{"location":"scans.html#parallel-execution","title":"Parallel execution\u00b6","text":"<p>By default, all scans are executed in parallel. To do this, they internally use the <code>parallelise</code> function defined by <code>mxlpy</code>.</p> <p>Tip: You can also use this function for other analyses as it is not specific to any <code>mxlpy</code> constructs.</p> <p>The <code>parallelise</code> takes a function of type <code>T</code> and an iterable of a <code>key: T</code> pair. The key is used to construct a dictionary of results and for caching (see below).</p>"},{"location":"scans.html#caching","title":"Caching\u00b6","text":"<p>In case the simulations take a significant amount of time to run, it makes sense to cache the results on disk. You can do that by adding a <code>cache</code> to the <code>parallelise</code> function (and thus to all <code>scan</code> functions as well).</p> <pre>parallelise(...,  cache=Cache())\n</pre> <p>The first time the scan is run, the calculations are done, every subsequent time the results are loaded.</p>"},{"location":"stability.html","title":"Stability analysis","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom example_models import get_phase_plane\nfrom mxlpy import plot\nfrom mxlpy.simulator import Simulator\nfrom mxlpy.types import unwrap\n</pre> import numpy as np  from example_models import get_phase_plane from mxlpy import plot from mxlpy.simulator import Simulator from mxlpy.types import unwrap In\u00a0[2]: Copied! <pre>_ = plot.trajectories_2d(\n    get_phase_plane(),\n    x1=(\"s1\", np.linspace(0, 2, 20)),\n    x2=(\"s2\", np.linspace(0, 2, 20)),\n)\n</pre> _ = plot.trajectories_2d(     get_phase_plane(),     x1=(\"s1\", np.linspace(0, 2, 20)),     x2=(\"s2\", np.linspace(0, 2, 20)), ) <p>As always, <code>plot.trajectories_2d</code> returns matplotlib <code>Figure</code> and <code>Axes</code> objects, so you can further customise the plot. Below we visualise example trajectories for different initial conditions of the model.</p> In\u00a0[3]: Copied! <pre>fig, ax = plot.trajectories_2d(\n    get_phase_plane(),\n    x1=(\"s1\", np.linspace(0, 2, 20)),\n    x2=(\"s2\", np.linspace(0, 2, 20)),\n)\n\nfor s1 in np.linspace(0, 1, 4):\n    for s2 in np.linspace(0, 2, 4):\n        c = unwrap(\n            Simulator(get_phase_plane(), y0={\"s1\": s1, \"s2\": s2})\n            .simulate(1.5)\n            .get_result()\n        ).variables\n        ax.plot(c[\"s1\"], c[\"s2\"])\n</pre> fig, ax = plot.trajectories_2d(     get_phase_plane(),     x1=(\"s1\", np.linspace(0, 2, 20)),     x2=(\"s2\", np.linspace(0, 2, 20)), )  for s1 in np.linspace(0, 1, 4):     for s2 in np.linspace(0, 2, 4):         c = unwrap(             Simulator(get_phase_plane(), y0={\"s1\": s1, \"s2\": s2})             .simulate(1.5)             .get_result()         ).variables         ax.plot(c[\"s1\"], c[\"s2\"])"},{"location":"stability.html#stability-analysis","title":"Stability analysis\u00b6","text":"<p>mxlpy offers routines to easily visualise the stability of the model over a wide range of parameters.</p> <p><code>plot.trajectories2d</code>  shows the vector field depending on the values of two <code>variables</code> as a quiver plot.</p>"},{"location":"symbolic.html","title":"Symbolic","text":"In\u00a0[1]: Copied! <pre>import sympy\n\nfrom mxlpy import Model, fns, symbolic, to_symbolic_model\n\n\ndef sir() -&gt; Model:\n    return (\n        Model()\n        .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})\n        .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})\n        .add_reaction(\n            \"infection\",\n            fns.mass_action_2s,\n            args=[\"s\", \"i\", \"beta\"],\n            stoichiometry={\"s\": -1, \"i\": 1},\n        )\n        .add_reaction(\n            \"recovery\",\n            fns.mass_action_1s,\n            args=[\"i\", \"gamma\"],\n            stoichiometry={\"i\": -1, \"r\": 1},\n        )\n    )\n\n\nsymbolic_model = to_symbolic_model(sir())\nsymbolic_model.jacobian()\n</pre> import sympy  from mxlpy import Model, fns, symbolic, to_symbolic_model   def sir() -&gt; Model:     return (         Model()         .add_variables({\"s\": 0.9, \"i\": 0.1, \"r\": 0.0})         .add_parameters({\"beta\": 0.2, \"gamma\": 0.1})         .add_reaction(             \"infection\",             fns.mass_action_2s,             args=[\"s\", \"i\", \"beta\"],             stoichiometry={\"s\": -1, \"i\": 1},         )         .add_reaction(             \"recovery\",             fns.mass_action_1s,             args=[\"i\", \"gamma\"],             stoichiometry={\"i\": -1, \"r\": 1},         )     )   symbolic_model = to_symbolic_model(sir()) symbolic_model.jacobian() Out[1]:  $\\displaystyle \\left[\\begin{matrix}- 1.0 \\beta i &amp; - 1.0 \\beta s &amp; 0\\\\1.0 \\beta i &amp; 1.0 \\beta s - 1.0 \\gamma &amp; 0\\\\0 &amp; 1.0 \\gamma &amp; 0\\end{matrix}\\right]$  In\u00a0[2]: Copied! <pre>res = symbolic.check_identifiability(\n    symbolic_model,\n    outputs=[sympy.Symbol(\"i\"), sympy.Symbol(\"r\")],\n)\nprint(res.summary())\n</pre> res = symbolic.check_identifiability(     symbolic_model,     outputs=[sympy.Symbol(\"i\"), sympy.Symbol(\"r\")], ) print(res.summary()) <pre>\rMain loop: 0it [00:00, ?it/s]</pre> <pre>\rMain loop: 2it [00:00, 27.15it/s]</pre> <pre>Summary\n=======\nThe model is not FISPO.\nIdentifiable parameters: [beta, gamma]\nUnidentifiable parameters: []\nIdentifiable variables: [s, i, r]\nUnidentifiable variables: []\nIdentifiable inputs: []\nUnidentifiable inputs: []\n\n</pre> <pre>\n</pre>"},{"location":"symbolic.html#identifiability","title":"Identifiability\u00b6","text":""},{"location":"tips.html","title":"Tips","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom cycler import cycler\n\nfrom mxlpy import plot\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd from cycler import cycler  from mxlpy import plot In\u00a0[2]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nfig, ax = plot.lines(\n    data.rename(\n        columns={\n            \"x1\": r\"$x_{1}$\",\n            \"x2\": r\"$x_{2}$\",\n            \"x3\": r\"$x_{3}$\",\n        }\n    )\n)\nax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\")\nplt.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  fig, ax = plot.lines(     data.rename(         columns={             \"x1\": r\"$x_{1}$\",             \"x2\": r\"$x_{2}$\",             \"x3\": r\"$x_{3}$\",         }     ) ) ax.set(xlabel=\"time / a.u.\", ylabel=\"concentration / a.u.\") plt.show() In\u00a0[3]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nwith plot.context(\n    colors=[\"r\", \"g\", \"b\"],\n    line_width=2,\n):\n    fig, ax = plot.lines(data)\n    ax.set(xlabel=\"time\", ylabel=\"amplitude\")\n\nax.legend()\nplot.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  with plot.context(     colors=[\"r\", \"g\", \"b\"],     line_width=2, ):     fig, ax = plot.lines(data)     ax.set(xlabel=\"time\", ylabel=\"amplitude\")  ax.legend() plot.show() In\u00a0[4]: Copied! <pre>x = np.linspace(0, np.pi, 100)\ndata = pd.DataFrame(\n    {\n        \"x1\": np.sin(x),\n        \"x2\": np.sin(x * 2),\n        \"x3\": np.sin(x * 4),\n    }\n)\n\nwith plot.context(\n    rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) + cycler(linestyle=[\"-\", \"--\"])},\n):\n    plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])\n    plot.show()\n\nwith plot.context(\n    rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) * cycler(linestyle=[\"-\", \"--\"])},\n):\n    plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])\n    plot.show()\n</pre> x = np.linspace(0, np.pi, 100) data = pd.DataFrame(     {         \"x1\": np.sin(x),         \"x2\": np.sin(x * 2),         \"x3\": np.sin(x * 4),     } )  with plot.context(     rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) + cycler(linestyle=[\"-\", \"--\"])}, ):     plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])     plot.show()  with plot.context(     rc={\"axes.prop_cycle\": cycler(color=[\"r\", \"b\"]) * cycler(linestyle=[\"-\", \"--\"])}, ):     plot.lines(data, ax=plot.one_axes(figsize=(3, 3))[1])     plot.show()"},{"location":"tips.html#tips-and-tricks","title":"Tips and tricks\u00b6","text":""},{"location":"tips.html#renaming-plots-arguments","title":"Renaming plots arguments\u00b6","text":"<p>The easiest way to rename plot arguments, e.g. for <code>LaTeX</code> display, is to work on the <code>pandas.DataFrame</code> directly. This conveniently offers a <code>rename</code> method, to which you can supply a dictionary of desired names.</p>"},{"location":"tips.html#custom-plot-styling","title":"Custom plot styling\u00b6","text":"<p>To change the style of plot elements, we recommend using <code>plot.context</code>, which is a convenience wrapper around <code>plt.rc_context</code>, see the matplotlib documentation.</p> <p>That way, our plotting routines can easily be re-used with completely different styling options.</p> <p>We opted for this way of styling plots so that you can use new features introduced by <code>matplotlib</code> immediately and don't have to wait for us to support every single update an every single plotting function.</p>"},{"location":"tips.html#advanced-plot-styling","title":"Advanced plot styling\u00b6","text":"<p>In case the our convenience arguments are not enough, you can use the entirety of the the matplotlib rc customizing arguments using the <code>rc</code> keyword argument of <code>plot.context</code>.</p> <p>Here, you have to spell out the exact name that <code>matplotlib</code> expects, e.g. <code>axes.prop_cycle</code> instead of just <code>colors</code> in case that was everything you wanted to change.</p> <p>Hint: watch out for the difference between <code>cycler + cycler</code> and <code>cycler * cycler</code>.</p>"}]}