{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelbase 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools as it\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from example_models import (\n",
    "    get_example1,\n",
    "    get_linear_chain_2v,\n",
    "    get_poolman2000,\n",
    "    get_upper_glycolysis,\n",
    ")\n",
    "\n",
    "import modelbase2 as mb2\n",
    "from modelbase2 import (\n",
    "    Cache,\n",
    "    Derived,\n",
    "    LabelMapper,\n",
    "    LinearLabelMapper,\n",
    "    Model,\n",
    "    Simulator,\n",
    "    fit,\n",
    "    mc,\n",
    "    mca,\n",
    "    npe,\n",
    "    plot,\n",
    "    scans,\n",
    ")\n",
    "from modelbase2.distributions import LogNormal, Uniform, sample\n",
    "from modelbase2.surrogates import create_ss_flux_data, train_torch_surrogate\n",
    "from modelbase2.types import unwrap, unwrap2\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from modelbase2.types import Array\n",
    "\n",
    "\n",
    "def create_steady_state_data(\n",
    "    model: Model,\n",
    "    parameters: pd.DataFrame,\n",
    "    cache: Cache | None,\n",
    "    y0: dict[str, float] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        scans.parameter_scan_ss(\n",
    "            model=model,\n",
    "            parameters=parameters,\n",
    "            y0=y0,\n",
    "            cache=cache,\n",
    "        ),\n",
    "        axis=1,\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def create_time_series_data(\n",
    "    model: Model,\n",
    "    parameters: pd.DataFrame,\n",
    "    time_points: Array,\n",
    "    cache: Cache | None,\n",
    "    y0: dict[str, float] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    return scans.parameter_scan_time_series(\n",
    "        model=model,\n",
    "        parameters=parameters,\n",
    "        time_points=time_points,\n",
    "        y0=y0,\n",
    "        cache=cache,\n",
    "    ).results\n",
    "\n",
    "\n",
    "def randomise_parameters(m: Model, seed: int = 42) -> Model:\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    m.update_parameters(\n",
    "        (pd.Series(m.parameters) + rng.normal(0, 0.125, len(m.parameters))).to_dict()\n",
    "    )\n",
    "    return m\n",
    "\n",
    "\n",
    "def make_protocol(steps: dict[float, dict[str, float]]) -> pd.DataFrame:\n",
    "    data = {}\n",
    "\n",
    "    t0 = pd.Timedelta(0)\n",
    "    for step, pars in steps.items():\n",
    "        t0 += pd.Timedelta(seconds=step)\n",
    "        data[t0] = pars\n",
    "    return pd.DataFrame(data).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your first model\n",
    "\n",
    "Let's say you want to model the following chemical network\n",
    "\n",
    "$$ \\Large \\varnothing \\xrightarrow{v_0} S \\xrightarrow{v_1} P \\xrightarrow{v_2} \\varnothing $$\n",
    "\n",
    "which translates into\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{dS}{dt} &= v_0 - v_1     \\\\\n",
    "\\frac{dP}{dt} &= v_1 - v_2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We then choose rate equations for each rate to get the flux vector $v$\n",
    "\n",
    "$$\\begin{align*}\n",
    "    v_0 &= k_0 \\\\\n",
    "    v_1 &= k_1 * S \\\\\n",
    "    v_2 &= k_2 * P \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "<!-- $$v = \\left\\{ \n",
    "    \\begin{align*}\n",
    "    & k_0 \\\\\n",
    "    & k_1 * S \\\\\n",
    "    & k_2 * P \\\\\n",
    "    \\end{align*} \n",
    "\\right.$$ -->\n",
    "\n",
    "Then the system of ODEs is given by \n",
    "\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{dS}{dt} &= k_0 - k_1 * S     \\\\\n",
    "\\frac{dP}{dt} &= k_1 * S - k_2 * P \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Let's begin by defining rate functions.  \n",
    "Note that these should be **general** and **re-usable** whenever possible, to make your model clear to people reading it.  \n",
    "Try to give these functions names that are meaningful to your audience, e.g. a rate function `k * s` could be named **proportional** or **mass-action**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant(k: float) -> float:\n",
    "    return k\n",
    "\n",
    "\n",
    "def proportional(k: float, s: float) -> float:\n",
    "    return k * s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create our model.  \n",
    "Note, that we use a single function that returns the model instead of defining it globally.  \n",
    "This allows us to quickly re-create the model whenever we need a fresh version of it.  \n",
    "\n",
    "Let's step through the code below:\n",
    "\n",
    "We first add parameters to the model using `.add_parameters({name: value})`.  \n",
    "\n",
    "Next, we add variables using `.add_variables({name: initial_value})`.  \n",
    "\n",
    "Finally, we add the three reactions by using \n",
    "\n",
    "```python\n",
    ".add_reaction(\n",
    "    name,              # the internal name for the reaction\n",
    "    fn=...,            # a python function to be evaluated\n",
    "    args=[name, ...]   # the arguments passed to the python function\n",
    "    stoichiometry={    \n",
    "        name: value    \n",
    "    },                 # a mapping encoding how much the variable `name`\n",
    "                       # is changed by the reaction\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_chain_2cpds() -> Model:\n",
    "    return (\n",
    "        Model()\n",
    "        .add_parameters({\"k_in\": 1, \"k_1\": 1, \"k_out\": 1})\n",
    "        .add_variables({\"S\": 0, \"P\": 0})\n",
    "        .add_reaction(\n",
    "            \"v0\",\n",
    "            fn=constant,\n",
    "            stoichiometry={\"S\": 1},\n",
    "            args=[\"k_in\"],\n",
    "        )\n",
    "        .add_reaction(\n",
    "            \"v1\",\n",
    "            fn=proportional,\n",
    "            stoichiometry={\"S\": -1, \"P\": 1},\n",
    "            args=[\"k_1\", \"S\"],\n",
    "        )\n",
    "        .add_reaction(\n",
    "            \"v2\",\n",
    "            fn=proportional,\n",
    "            stoichiometry={\"P\": -1},\n",
    "            args=[\"k_out\", \"P\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then simulate the model by passing it to a `Simulator` and simulate a time series using `.simulate(t_end)`.  \n",
    "Finally, we can obtain the concentrations and fluxes using `get_concs_and_fluxes`.  \n",
    "\n",
    "> Note, that  `get_concs_and_fluxes` returns `tuple[pd.DataFrame | None, pd.DataFrame | None]`, indicating that it will return `None` in case the simulation fails.  \n",
    "> Thus, it is good practice to always check for failure.  \n",
    "\n",
    "While you can directly plot the `pd.DataFrame`s, modelbase supplies a variety of plots in the `plot` namespace that are worth checking out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, v = unwrap2(\n",
    "    Simulator(linear_chain_2cpds())  # initialise the simulator\n",
    "    .simulate(10)  # simulate until t_end = 10\n",
    "    .get_concs_and_fluxes()  # return pd.DataFrames for concentrations and fluxes\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(6, 3))\n",
    "_ = plot.lines(c, ax=ax1)\n",
    "_ = plot.lines(v, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `Simulator` is initialised with the initial concentrations set in the `Model`.  \n",
    "Optionally, you can overwrite the initial conditions using the `y0` argument.  \n",
    "\n",
    "```python\n",
    "Simulator(model, y0={name: value, ...})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived quantities\n",
    "\n",
    "Frequently it makes sense to derive one quantity in a model from other quantities.  \n",
    "In `modelbase2` this is done by using the `Derived` class.\n",
    "This can be done for\n",
    "\n",
    "- parameters derived from other parameters\n",
    "- variables derived from parameters or other variables\n",
    "- stoichiometries derived from parameters or variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moiety_1(x1: float, total: float) -> float:\n",
    "    return total - x1\n",
    "\n",
    "\n",
    "m = (\n",
    "    Model()\n",
    "    .add_variables({\"ATP\": 1.0})\n",
    "    .add_parameters({\"ATP_total\": 1.0})\n",
    "    .add_derived(\"ADP\", moiety_1, [\"ATP\", \"ATP_total\"])\n",
    "    .add_reaction(\"ATPase\", constant, {\"ATP\": -1}, [\"ATP\"])\n",
    ")\n",
    "\n",
    "c, v = Simulator(m).simulate(10).get_full_concs_and_fluxes()\n",
    "if c is not None:\n",
    "    plot.lines(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady-state\n",
    "\n",
    "You can simulate until the model reaches a steady-state using the `simulate_to_steady_state` method.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concs, fluxes = (\n",
    "    Simulator(get_linear_chain_2v())  # optionally supply initial conditions\n",
    "    .simulate_to_steady_state()\n",
    "    .get_concs_and_fluxes()\n",
    ")\n",
    "concs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "You can obtain the time series of integration using the `simulate` method.  \n",
    "There are three ways how you can define the time points this function returns.  \n",
    "\n",
    "1. supply the end time `t_end`\n",
    "2. supply both end time and number of steps with `steps`\n",
    "3. supply the exact time points to be returned using `time_points`\n",
    "\n",
    "```python\n",
    "simulate(t_end=10)\n",
    "simulate(t_end=10, steps=10)\n",
    "simulate(time_points=np.linspace(0, 10, 11))\n",
    "```\n",
    "\n",
    "> Note that these settings don't change the integration itself (e.g. tolerances)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concs, fluxes = (\n",
    "    Simulator(get_linear_chain_2v())  # optionally supply initial conditions\n",
    "    .simulate(t_end=10)\n",
    "    .get_concs_and_fluxes()\n",
    ")\n",
    "\n",
    "if concs is not None:\n",
    "    _ = plot.lines(concs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol time series\n",
    "\n",
    "Protocols are used to make parameter changes discrete in time.  \n",
    "This is useful e.g. for reproducing experimental time courses where a parameter was changed at fixed time points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = make_protocol(\n",
    "    {\n",
    "        1: {\"k1\": 1},\n",
    "        2: {\"k1\": 2},\n",
    "        3: {\"k1\": 1},\n",
    "    }\n",
    ")\n",
    "concs, fluxes = (\n",
    "    Simulator(get_linear_chain_2v())\n",
    "    .simulate_over_protocol(protocol)\n",
    "    .get_concs_and_fluxes()\n",
    ")\n",
    "\n",
    "if concs is not None:\n",
    "    fig, ax = plt.subplots()\n",
    "    plot.lines(concs, ax=ax)\n",
    "    plot.shade_protocol(protocol[\"k1\"], ax=ax, alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter scans\n",
    "\n",
    "`modelbase` has a variety of parameter scans available.  \n",
    "They differ by the kind of data returned by them, e.g. steady-states or time series of concentration and fluxes.\n",
    "\n",
    "In all cases, the parameters which you want to scan over are passed as a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mb2.parameter_scan_ss(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 3))\n",
    "plot.lines(scan.concs, ax=ax1)\n",
    "plot.lines(scan.fluxes, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scans return some kind of result object, which allow multiple access patterns for convenience. \n",
    "\n",
    "Namely, the concentrations and fluxes can be accessed by name, unpacked or combined into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access by name\n",
    "_ = scan.concs\n",
    "_ = scan.fluxes\n",
    "\n",
    "# scan can be unpacked\n",
    "concs, fluxes = scan\n",
    "\n",
    "# combine concs and fluxes as single dataframe\n",
    "_ = scan.results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinations\n",
    "\n",
    "Often you want to scan over multiple parameters at the same time.  \n",
    "The recommended way to do this is to use the `cartesian_product` function, which takes a `parameter_name: values` mapping and creates a `pandas.DataFrame` of their combinations from it (think nested for loop).  \n",
    "\n",
    "In the case of more than one parameter, the returned `pandas.DataFrame` contains a `pandas.MultiIndex`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mb2.parameter_scan_ss(\n",
    "    get_linear_chain_2v(),\n",
    "    mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 3),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "scan.results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the results of this scan using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap_from_2d_idx(scan.concs, variable=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or create heatmaps of all passed variables at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmaps_from_2d_idx(scan.concs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine more than two parameters, however, visualisation becomes challenging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mb2.parameter_scan_ss(\n",
    "    get_linear_chain_2v(),\n",
    "    mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 3),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "            \"k3\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "scan.results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series\n",
    "\n",
    "You can perform a time series for each of the parameter values.  \n",
    "The index now also contains the time, so even for one parameter a `pandas.MultiIndex` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = mb2.parameter_scan_time_series(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=pd.DataFrame({\"k1\": np.linspace(1, 2, 11)}),\n",
    "    time_points=np.linspace(0, 1, 11),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(tss.concs, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this works for an arbitray number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = mb2.parameter_scan_time_series(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(1, 2, 11),\n",
    "            \"k2\": np.linspace(1, 2, 4),\n",
    "        }\n",
    "    ),\n",
    "    time_points=np.linspace(0, 1, 11),\n",
    ")\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(tss.concs, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(tss.fluxes, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scan object returned has a `pandas.MultiIndex` of `n x time`, where `n` is an index that references parameter combinations.  \n",
    "You can access the referenced parameters using `.parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.parameters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily access common aggregates using `get_agg_per_time`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss.get_agg_per_time(\"std\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol\n",
    "\n",
    "The same can be done for protocols.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mb2.parameter_scan_protocol(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=pd.DataFrame({\"k2\": np.linspace(1, 2, 11)}),\n",
    "    protocol=make_protocol(\n",
    "        {\n",
    "            1: {\"k1\": 1},\n",
    "            2: {\"k1\": 2},\n",
    "            3: {\"k1\": 1},\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(scan.concs, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(scan.fluxes, ax=ax2)\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    plot.shade_protocol(scan.protocol[\"k1\"], ax=ax, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabolic control analysis\n",
    "\n",
    "`modelbase` supports both elasticities (arbitrary state) and response coefficients (steady-state) measurements from metabolic control analysis.  \n",
    "They can all be found in the `modelbase2.mca` namespace.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable elasticities\n",
    "\n",
    "Variable elasticities are the sensitivity of reactions to a small change in the concentration of a variable.  \n",
    "They are **not** a steady-state measurement and can be calculated for any arbitrary state.  \n",
    "\n",
    "Both the `concs` and `variables` arguments are optional.  \n",
    "If `concs` is not supplied, the routine will use the initial conditions from the model.  \n",
    "If `variables` is not supplied, the elasticities will be calculated for all variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elas = mca.variable_elasticities(\n",
    "    get_upper_glycolysis(),\n",
    "    concs={\n",
    "        \"GLC\": 0.3,\n",
    "        \"G6P\": 0.4,\n",
    "        \"F6P\": 0.5,\n",
    "        \"FBP\": 0.6,\n",
    "        \"ATP\": 0.4,\n",
    "        \"ADP\": 0.6,\n",
    "    },\n",
    "    variables=[\"GLC\", \"F6P\"],\n",
    ")\n",
    "\n",
    "_ = plot.heatmap(elas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter elasticities\n",
    "\n",
    "Parameter elasticities are the sensitivity of reactions to a small change in the concentration of a variable.  \n",
    "They are **not** a steady-state measurement and can be calculated for any arbitrary state.  \n",
    "\n",
    "Both the `concs` and `parameters` arguments are optional.  \n",
    "If `concs` is not supplied, the routine will use the initial conditions from the model.  \n",
    "If `parameters` is not supplied, the elasticities will be calculated for all parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elas = mca.parameter_elasticities(\n",
    "    get_upper_glycolysis(),\n",
    "    concs={\n",
    "        \"GLC\": 0.3,\n",
    "        \"G6P\": 0.4,\n",
    "        \"F6P\": 0.5,\n",
    "        \"FBP\": 0.6,\n",
    "        \"ATP\": 0.4,\n",
    "        \"ADP\": 0.6,\n",
    "    },\n",
    "    parameters=[\"k1\", \"k2\"],\n",
    ")\n",
    "\n",
    "_ = plot.heatmap(elas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response coefficients\n",
    "\n",
    "Response coefficients show the sensitivity of variables and reactions **at steady-state** to a small change in a parameter.  \n",
    "\n",
    "If the parameter is proportional to the rate, they are also called **control coefficients**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crcs, frcs = mca.response_coefficients(\n",
    "    get_upper_glycolysis(),\n",
    "    parameters=[\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\"],\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "_ = plot.heatmap(crcs, ax=ax1)\n",
    "_ = plot.heatmap(frcs, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-carlo scans\n",
    "\n",
    "Most model parameters in the natural sciences are typically best described using **distributions**.  \n",
    "Thus, to get the distribution of realistic behaviour, `modelbase` supplies monte-carlo methods of all other analyses.\n",
    "\n",
    "For that, you supply a `pandas.DataFrame` of parameter values randomly drawn from different distributions.  \n",
    "You can use the `sample` function and distributions supplied by modelbase.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(\n",
    "    {\n",
    "        \"k2\": Uniform(1.0, 2.0),\n",
    "        \"k3\": LogNormal(mean=1.0, sigma=1.0),\n",
    "    },\n",
    "    n=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create custom distributions, all you need to do is to create a class that follows the `Distribution` protocol, e.g. implements a sample function.  \n",
    "\n",
    "```python\n",
    "class MyOwnDistribution:\n",
    "    def sample(self, num: int) -> Array:\n",
    "        # implement here\n",
    "```\n",
    "\n",
    "and it can be used in the `sample` function as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monte-carlo steady-states\n",
    "\n",
    "Using `mc.steady_state` you can calculate the steady-state distribution given the monte-carlo parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mc.steady_state(\n",
    "    get_linear_chain_2v(),\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k1\": Uniform(0.9, 1.1),\n",
    "            \"k2\": Uniform(1.0, 1.3),\n",
    "            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n",
    "        },\n",
    "        n=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4), sharex=False)\n",
    "plot.violins(scan.concs, ax=ax1)\n",
    "plot.violins(scan.fluxes, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monte-carlo time series\n",
    "\n",
    "Using `mc.time_course` you can calculate time courses for sampled parameters.  \n",
    "\n",
    "The `pandas.DataFrame`s for concentrations and fluxes have a `n x time` `pandas.MultiIndex`.  \n",
    "The corresponding parameters can be found in `scan.parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mc.time_course(\n",
    "    get_linear_chain_2v(),\n",
    "    time_points=np.linspace(0, 1, 11),\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k1\": Uniform(0.9, 1.1),\n",
    "            \"k2\": Uniform(1.0, 1.3),\n",
    "            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n",
    "        },\n",
    "        n=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(scan.concs, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(scan.fluxes, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mc protocol\n",
    "\n",
    "\n",
    "Using `mc.time_course_over_protocol` you can calculate time courses for sampled parameters given a discrete protocol.  \n",
    "\n",
    "The `pandas.DataFrame`s for concentrations and fluxes have a `n x time` `pandas.MultiIndex`.  \n",
    "The corresponding parameters can be found in `scan.parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = mc.time_course_over_protocol(\n",
    "    get_linear_chain_2v(),\n",
    "    time_points_per_step=10,\n",
    "    protocol=make_protocol(\n",
    "        {\n",
    "            1: {\"k1\": 1},\n",
    "            2: {\"k1\": 2},\n",
    "            3: {\"k1\": 1},\n",
    "        }\n",
    "    ),\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k2\": Uniform(1.0, 1.3),\n",
    "            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n",
    "        },\n",
    "        n=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plot.two_axes(figsize=(7, 4))\n",
    "plot.lines_mean_std_from_2d_idx(scan.concs, ax=ax1)\n",
    "plot.lines_mean_std_from_2d_idx(scan.fluxes, ax=ax2)\n",
    "for ax in (ax1, ax2):\n",
    "    plot.shade_protocol(scan.protocol[\"k1\"], ax=ax, alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mc metabolic control analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compound elasticities\n",
    "\n",
    "The returned `pandas.DataFrame` has a `pd.MultiIndex` of shape `n x reaction`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elas = mc.compound_elasticities(\n",
    "    get_upper_glycolysis(),\n",
    "    concs={\n",
    "        \"GLC\": 0.3,\n",
    "        \"G6P\": 0.4,\n",
    "        \"F6P\": 0.5,\n",
    "        \"FBP\": 0.6,\n",
    "        \"ATP\": 0.4,\n",
    "        \"ADP\": 0.6,\n",
    "    },\n",
    "    variables=[\"GLC\", \"F6P\"],\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            # \"k1\": LogNormal(mean=np.log(0.25), sigma=1.0),\n",
    "            # \"k2\": LogNormal(mean=np.log(1.0), sigma=1.0),\n",
    "            \"k3\": LogNormal(mean=np.log(1.0), sigma=1.0),\n",
    "            # \"k4\": LogNormal(mean=np.log(1.0), sigma=1.0),\n",
    "            # \"k5\": LogNormal(mean=np.log(1.0), sigma=1.0),\n",
    "            # \"k6\": LogNormal(mean=np.log(1.0), sigma=1.0),\n",
    "            # \"k7\": LogNormal(mean=np.log(2.5), sigma=1.0),\n",
    "        },\n",
    "        n=5,\n",
    "    ),\n",
    ")\n",
    "\n",
    "_ = plot.violins_from_2d_idx(elas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elas = mc.parameter_elasticities(\n",
    "    get_upper_glycolysis(),\n",
    "    concs={\n",
    "        \"GLC\": 0.3,\n",
    "        \"G6P\": 0.4,\n",
    "        \"F6P\": 0.5,\n",
    "        \"FBP\": 0.6,\n",
    "        \"ATP\": 0.4,\n",
    "        \"ADP\": 0.6,\n",
    "    },\n",
    "    parameters=[\"k1\", \"k2\", \"k3\"],\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k3\": LogNormal(mean=np.log(0.25), sigma=1.0),\n",
    "        },\n",
    "        n=5,\n",
    "    ),\n",
    ")\n",
    "\n",
    "_ = plot.violins_from_2d_idx(elas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = mc.response_coefficients(\n",
    "    get_poolman2000(),\n",
    "    parameters=[\"Vmax_1\", \"Vmax_6\", \"Vmax_9\", \"Vmax_13\", \"Vmax_16\"],\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"Vmax_1\": LogNormal(np.log(2.72), sigma=0.1),\n",
    "            \"Vmax_6\": LogNormal(np.log(1.6), sigma=0.1),\n",
    "            \"Vmax_9\": LogNormal(np.log(0.32), sigma=0.1),\n",
    "            \"Vmax_13\": LogNormal(np.log(8.0), sigma=0.1),\n",
    "            \"Vmax_16\": LogNormal(np.log(2.8), sigma=0.1),\n",
    "        },\n",
    "        n=5,\n",
    "    ),\n",
    ")\n",
    "\n",
    "_ = plot.violins_from_2d_idx(resp.concs.loc[:, [\"PGA\", \"GAP\", \"SBP\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mc steady-state parameter scan\n",
    "\n",
    "Vary **both** monte carlo parameters as well as systematically scan for other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcss = mc.parameter_scan_ss(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=pd.DataFrame({\"k1\": np.linspace(0, 1, 3)}),\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k2\": Uniform(1.0, 1.3),\n",
    "            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n",
    "        },\n",
    "        n=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "plot.violins_from_2d_idx(mcss.concs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: no idea how to plot this yet. Ridge plots?\n",
    "# Maybe it's just a bit much :D\n",
    "\n",
    "mcss = mc.parameter_scan_ss(\n",
    "    get_linear_chain_2v(),\n",
    "    parameters=mb2.cartesian_product(\n",
    "        {\n",
    "            \"k1\": np.linspace(0, 1, 3),\n",
    "            \"k2\": np.linspace(0, 1, 3),\n",
    "        }\n",
    "    ),\n",
    "    mc_parameters=sample(\n",
    "        {\n",
    "            \"k3\": LogNormal(mean=1.0, sigma=0.2),\n",
    "        },\n",
    "        n=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "mcss.concs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_linear_chain_2v()\n",
    "c, v = (\n",
    "    Simulator(m).simulate(time_points=np.linspace(0, 1, 11)).get_full_concs_and_fluxes()\n",
    ")\n",
    "\n",
    "res = pd.concat((c, v), axis=1)\n",
    "res.head()\n",
    "\n",
    "fit.steady_state(\n",
    "    randomise_parameters(get_linear_chain_2v()),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=res.iloc[-1].loc[[\"x\", \"v1\"]],\n",
    ")\n",
    "fit.time_series(\n",
    "    randomise_parameters(get_linear_chain_2v()),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=res.loc[:, [\"x\", \"v1\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady-state surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of this models behaviour\n",
    "_ = unwrap(Simulator(get_example1()).simulate(10).get_fluxes()).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    it.product(\n",
    "        np.linspace(0, 2.0, 21),\n",
    "        np.linspace(0, 2.0, 21),\n",
    "        np.linspace(0, 2.0, 21),\n",
    "    ),\n",
    "    columns=[\"x1\", \"ATP\", \"NADPH\"],\n",
    ")\n",
    "\n",
    "targets = create_ss_flux_data(\n",
    "    get_example1(),\n",
    "    features,\n",
    "    cache=Cache(Path(\".cache\") / \"linear\"),\n",
    ").loc[:, [\"x2_out\", \"x3_out\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate, loss = train_torch_surrogate(\n",
    "    features=features,\n",
    "    targets=targets,\n",
    "    epochs=2000,\n",
    "    surrogate_inputs=[\"x1\", \"ATP\", \"NADPH\"],\n",
    "    surrogate_stoichiometries={\n",
    "        \"v2\": {\"x1\": -1, \"x2\": 1, \"ATP\": -1},\n",
    "        \"v3\": {\"x1\": -1, \"x3\": 1, \"NADPH\": -1},\n",
    "    },\n",
    ")\n",
    "\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions of rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surrogate.predict(np.array([0.0, 0.0, 0.0])))\n",
    "print(surrogate.predict(np.array([1.0, 0.0, 0.0])))\n",
    "print(surrogate.predict(np.array([0.0, 1.0, 0.0])))\n",
    "print(surrogate.predict(np.array([0.0, 0.0, 1.0])))\n",
    "print(surrogate.predict(np.array([1.0, 0.0, 1.0])))\n",
    "print(surrogate.predict(np.array([1.0, 1.0, 1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert surrogate into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> Model:\n",
    "    model = Model()\n",
    "    model.add_variables(\n",
    "        {\n",
    "            \"x1\": 1.0,\n",
    "            \"x2\": 0.0,\n",
    "            \"x3\": 0.0,\n",
    "            \"ATP\": 2.0,\n",
    "            \"NADPH\": 0.1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Adding the surrogate\n",
    "    model.add_surrogate(\"surrogate\", surrogate)\n",
    "\n",
    "    # Note that besides the surrogate we haven't defined any other reaction!\n",
    "    # We could have though\n",
    "    return model\n",
    "\n",
    "\n",
    "c, v = Simulator(get_model()).simulate(0.8).get_full_concs_and_fluxes()\n",
    "\n",
    "# FIXME: note that NADPH get's negative\n",
    "# At least the rates seem to get 0 around the tie when x1 is 0\n",
    "if c is None or v is None:\n",
    "    msg = \"Simulation failed\"\n",
    "    raise ValueError(msg)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "c.plot(ax=ax1, xlabel=\"time / s\", ylabel=\"concentration / mM\")\n",
    "v.plot(ax=ax2, xlabel=\"time / s\", ylabel=\"flux / (mM / s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural posterior estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of this models behaviour\n",
    "if (fluxes := Simulator(get_example1()).simulate(10).get_fluxes()) is not None:\n",
    "    fluxes.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = sample(\n",
    "    {\n",
    "        \"x1\": LogNormal(mean=1.0, sigma=0.3),\n",
    "        \"ATP\": LogNormal(mean=0.7, sigma=0.1),\n",
    "        \"NADPH\": LogNormal(mean=0.3, sigma=0.2),\n",
    "    },\n",
    "    n=10_000,\n",
    ")\n",
    "\n",
    "time_points = np.linspace(0, 10, 11)\n",
    "\n",
    "ss_data = create_steady_state_data(\n",
    "    get_example1(),\n",
    "    parameters=targets,\n",
    "    cache=Cache(Path(\".cache\") / \"npe-ss\"),\n",
    ")\n",
    "\n",
    "ts_data = create_time_series_data(\n",
    "    get_example1(),\n",
    "    parameters=targets,\n",
    "    time_points=time_points,\n",
    "    cache=Cache(Path(\".cache\") / \"npe-ts\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NPE on steady-state data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ss_data.loc[:, [\"x2\", \"x3\"]]\n",
    "\n",
    "estimator, losses = npe.train_torch_ss_estimator(\n",
    "    features=features,\n",
    "    targets=targets,\n",
    "    epochs=5_000,\n",
    ")\n",
    "\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(8, 3),\n",
    "    layout=\"constrained\",\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "ax = sns.kdeplot(targets, fill=True, ax=ax1)\n",
    "ax.set_title(\"Prior\")\n",
    "\n",
    "posterior = estimator.predict(features)\n",
    "\n",
    "ax = sns.kdeplot(posterior, fill=True, ax=ax2)\n",
    "ax.set_title(\"Posterior\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NPE on time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ts_data.loc[:, [\"x2\", \"x3\"]]\n",
    "\n",
    "\n",
    "estimator, losses = npe.train_torch_time_series_estimator(\n",
    "    features=features,\n",
    "    targets=targets,\n",
    "    epochs=5_000,\n",
    ")\n",
    "\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(8, 3),\n",
    "    layout=\"constrained\",\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "ax = sns.kdeplot(targets, fill=True, ax=ax1)\n",
    "ax.set_title(\"Prior\")\n",
    "\n",
    "posterior = estimator.predict(features)\n",
    "\n",
    "ax = sns.kdeplot(posterior, fill=True, ax=ax2)\n",
    "ax.set_title(\"Posterior\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_action_1(kf: float, s: float) -> float:\n",
    "    return kf * s\n",
    "\n",
    "\n",
    "def mass_action_2(kf: float, s1: float, s2: float) -> float:\n",
    "    return kf * s1 * s2\n",
    "\n",
    "\n",
    "def get_model() -> Model:\n",
    "    p = {\n",
    "        \"kf_TPI\": 1.0,\n",
    "        \"Keq_TPI\": 21.0,\n",
    "        \"kf_Ald\": 2000.0,\n",
    "        \"Keq_Ald\": 7000.0,\n",
    "    }\n",
    "    p[\"kr_TPI\"] = p[\"kf_TPI\"] / p[\"Keq_TPI\"]\n",
    "    p[\"kr_Ald\"] = p[\"kf_Ald\"] / p[\"Keq_Ald\"]\n",
    "\n",
    "    GAP0 = 2.5e-5\n",
    "    DHAP0 = GAP0 * p[\"Keq_TPI\"]\n",
    "    FBP0 = GAP0 * DHAP0 * p[\"Keq_Ald\"]\n",
    "\n",
    "    y0 = {\"GAP\": GAP0, \"DHAP\": DHAP0, \"FBP\": FBP0}\n",
    "\n",
    "    return (\n",
    "        Model()\n",
    "        .add_variables(y0)\n",
    "        .add_parameters(p)\n",
    "        .add_reaction(\n",
    "            \"TPIf\",\n",
    "            mass_action_1,\n",
    "            {\"GAP\": -1, \"DHAP\": 1},\n",
    "            [\"kf_TPI\", \"GAP\"],\n",
    "        )\n",
    "        .add_reaction(\n",
    "            \"TPIr\",\n",
    "            mass_action_1,\n",
    "            {\"DHAP\": -1, \"GAP\": 1},\n",
    "            [\"kr_TPI\", \"DHAP\"],\n",
    "        )\n",
    "        .add_reaction(\n",
    "            \"ALDf\",\n",
    "            mass_action_2,\n",
    "            {\"DHAP\": -1, \"GAP\": -1, \"FBP\": 1},\n",
    "            [\"kf_Ald\", \"DHAP\", \"GAP\"],\n",
    "        )\n",
    "        .add_reaction(\n",
    "            \"ALDr\",\n",
    "            mass_action_1,\n",
    "            {\n",
    "                \"FBP\": -1,\n",
    "                \"DHAP\": 1,\n",
    "                \"GAP\": 1,\n",
    "            },\n",
    "            [\"kr_Ald\", \"FBP\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = LabelMapper(\n",
    "    get_model(),\n",
    "    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n",
    "    label_maps={\n",
    "        \"TPIf\": [2, 1, 0],\n",
    "        \"TPIr\": [2, 1, 0],\n",
    "        \"ALDf\": [0, 1, 2, 3, 4, 5],\n",
    "        \"ALDr\": [0, 1, 2, 3, 4, 5],\n",
    "    },\n",
    ")\n",
    "\n",
    "if (\n",
    "    concs := Simulator(mapper.build_model(initial_labels={\"GAP\": 0}))\n",
    "    .simulate(20)\n",
    "    .get_full_concs()\n",
    ") is not None:\n",
    "    plot.relative_label_distribution(mapper, concs, n_cols=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear label mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_model()\n",
    "\n",
    "concs, fluxes = Simulator(m).simulate(20).get_concs_and_fluxes()\n",
    "if concs is None or fluxes is None:\n",
    "    raise ValueError\n",
    "\n",
    "mapper = LinearLabelMapper(\n",
    "    m,\n",
    "    label_variables={\"GAP\": 3, \"DHAP\": 3, \"FBP\": 6},\n",
    "    label_maps={\n",
    "        \"TPIf\": [2, 1, 0],\n",
    "        \"TPIr\": [2, 1, 0],\n",
    "        \"ALDf\": [0, 1, 2, 3, 4, 5],\n",
    "        \"ALDr\": [0, 1, 2, 3, 4, 5],\n",
    "    },\n",
    ")\n",
    "\n",
    "if (\n",
    "    concs := (\n",
    "        Simulator(\n",
    "            mapper.build_model(\n",
    "                concs=concs.iloc[-1],\n",
    "                fluxes=fluxes.iloc[-1],\n",
    "                initial_labels={\"GAP\": 0},\n",
    "            )\n",
    "        )\n",
    "        .simulate(20)\n",
    "        .get_full_concs()\n",
    "    )\n",
    ") is not None:\n",
    "    plot.relative_label_distribution(mapper, concs, n_cols=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
