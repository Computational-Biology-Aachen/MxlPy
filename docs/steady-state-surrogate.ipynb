{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools as it\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn, optim\n",
    "\n",
    "from modelbase2.mc import parallelise\n",
    "from modelbase2.mc._scan import _empty_flux_series\n",
    "from modelbase2 import Model, Simulator, TorchSurrogate\n",
    "from modelbase2.mc import Cache\n",
    "\n",
    "\n",
    "def filter_stoichiometry(\n",
    "    model: Model,\n",
    "    stoichiometry: dict[str, float],\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Only use components that are actually compounds in the model\"\"\"\n",
    "    new: dict[str, float] = {}\n",
    "    for k, v in stoichiometry.items():\n",
    "        if k in model._variables:\n",
    "            new[k] = v\n",
    "        elif k not in model._ids:  # noqa: SLF001\n",
    "            msg = f\"Missing component {k}\"\n",
    "            raise KeyError(msg)\n",
    "    return new\n",
    "\n",
    "\n",
    "def constant(x: float) -> float:\n",
    "    return x\n",
    "\n",
    "\n",
    "def michaelis_menten_2s(\n",
    "    s1: float,\n",
    "    s2: float,\n",
    "    vmax: float,\n",
    "    km1: float,\n",
    "    km2: float,\n",
    "    ki1: float,\n",
    ") -> float:\n",
    "    return vmax * s1 * s2 / (ki1 * km2 + km2 * s1 + km1 * s2 + s1 * s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_be_replaced() -> Model:\n",
    "    model = Model()\n",
    "    model.add_variables({\"x2\": 0.0, \"x3\": 0.0})\n",
    "    model.add_parameters(\n",
    "        {\n",
    "            # These need to be static in order to train the model later\n",
    "            \"x1\": 1.0,\n",
    "            \"ATP\": 1.0,\n",
    "            \"NADPH\": 1.0,\n",
    "            # v2\n",
    "            \"vmax_v2\": 2.0,\n",
    "            \"km_v2_1\": 0.1,\n",
    "            \"km_v2_2\": 0.1,\n",
    "            \"ki_v2\": 0.1,\n",
    "            # v3\n",
    "            \"vmax_v3\": 2.0,\n",
    "            \"km_v3_1\": 0.2,\n",
    "            \"km_v3_2\": 0.2,\n",
    "            \"ki_v3\": 0.2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model.add_reaction(\n",
    "        \"v2\",\n",
    "        michaelis_menten_2s,\n",
    "        filter_stoichiometry(model, {\"x1\": -1, \"ATP\": -1, \"x2\": 1}),\n",
    "        [\"x1\", \"ATP\", \"vmax_v2\", \"km_v2_1\", \"km_v2_2\", \"ki_v2\"],\n",
    "    )\n",
    "    model.add_reaction(\n",
    "        \"v3\",\n",
    "        michaelis_menten_2s,\n",
    "        filter_stoichiometry(model, {\"x1\": -1, \"NADPH\": -1, \"x3\": 1}),\n",
    "        [\"x1\", \"ATP\", \"vmax_v3\", \"km_v3_1\", \"km_v3_2\", \"ki_v3\"],\n",
    "    )\n",
    "    model.add_reaction(\"x2_out\", constant, {\"x2\": -1}, [\"x2\"])\n",
    "    model.add_reaction(\"x3_out\", constant, {\"x3\": -1}, [\"x3\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example plot of this models behaviour\n",
    "_ = Simulator(model_to_be_replaced()).simulate_and(10).get_fluxes().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_flux(\n",
    "    params: pd.Series,\n",
    "    model: Model,\n",
    ") -> pd.Series:\n",
    "    flux = (\n",
    "        Simulator(model.update_parameters(params.to_dict()))\n",
    "        .simulate_to_steady_state_and()\n",
    "        .get_fluxes()\n",
    "    )\n",
    "    if flux is None:\n",
    "        return _empty_flux_series(model)\n",
    "    return flux.iloc[-1]\n",
    "\n",
    "\n",
    "inp = pd.DataFrame(\n",
    "    it.product(\n",
    "        np.linspace(0, 2.0, 21),\n",
    "        np.linspace(0, 2.0, 21),\n",
    "        np.linspace(0, 2.0, 21),\n",
    "    ),\n",
    "    columns=[\"x1\", \"ATP\", \"NADPH\"],\n",
    ")\n",
    "\n",
    "\n",
    "res = (\n",
    "    pd.concat(\n",
    "        parallelise(\n",
    "            partial(\n",
    "                ss_flux,\n",
    "                model=model_to_be_replaced(),\n",
    "            ),\n",
    "            inputs=list(inp.iterrows()),\n",
    "            cache=Cache(),\n",
    "        )\n",
    "    )\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "features = inp\n",
    "target = res.loc[:, [\"x2_out\", \"x3_out\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approximator(nn.Module):\n",
    "    def __init__(self, n_inputs: int, n_outputs: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, n_outputs),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "aprox = Approximator(\n",
    "    n_inputs=len(features.columns),\n",
    "    n_outputs=len(target.columns),\n",
    ").to(device)\n",
    "optimizer = optim.RMSprop(aprox.parameters(), lr=1e-3)\n",
    "\n",
    "X = torch.Tensor(features.to_numpy(), device=device)\n",
    "Y = torch.Tensor(target.to_numpy(), device=device)\n",
    "\n",
    "# TODO: batch the training\n",
    "losses = {}\n",
    "for i in tqdm.trange(2000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean(torch.abs(aprox(X) - Y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses[i] = loss.detach().numpy()\n",
    "\n",
    "_ = pd.Series(losses, dtype=float).plot(xlabel=\"Epoch\", ylabel=\"Loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert surrogate into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> Model:\n",
    "    model = Model()\n",
    "    model.add_variables({\"x1\": 1.0, \"x2\": 0.0, \"x3\": 0.0, \"ATP\": 2.0, \"NADPH\": 0.1})\n",
    "\n",
    "    # Adding the surrogate\n",
    "    model.add_surrogate(\n",
    "        \"surrogate\",\n",
    "        TorchSurrogate(\n",
    "            model=aprox,\n",
    "            inputs=[\"x1\", \"ATP\", \"NADPH\"],\n",
    "            stoichiometries={\n",
    "                \"v2\": {\"x1\": -1, \"x2\": 1, \"ATP\": -1},\n",
    "                \"v3\": {\"x1\": -1, \"x3\": 1, \"NADPH\": -1},\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Note that besides the surrogate we haven't defined any other reaction!\n",
    "    # We could obviously though\n",
    "    return model\n",
    "\n",
    "\n",
    "c, v = Simulator(get_model()).simulate_and(2).get_full_concs_and_fluxes()\n",
    "\n",
    "# FIXME: note that NADPH get's negative\n",
    "# At least the rates seem to get 0 around the tie when x1 is 0\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "c.plot(ax=ax1, xlabel=\"time / s\", ylabel=\"concentration / mM\")\n",
    "v.plot(ax=ax2, xlabel=\"time / s\", ylabel=\"flux / (mM / s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some manual tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = TorchSurrogate(\n",
    "    model=aprox,\n",
    "    inputs=[\"x1\", \"ATP\", \"NADPH\"],\n",
    "    stoichiometries={\n",
    "        \"v2\": {\"x1\": -1, \"x2\": 1, \"ATP\": -1},\n",
    "        \"v3\": {\"x1\": -1, \"x3\": 1, \"NADPH\": -1},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(surrogate.predict(np.array([0.0, 0.0, 0.0])))\n",
    "print(surrogate.predict(np.array([1.0, 0.0, 0.0])))\n",
    "print(surrogate.predict(np.array([0.0, 1.0, 0.0])))\n",
    "print(surrogate.predict(np.array([0.0, 0.0, 1.0])))\n",
    "print(surrogate.predict(np.array([1.0, 0.0, 1.0])))\n",
    "print(surrogate.predict(np.array([1.0, 1.0, 1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
